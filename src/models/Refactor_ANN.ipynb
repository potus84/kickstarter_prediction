{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/potusvn/Projects/kickstarter_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras import models, optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import l2\n",
    "from os.path import join\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer\n",
    "from settings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_quantile_transform.csv', encoding='latin1', low_memory=True)\n",
    "test = pd.read_csv('data/test_quantile_transform.csv', encoding='latin1', low_memory=True)\n",
    "val = pd.read_csv('data/val_quantile_transform.csv', encoding='latin1', low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(['success'], axis=1)\n",
    "train_y = train.success\n",
    "\n",
    "val_x = val.drop(['success'], axis=1)\n",
    "val_y = val.success\n",
    "\n",
    "test_x = test.drop(['success'], axis=1)\n",
    "test_y = test.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(185736, 221)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Test the structure of network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hidden_layers, optimizer=optimizers.Adam(lr=0.01), batch_size=512, drop_out=0.0, l2_val=0, file_name=None):\n",
    "    model = models.Sequential()\n",
    "    # Hidden - Layers\n",
    "    for idx, layer in enumerate(hidden_layers):\n",
    "        if idx == 0:\n",
    "            model.add(Dense(layer, activation=\"relu\", input_shape=(221,), kernel_regularizer=l2(l2_val)))\n",
    "            model.add(Dropout(drop_out, noise_shape=None, seed=None))\n",
    "        else:\n",
    "            model.add(Dense(layer, activation=\"relu\", kernel_regularizer=l2(l2_val)))\n",
    "            model.add(Dropout(drop_out, noise_shape=None, seed=None))\n",
    "    # Output- Layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    # compiling the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    # Define some callbacks\n",
    "    callbacks_func = []\n",
    "    earlyStopping = EarlyStopping(monitor='val_acc', patience=50, verbose=0, mode='max')\n",
    "    if file_name is None:\n",
    "        callbacks_func = [earlyStopping]\n",
    "    else:\n",
    "        mcp_save = ModelCheckpoint(file_name+'.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
    "        callbacks_func = [mcp_save, earlyStopping]\n",
    "    results = model.fit(\n",
    "        train_x, train_y,\n",
    "        epochs=1000,\n",
    "        batch_size=batch_size,\n",
    "        callbacks = callbacks_func,\n",
    "        validation_data=(val_x, val_y)\n",
    "    )\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_accuracy_train_and_val(history, title):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.ylim(0.77, 0.81)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 10)                2220      \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 2,281\n",
      "Trainable params: 2,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4692 - acc: 0.7592 - val_loss: 0.4367 - val_acc: 0.7786\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4259 - acc: 0.7858 - val_loss: 0.4269 - val_acc: 0.7807\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4227 - acc: 0.7871 - val_loss: 0.4242 - val_acc: 0.7869\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4199 - acc: 0.7893 - val_loss: 0.4215 - val_acc: 0.7873\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4186 - acc: 0.7899 - val_loss: 0.4216 - val_acc: 0.7877\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4179 - acc: 0.7905 - val_loss: 0.4212 - val_acc: 0.7884\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4172 - acc: 0.7904 - val_loss: 0.4224 - val_acc: 0.7869\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4166 - acc: 0.7910 - val_loss: 0.4203 - val_acc: 0.7887\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4158 - acc: 0.7914 - val_loss: 0.4218 - val_acc: 0.7877\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4161 - acc: 0.7913 - val_loss: 0.4221 - val_acc: 0.7881\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4152 - acc: 0.7922 - val_loss: 0.4201 - val_acc: 0.7875\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4148 - acc: 0.7926 - val_loss: 0.4203 - val_acc: 0.7886\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4142 - acc: 0.7933 - val_loss: 0.4208 - val_acc: 0.7878\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4139 - acc: 0.7930 - val_loss: 0.4204 - val_acc: 0.7871\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4137 - acc: 0.7929 - val_loss: 0.4203 - val_acc: 0.7877\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4138 - acc: 0.7929 - val_loss: 0.4192 - val_acc: 0.7880\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4132 - acc: 0.7936 - val_loss: 0.4188 - val_acc: 0.7887\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4130 - acc: 0.7933 - val_loss: 0.4202 - val_acc: 0.7876\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4127 - acc: 0.7936 - val_loss: 0.4203 - val_acc: 0.7876\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4122 - acc: 0.7943 - val_loss: 0.4209 - val_acc: 0.7870\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4123 - acc: 0.7937 - val_loss: 0.4196 - val_acc: 0.7879\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4119 - acc: 0.7946 - val_loss: 0.4214 - val_acc: 0.7871\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4122 - acc: 0.7943 - val_loss: 0.4195 - val_acc: 0.7883\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4119 - acc: 0.7943 - val_loss: 0.4226 - val_acc: 0.7857\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4114 - acc: 0.7949 - val_loss: 0.4195 - val_acc: 0.7880\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4117 - acc: 0.7944 - val_loss: 0.4229 - val_acc: 0.7881\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4112 - acc: 0.7946 - val_loss: 0.4195 - val_acc: 0.7892\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4113 - acc: 0.7949 - val_loss: 0.4191 - val_acc: 0.7900\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4111 - acc: 0.7946 - val_loss: 0.4206 - val_acc: 0.7887\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4109 - acc: 0.7952 - val_loss: 0.4201 - val_acc: 0.7888\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4108 - acc: 0.7951 - val_loss: 0.4195 - val_acc: 0.7875\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4106 - acc: 0.7955 - val_loss: 0.4192 - val_acc: 0.7897\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4109 - acc: 0.7948 - val_loss: 0.4209 - val_acc: 0.7882\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4105 - acc: 0.7951 - val_loss: 0.4196 - val_acc: 0.7898\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4103 - acc: 0.7952 - val_loss: 0.4219 - val_acc: 0.7874\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4107 - acc: 0.7951 - val_loss: 0.4196 - val_acc: 0.7883\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4104 - acc: 0.7957 - val_loss: 0.4204 - val_acc: 0.7894\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4102 - acc: 0.7952 - val_loss: 0.4185 - val_acc: 0.7894\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4102 - acc: 0.7954 - val_loss: 0.4186 - val_acc: 0.7897\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4100 - acc: 0.7963 - val_loss: 0.4194 - val_acc: 0.7890\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4101 - acc: 0.7955 - val_loss: 0.4204 - val_acc: 0.7882\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4097 - acc: 0.7962 - val_loss: 0.4200 - val_acc: 0.7881\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4100 - acc: 0.7953 - val_loss: 0.4196 - val_acc: 0.7891\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4100 - acc: 0.7954 - val_loss: 0.4187 - val_acc: 0.7897\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 3s 14us/step - loss: 0.4095 - acc: 0.7967 - val_loss: 0.4195 - val_acc: 0.7884\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4094 - acc: 0.7963 - val_loss: 0.4188 - val_acc: 0.7903\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4097 - acc: 0.7960 - val_loss: 0.4195 - val_acc: 0.7885\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4094 - acc: 0.7960 - val_loss: 0.4188 - val_acc: 0.7899\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4093 - acc: 0.7955 - val_loss: 0.4189 - val_acc: 0.7892\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4096 - acc: 0.7965 - val_loss: 0.4226 - val_acc: 0.7857\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4095 - acc: 0.7956 - val_loss: 0.4192 - val_acc: 0.7891\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4092 - acc: 0.7964 - val_loss: 0.4190 - val_acc: 0.7902\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4091 - acc: 0.7964 - val_loss: 0.4192 - val_acc: 0.7894\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4091 - acc: 0.7961 - val_loss: 0.4199 - val_acc: 0.7888\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4094 - acc: 0.7965 - val_loss: 0.4203 - val_acc: 0.7884\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4091 - acc: 0.7961 - val_loss: 0.4189 - val_acc: 0.7890\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4090 - acc: 0.7966 - val_loss: 0.4210 - val_acc: 0.7897\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4092 - acc: 0.7956 - val_loss: 0.4196 - val_acc: 0.7896\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4090 - acc: 0.7963 - val_loss: 0.4201 - val_acc: 0.7884\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4090 - acc: 0.7963 - val_loss: 0.4199 - val_acc: 0.7897\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4089 - acc: 0.7964 - val_loss: 0.4193 - val_acc: 0.7896\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4085 - acc: 0.7963 - val_loss: 0.4188 - val_acc: 0.7900\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4086 - acc: 0.7958 - val_loss: 0.4192 - val_acc: 0.7900\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4085 - acc: 0.7965 - val_loss: 0.4194 - val_acc: 0.7899\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4084 - acc: 0.7968 - val_loss: 0.4201 - val_acc: 0.7886\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4086 - acc: 0.7964 - val_loss: 0.4193 - val_acc: 0.7890\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4087 - acc: 0.7962 - val_loss: 0.4194 - val_acc: 0.7894\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4085 - acc: 0.7970 - val_loss: 0.4200 - val_acc: 0.7903\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4084 - acc: 0.7964 - val_loss: 0.4203 - val_acc: 0.7893\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4083 - acc: 0.7966 - val_loss: 0.4196 - val_acc: 0.7897\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4088 - acc: 0.7964 - val_loss: 0.4203 - val_acc: 0.7894\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4082 - acc: 0.7970 - val_loss: 0.4196 - val_acc: 0.7900\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4082 - acc: 0.7968 - val_loss: 0.4198 - val_acc: 0.7899\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4081 - acc: 0.7972 - val_loss: 0.4220 - val_acc: 0.7884\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4080 - acc: 0.7969 - val_loss: 0.4207 - val_acc: 0.7897\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4080 - acc: 0.7971 - val_loss: 0.4223 - val_acc: 0.7894\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4084 - acc: 0.7966 - val_loss: 0.4202 - val_acc: 0.7892\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4079 - acc: 0.7968 - val_loss: 0.4203 - val_acc: 0.7880\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4078 - acc: 0.7971 - val_loss: 0.4198 - val_acc: 0.7898\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4081 - acc: 0.7967 - val_loss: 0.4194 - val_acc: 0.7892\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4076 - acc: 0.7969 - val_loss: 0.4230 - val_acc: 0.7885\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4079 - acc: 0.7968 - val_loss: 0.4198 - val_acc: 0.7894\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4078 - acc: 0.7971 - val_loss: 0.4208 - val_acc: 0.7884\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4078 - acc: 0.7971 - val_loss: 0.4210 - val_acc: 0.7884\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4076 - acc: 0.7971 - val_loss: 0.4202 - val_acc: 0.7893\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4077 - acc: 0.7970 - val_loss: 0.4200 - val_acc: 0.7894\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4076 - acc: 0.7974 - val_loss: 0.4193 - val_acc: 0.7884\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4078 - acc: 0.7966 - val_loss: 0.4225 - val_acc: 0.7889\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4079 - acc: 0.7970 - val_loss: 0.4213 - val_acc: 0.7894\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4076 - acc: 0.7970 - val_loss: 0.4209 - val_acc: 0.7886\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4074 - acc: 0.7971 - val_loss: 0.4218 - val_acc: 0.7882\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4073 - acc: 0.7976 - val_loss: 0.4209 - val_acc: 0.7893\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4075 - acc: 0.7977 - val_loss: 0.4206 - val_acc: 0.7892\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4074 - acc: 0.7971 - val_loss: 0.4205 - val_acc: 0.7888\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4075 - acc: 0.7971 - val_loss: 0.4212 - val_acc: 0.7880\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4072 - acc: 0.7972 - val_loss: 0.4222 - val_acc: 0.7879\n"
     ]
    }
   ],
   "source": [
    "model, results = build_model(hidden_layers=[10, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_accuracy_train_and_val(results, '[10, 5]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7903045181459546"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_93 (Dense)             (None, 100)               22200     \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 27,301\n",
      "Trainable params: 27,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 4s 24us/step - loss: 0.4593 - acc: 0.7674 - val_loss: 0.4313 - val_acc: 0.7847\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4229 - acc: 0.7880 - val_loss: 0.4253 - val_acc: 0.7859\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4195 - acc: 0.7897 - val_loss: 0.4223 - val_acc: 0.7866\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4172 - acc: 0.7902 - val_loss: 0.4247 - val_acc: 0.7854\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4154 - acc: 0.7921 - val_loss: 0.4210 - val_acc: 0.7876\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4140 - acc: 0.7928 - val_loss: 0.4194 - val_acc: 0.7878\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4131 - acc: 0.7930 - val_loss: 0.4195 - val_acc: 0.7888\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4124 - acc: 0.7940 - val_loss: 0.4192 - val_acc: 0.7891\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4120 - acc: 0.7932 - val_loss: 0.4196 - val_acc: 0.7887\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4113 - acc: 0.7943 - val_loss: 0.4217 - val_acc: 0.7863\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4106 - acc: 0.7942 - val_loss: 0.4192 - val_acc: 0.7897\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4104 - acc: 0.7948 - val_loss: 0.4175 - val_acc: 0.7907\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4098 - acc: 0.7948 - val_loss: 0.4193 - val_acc: 0.7881\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4094 - acc: 0.7952 - val_loss: 0.4182 - val_acc: 0.7893\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4088 - acc: 0.7955 - val_loss: 0.4184 - val_acc: 0.7893\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4085 - acc: 0.7951 - val_loss: 0.4198 - val_acc: 0.7885\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4081 - acc: 0.7960 - val_loss: 0.4192 - val_acc: 0.7897\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4080 - acc: 0.7959 - val_loss: 0.4200 - val_acc: 0.7878\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4071 - acc: 0.7968 - val_loss: 0.4219 - val_acc: 0.7877\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4072 - acc: 0.7962 - val_loss: 0.4192 - val_acc: 0.7903\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4071 - acc: 0.7967 - val_loss: 0.4197 - val_acc: 0.7902\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4071 - acc: 0.7962 - val_loss: 0.4190 - val_acc: 0.7896\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4064 - acc: 0.7973 - val_loss: 0.4203 - val_acc: 0.7897\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4060 - acc: 0.7966 - val_loss: 0.4215 - val_acc: 0.7890\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4059 - acc: 0.7966 - val_loss: 0.4185 - val_acc: 0.7894\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4054 - acc: 0.7967 - val_loss: 0.4188 - val_acc: 0.7905\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4054 - acc: 0.7968 - val_loss: 0.4218 - val_acc: 0.7891\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4052 - acc: 0.7975 - val_loss: 0.4206 - val_acc: 0.7904\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4046 - acc: 0.7974 - val_loss: 0.4218 - val_acc: 0.7870\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4047 - acc: 0.7974 - val_loss: 0.4196 - val_acc: 0.7896\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4047 - acc: 0.7980 - val_loss: 0.4212 - val_acc: 0.7891\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4043 - acc: 0.7984 - val_loss: 0.4201 - val_acc: 0.7903\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4044 - acc: 0.7976 - val_loss: 0.4205 - val_acc: 0.7902\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4044 - acc: 0.7981 - val_loss: 0.4225 - val_acc: 0.7890\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4036 - acc: 0.7980 - val_loss: 0.4243 - val_acc: 0.7888\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4037 - acc: 0.7983 - val_loss: 0.4228 - val_acc: 0.7876\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4035 - acc: 0.7982 - val_loss: 0.4211 - val_acc: 0.7896\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4036 - acc: 0.7984 - val_loss: 0.4220 - val_acc: 0.7884\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4035 - acc: 0.7980 - val_loss: 0.4237 - val_acc: 0.7884\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4032 - acc: 0.7987 - val_loss: 0.4253 - val_acc: 0.7892\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4029 - acc: 0.7988 - val_loss: 0.4222 - val_acc: 0.7905\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4028 - acc: 0.7988 - val_loss: 0.4265 - val_acc: 0.7866\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4027 - acc: 0.7991 - val_loss: 0.4217 - val_acc: 0.7899\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4031 - acc: 0.7985 - val_loss: 0.4223 - val_acc: 0.7903\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4030 - acc: 0.7989 - val_loss: 0.4266 - val_acc: 0.7889\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4022 - acc: 0.7992 - val_loss: 0.4227 - val_acc: 0.7894\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4027 - acc: 0.7985 - val_loss: 0.4248 - val_acc: 0.7885\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4023 - acc: 0.7989 - val_loss: 0.4249 - val_acc: 0.7905\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4027 - acc: 0.7981 - val_loss: 0.4260 - val_acc: 0.7901\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4024 - acc: 0.7990 - val_loss: 0.4235 - val_acc: 0.7899\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4020 - acc: 0.7992 - val_loss: 0.4237 - val_acc: 0.7903\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4018 - acc: 0.7990 - val_loss: 0.4234 - val_acc: 0.7900\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4016 - acc: 0.7993 - val_loss: 0.4284 - val_acc: 0.7863\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4021 - acc: 0.7990 - val_loss: 0.4242 - val_acc: 0.7898\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4017 - acc: 0.7991 - val_loss: 0.4260 - val_acc: 0.7897\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4015 - acc: 0.7993 - val_loss: 0.4260 - val_acc: 0.7883\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4023 - acc: 0.7992 - val_loss: 0.4254 - val_acc: 0.7901\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4016 - acc: 0.7992 - val_loss: 0.4250 - val_acc: 0.7894\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4013 - acc: 0.7996 - val_loss: 0.4246 - val_acc: 0.7886\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4015 - acc: 0.7991 - val_loss: 0.4254 - val_acc: 0.7887\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4010 - acc: 0.7995 - val_loss: 0.4260 - val_acc: 0.7896\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4012 - acc: 0.7996 - val_loss: 0.4255 - val_acc: 0.7896\n"
     ]
    }
   ],
   "source": [
    "model2, results2 = build_model(hidden_layers=[100, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_accuracy_train_and_val(results2, '[100, 50]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7907352372570731"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results2.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_96 (Dense)             (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4505 - acc: 0.7715 - val_loss: 0.4282 - val_acc: 0.7849\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4235 - acc: 0.7866 - val_loss: 0.4240 - val_acc: 0.7866\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4193 - acc: 0.7897 - val_loss: 0.4222 - val_acc: 0.7863\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4180 - acc: 0.7903 - val_loss: 0.4232 - val_acc: 0.7857\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4168 - acc: 0.7914 - val_loss: 0.4265 - val_acc: 0.7857\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4155 - acc: 0.7918 - val_loss: 0.4216 - val_acc: 0.7868\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4145 - acc: 0.7928 - val_loss: 0.4220 - val_acc: 0.7876\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4145 - acc: 0.7924 - val_loss: 0.4200 - val_acc: 0.7892\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4134 - acc: 0.7942 - val_loss: 0.4203 - val_acc: 0.7883\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4129 - acc: 0.7935 - val_loss: 0.4188 - val_acc: 0.7895\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4125 - acc: 0.7938 - val_loss: 0.4196 - val_acc: 0.7880\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4128 - acc: 0.7934 - val_loss: 0.4210 - val_acc: 0.7890\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4124 - acc: 0.7939 - val_loss: 0.4207 - val_acc: 0.7869\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4119 - acc: 0.7940 - val_loss: 0.4202 - val_acc: 0.7877\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4116 - acc: 0.7938 - val_loss: 0.4189 - val_acc: 0.7887\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4117 - acc: 0.7943 - val_loss: 0.4209 - val_acc: 0.7903\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4115 - acc: 0.7947 - val_loss: 0.4188 - val_acc: 0.7908\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4112 - acc: 0.7940 - val_loss: 0.4191 - val_acc: 0.7890\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4110 - acc: 0.7946 - val_loss: 0.4191 - val_acc: 0.7899\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4110 - acc: 0.7945 - val_loss: 0.4204 - val_acc: 0.7889\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4108 - acc: 0.7946 - val_loss: 0.4189 - val_acc: 0.7900\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4102 - acc: 0.7949 - val_loss: 0.4193 - val_acc: 0.7895\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4102 - acc: 0.7951 - val_loss: 0.4186 - val_acc: 0.7899\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4101 - acc: 0.7948 - val_loss: 0.4199 - val_acc: 0.7904\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4103 - acc: 0.7948 - val_loss: 0.4199 - val_acc: 0.7908\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4098 - acc: 0.7949 - val_loss: 0.4204 - val_acc: 0.7901\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4097 - acc: 0.7947 - val_loss: 0.4195 - val_acc: 0.7918\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4096 - acc: 0.7950 - val_loss: 0.4191 - val_acc: 0.7905\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4093 - acc: 0.7949 - val_loss: 0.4195 - val_acc: 0.7899\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4092 - acc: 0.7957 - val_loss: 0.4190 - val_acc: 0.7906\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4099 - acc: 0.7957 - val_loss: 0.4193 - val_acc: 0.7914\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4089 - acc: 0.7956 - val_loss: 0.4181 - val_acc: 0.7908\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4091 - acc: 0.7955 - val_loss: 0.4184 - val_acc: 0.7906\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4090 - acc: 0.7960 - val_loss: 0.4191 - val_acc: 0.7897\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4086 - acc: 0.7958 - val_loss: 0.4186 - val_acc: 0.7896\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4087 - acc: 0.7955 - val_loss: 0.4185 - val_acc: 0.7909\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4090 - acc: 0.7954 - val_loss: 0.4181 - val_acc: 0.7902\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4085 - acc: 0.7961 - val_loss: 0.4201 - val_acc: 0.7894\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4089 - acc: 0.7949 - val_loss: 0.4178 - val_acc: 0.7913\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4080 - acc: 0.7967 - val_loss: 0.4197 - val_acc: 0.7904\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4081 - acc: 0.7966 - val_loss: 0.4208 - val_acc: 0.7906\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4084 - acc: 0.7956 - val_loss: 0.4193 - val_acc: 0.7909\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4083 - acc: 0.7963 - val_loss: 0.4188 - val_acc: 0.7910\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4079 - acc: 0.7961 - val_loss: 0.4183 - val_acc: 0.7909\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4082 - acc: 0.7959 - val_loss: 0.4231 - val_acc: 0.7914\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4082 - acc: 0.7961 - val_loss: 0.4185 - val_acc: 0.7916\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4079 - acc: 0.7959 - val_loss: 0.4205 - val_acc: 0.7906\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4079 - acc: 0.7966 - val_loss: 0.4192 - val_acc: 0.7894\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4078 - acc: 0.7962 - val_loss: 0.4201 - val_acc: 0.7912\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4077 - acc: 0.7962 - val_loss: 0.4200 - val_acc: 0.7896\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4073 - acc: 0.7970 - val_loss: 0.4193 - val_acc: 0.7908\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4075 - acc: 0.7966 - val_loss: 0.4201 - val_acc: 0.7911\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4074 - acc: 0.7969 - val_loss: 0.4199 - val_acc: 0.7903\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4071 - acc: 0.7972 - val_loss: 0.4201 - val_acc: 0.7900\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4077 - acc: 0.7964 - val_loss: 0.4193 - val_acc: 0.7900\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4072 - acc: 0.7967 - val_loss: 0.4208 - val_acc: 0.7914\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4075 - acc: 0.7968 - val_loss: 0.4200 - val_acc: 0.7911\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4070 - acc: 0.7971 - val_loss: 0.4224 - val_acc: 0.7882\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4072 - acc: 0.7970 - val_loss: 0.4183 - val_acc: 0.7911\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4071 - acc: 0.7966 - val_loss: 0.4193 - val_acc: 0.7913\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4068 - acc: 0.7969 - val_loss: 0.4199 - val_acc: 0.7913\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4071 - acc: 0.7968 - val_loss: 0.4201 - val_acc: 0.7914\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4073 - acc: 0.7963 - val_loss: 0.4215 - val_acc: 0.7908\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4067 - acc: 0.7967 - val_loss: 0.4202 - val_acc: 0.7906\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4071 - acc: 0.7976 - val_loss: 0.4216 - val_acc: 0.7912\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4068 - acc: 0.7976 - val_loss: 0.4212 - val_acc: 0.7909\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4068 - acc: 0.7972 - val_loss: 0.4208 - val_acc: 0.7904\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4066 - acc: 0.7971 - val_loss: 0.4197 - val_acc: 0.7909\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4067 - acc: 0.7969 - val_loss: 0.4219 - val_acc: 0.7902\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4064 - acc: 0.7971 - val_loss: 0.4218 - val_acc: 0.7894\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4067 - acc: 0.7971 - val_loss: 0.4209 - val_acc: 0.7911\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4066 - acc: 0.7973 - val_loss: 0.4239 - val_acc: 0.7914\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4064 - acc: 0.7976 - val_loss: 0.4239 - val_acc: 0.7883\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4067 - acc: 0.7976 - val_loss: 0.4241 - val_acc: 0.7909\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4063 - acc: 0.7979 - val_loss: 0.4193 - val_acc: 0.7910\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4064 - acc: 0.7974 - val_loss: 0.4218 - val_acc: 0.7893\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4062 - acc: 0.7969 - val_loss: 0.4238 - val_acc: 0.7883\n"
     ]
    }
   ],
   "source": [
    "model3, results3 = build_model(hidden_layers=[20, 15, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_accuracy_train_and_val(results3, '[20, 15, 10]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7918120342184727"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results3.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_100 (Dense)            (None, 200)               44400     \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 89,751\n",
      "Trainable params: 89,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 6s 34us/step - loss: 0.4632 - acc: 0.7726 - val_loss: 0.4275 - val_acc: 0.7841\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4221 - acc: 0.7878 - val_loss: 0.4250 - val_acc: 0.7867\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4186 - acc: 0.7899 - val_loss: 0.4216 - val_acc: 0.7863\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4177 - acc: 0.7902 - val_loss: 0.4204 - val_acc: 0.7869\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4165 - acc: 0.7908 - val_loss: 0.4217 - val_acc: 0.7868\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4159 - acc: 0.7917 - val_loss: 0.4199 - val_acc: 0.7892\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4148 - acc: 0.7920 - val_loss: 0.4207 - val_acc: 0.7866\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4141 - acc: 0.7922 - val_loss: 0.4204 - val_acc: 0.7879\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4139 - acc: 0.7924 - val_loss: 0.4204 - val_acc: 0.7887\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4133 - acc: 0.7932 - val_loss: 0.4233 - val_acc: 0.7873\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4128 - acc: 0.7934 - val_loss: 0.4195 - val_acc: 0.7887\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4120 - acc: 0.7947 - val_loss: 0.4212 - val_acc: 0.7873\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4122 - acc: 0.7939 - val_loss: 0.4275 - val_acc: 0.7872\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4108 - acc: 0.7950 - val_loss: 0.4233 - val_acc: 0.7880\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4107 - acc: 0.7944 - val_loss: 0.4224 - val_acc: 0.7868\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4100 - acc: 0.7954 - val_loss: 0.4210 - val_acc: 0.7895\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4098 - acc: 0.7952 - val_loss: 0.4202 - val_acc: 0.7900\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4091 - acc: 0.7958 - val_loss: 0.4231 - val_acc: 0.7888\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4091 - acc: 0.7959 - val_loss: 0.4264 - val_acc: 0.7856\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4089 - acc: 0.7959 - val_loss: 0.4237 - val_acc: 0.7883\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4077 - acc: 0.7970 - val_loss: 0.4227 - val_acc: 0.7889\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4081 - acc: 0.7960 - val_loss: 0.4235 - val_acc: 0.7879\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4077 - acc: 0.7961 - val_loss: 0.4226 - val_acc: 0.7895\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4077 - acc: 0.7963 - val_loss: 0.4257 - val_acc: 0.7878\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4068 - acc: 0.7970 - val_loss: 0.4285 - val_acc: 0.7877\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4068 - acc: 0.7969 - val_loss: 0.4223 - val_acc: 0.7906\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4067 - acc: 0.7969 - val_loss: 0.4226 - val_acc: 0.7888\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4062 - acc: 0.7968 - val_loss: 0.4232 - val_acc: 0.7886\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4059 - acc: 0.7975 - val_loss: 0.4213 - val_acc: 0.7907\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4058 - acc: 0.7976 - val_loss: 0.4216 - val_acc: 0.7891\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4052 - acc: 0.7976 - val_loss: 0.4287 - val_acc: 0.7867\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4056 - acc: 0.7978 - val_loss: 0.4263 - val_acc: 0.7879\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4050 - acc: 0.7976 - val_loss: 0.4233 - val_acc: 0.7898\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4050 - acc: 0.7980 - val_loss: 0.4225 - val_acc: 0.7895\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4048 - acc: 0.7979 - val_loss: 0.4241 - val_acc: 0.7895\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4049 - acc: 0.7977 - val_loss: 0.4262 - val_acc: 0.7865\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4041 - acc: 0.7977 - val_loss: 0.4249 - val_acc: 0.7895\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4042 - acc: 0.7978 - val_loss: 0.4239 - val_acc: 0.7897\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4041 - acc: 0.7980 - val_loss: 0.4237 - val_acc: 0.7884\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4038 - acc: 0.7985 - val_loss: 0.4273 - val_acc: 0.7897\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4041 - acc: 0.7978 - val_loss: 0.4248 - val_acc: 0.7874\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4040 - acc: 0.7986 - val_loss: 0.4293 - val_acc: 0.7847\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4039 - acc: 0.7985 - val_loss: 0.4254 - val_acc: 0.7896\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4035 - acc: 0.7985 - val_loss: 0.4255 - val_acc: 0.7872\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4033 - acc: 0.7990 - val_loss: 0.4254 - val_acc: 0.7891\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4033 - acc: 0.7985 - val_loss: 0.4279 - val_acc: 0.7895\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4030 - acc: 0.7990 - val_loss: 0.4261 - val_acc: 0.7878\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4029 - acc: 0.7984 - val_loss: 0.4282 - val_acc: 0.7899\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4031 - acc: 0.7986 - val_loss: 0.4287 - val_acc: 0.7903\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4026 - acc: 0.7988 - val_loss: 0.4303 - val_acc: 0.7889\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4027 - acc: 0.7990 - val_loss: 0.4284 - val_acc: 0.7888\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4025 - acc: 0.7985 - val_loss: 0.4281 - val_acc: 0.7884\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4026 - acc: 0.7989 - val_loss: 0.4281 - val_acc: 0.7892\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4024 - acc: 0.7994 - val_loss: 0.4268 - val_acc: 0.7900\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4024 - acc: 0.7987 - val_loss: 0.4296 - val_acc: 0.7892\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4022 - acc: 0.7994 - val_loss: 0.4329 - val_acc: 0.7893\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4020 - acc: 0.7990 - val_loss: 0.4280 - val_acc: 0.7899\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4017 - acc: 0.7993 - val_loss: 0.4284 - val_acc: 0.7895\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4020 - acc: 0.7994 - val_loss: 0.4341 - val_acc: 0.7888\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4018 - acc: 0.7994 - val_loss: 0.4343 - val_acc: 0.7879\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4021 - acc: 0.7994 - val_loss: 0.4286 - val_acc: 0.7900\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4017 - acc: 0.7993 - val_loss: 0.4307 - val_acc: 0.7908\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4020 - acc: 0.7995 - val_loss: 0.4331 - val_acc: 0.7860\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4015 - acc: 0.7993 - val_loss: 0.4387 - val_acc: 0.7886\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4016 - acc: 0.7997 - val_loss: 0.4354 - val_acc: 0.7885\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4009 - acc: 0.8000 - val_loss: 0.4312 - val_acc: 0.7888\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4020 - acc: 0.7993 - val_loss: 0.4284 - val_acc: 0.7894\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4013 - acc: 0.7997 - val_loss: 0.4298 - val_acc: 0.7906\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4007 - acc: 0.7995 - val_loss: 0.4352 - val_acc: 0.7903\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4005 - acc: 0.7998 - val_loss: 0.4379 - val_acc: 0.7851\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4012 - acc: 0.7998 - val_loss: 0.4300 - val_acc: 0.7910\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4008 - acc: 0.8000 - val_loss: 0.4323 - val_acc: 0.7900\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4004 - acc: 0.8000 - val_loss: 0.4340 - val_acc: 0.7891\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4005 - acc: 0.8002 - val_loss: 0.4314 - val_acc: 0.7887\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4007 - acc: 0.7999 - val_loss: 0.4310 - val_acc: 0.7899\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4012 - acc: 0.7996 - val_loss: 0.4348 - val_acc: 0.7880\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4008 - acc: 0.7999 - val_loss: 0.4314 - val_acc: 0.7898\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4003 - acc: 0.8005 - val_loss: 0.4379 - val_acc: 0.7885\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4003 - acc: 0.7998 - val_loss: 0.4357 - val_acc: 0.7896\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4000 - acc: 0.8000 - val_loss: 0.4386 - val_acc: 0.7868\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4009 - acc: 0.7997 - val_loss: 0.4345 - val_acc: 0.7891\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4004 - acc: 0.7999 - val_loss: 0.4348 - val_acc: 0.7896\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4002 - acc: 0.7999 - val_loss: 0.4367 - val_acc: 0.7909\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4000 - acc: 0.8003 - val_loss: 0.4375 - val_acc: 0.7876\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4003 - acc: 0.7996 - val_loss: 0.4355 - val_acc: 0.7895\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4001 - acc: 0.8007 - val_loss: 0.4383 - val_acc: 0.7899\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4001 - acc: 0.8000 - val_loss: 0.4393 - val_acc: 0.7886\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3995 - acc: 0.8005 - val_loss: 0.4383 - val_acc: 0.7889\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3999 - acc: 0.8003 - val_loss: 0.4351 - val_acc: 0.7892\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.4000 - acc: 0.8007 - val_loss: 0.4359 - val_acc: 0.7892\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3995 - acc: 0.8003 - val_loss: 0.4379 - val_acc: 0.7904\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3999 - acc: 0.8006 - val_loss: 0.4365 - val_acc: 0.7892\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3999 - acc: 0.8003 - val_loss: 0.4367 - val_acc: 0.7891\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3998 - acc: 0.8002 - val_loss: 0.4389 - val_acc: 0.7903\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3995 - acc: 0.8002 - val_loss: 0.4411 - val_acc: 0.7902\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3993 - acc: 0.8004 - val_loss: 0.4390 - val_acc: 0.7898\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3992 - acc: 0.8001 - val_loss: 0.4359 - val_acc: 0.7910\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3993 - acc: 0.8006 - val_loss: 0.4426 - val_acc: 0.7900\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3999 - acc: 0.8001 - val_loss: 0.4393 - val_acc: 0.7888\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3997 - acc: 0.8004 - val_loss: 0.4415 - val_acc: 0.7894\n",
      "Epoch 101/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3989 - acc: 0.8007 - val_loss: 0.4426 - val_acc: 0.7900\n",
      "Epoch 102/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3989 - acc: 0.8008 - val_loss: 0.4404 - val_acc: 0.7884\n",
      "Epoch 103/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3996 - acc: 0.8002 - val_loss: 0.4380 - val_acc: 0.7883\n",
      "Epoch 104/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3996 - acc: 0.8004 - val_loss: 0.4459 - val_acc: 0.7886\n",
      "Epoch 105/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3990 - acc: 0.8011 - val_loss: 0.4422 - val_acc: 0.7892\n",
      "Epoch 106/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3986 - acc: 0.8002 - val_loss: 0.4440 - val_acc: 0.7901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3994 - acc: 0.8004 - val_loss: 0.4402 - val_acc: 0.7902\n",
      "Epoch 108/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3992 - acc: 0.8011 - val_loss: 0.4420 - val_acc: 0.7892\n",
      "Epoch 109/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3992 - acc: 0.8002 - val_loss: 0.4408 - val_acc: 0.7869\n",
      "Epoch 110/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3991 - acc: 0.8002 - val_loss: 0.4441 - val_acc: 0.7902\n",
      "Epoch 111/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3984 - acc: 0.8011 - val_loss: 0.4467 - val_acc: 0.7906\n",
      "Epoch 112/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3986 - acc: 0.8008 - val_loss: 0.4444 - val_acc: 0.7891\n",
      "Epoch 113/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3985 - acc: 0.8005 - val_loss: 0.4440 - val_acc: 0.7893\n",
      "Epoch 114/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3987 - acc: 0.8007 - val_loss: 0.4436 - val_acc: 0.7891\n",
      "Epoch 115/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3986 - acc: 0.8007 - val_loss: 0.4494 - val_acc: 0.7881\n",
      "Epoch 116/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3993 - acc: 0.8000 - val_loss: 0.4462 - val_acc: 0.7894\n",
      "Epoch 117/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3985 - acc: 0.8007 - val_loss: 0.4396 - val_acc: 0.7906\n",
      "Epoch 118/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3988 - acc: 0.8007 - val_loss: 0.4451 - val_acc: 0.7888\n",
      "Epoch 119/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3996 - acc: 0.8002 - val_loss: 0.4439 - val_acc: 0.7891\n",
      "Epoch 120/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3986 - acc: 0.8009 - val_loss: 0.4423 - val_acc: 0.7902\n",
      "Epoch 121/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.3982 - acc: 0.8009 - val_loss: 0.4473 - val_acc: 0.7887\n"
     ]
    }
   ],
   "source": [
    "model4, results4 = build_model(hidden_layers=[200, 150, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_accuracy_train_and_val(results4, '[200, 150, 100]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7910367403170261"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results4.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_104 (Dense)            (None, 25)                5550      \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 20)                520       \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 6,556\n",
      "Trainable params: 6,556\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4564 - acc: 0.7665 - val_loss: 0.4296 - val_acc: 0.7823\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4216 - acc: 0.7889 - val_loss: 0.4231 - val_acc: 0.7860\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4183 - acc: 0.7900 - val_loss: 0.4222 - val_acc: 0.7855\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4169 - acc: 0.7913 - val_loss: 0.4214 - val_acc: 0.7863\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4151 - acc: 0.7924 - val_loss: 0.4207 - val_acc: 0.7872\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4143 - acc: 0.7925 - val_loss: 0.4209 - val_acc: 0.7885\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4141 - acc: 0.7930 - val_loss: 0.4202 - val_acc: 0.7877\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4132 - acc: 0.7942 - val_loss: 0.4198 - val_acc: 0.7872\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4128 - acc: 0.7937 - val_loss: 0.4229 - val_acc: 0.7854\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4124 - acc: 0.7940 - val_loss: 0.4216 - val_acc: 0.7867\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4117 - acc: 0.7954 - val_loss: 0.4214 - val_acc: 0.7866\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4113 - acc: 0.7950 - val_loss: 0.4203 - val_acc: 0.7871\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4111 - acc: 0.7951 - val_loss: 0.4219 - val_acc: 0.7866\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4109 - acc: 0.7956 - val_loss: 0.4206 - val_acc: 0.7869\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4102 - acc: 0.7957 - val_loss: 0.4217 - val_acc: 0.7880\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4099 - acc: 0.7955 - val_loss: 0.4245 - val_acc: 0.7875\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4096 - acc: 0.7953 - val_loss: 0.4212 - val_acc: 0.7873\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4096 - acc: 0.7956 - val_loss: 0.4228 - val_acc: 0.7859\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4093 - acc: 0.7958 - val_loss: 0.4204 - val_acc: 0.7880\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4088 - acc: 0.7963 - val_loss: 0.4230 - val_acc: 0.7866\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4086 - acc: 0.7965 - val_loss: 0.4229 - val_acc: 0.7876\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4081 - acc: 0.7966 - val_loss: 0.4242 - val_acc: 0.7868\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4082 - acc: 0.7965 - val_loss: 0.4232 - val_acc: 0.7876\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4081 - acc: 0.7966 - val_loss: 0.4262 - val_acc: 0.7848\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4076 - acc: 0.7968 - val_loss: 0.4226 - val_acc: 0.7873\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4075 - acc: 0.7970 - val_loss: 0.4239 - val_acc: 0.7872\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4076 - acc: 0.7965 - val_loss: 0.4227 - val_acc: 0.7870\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4071 - acc: 0.7974 - val_loss: 0.4229 - val_acc: 0.7886\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4070 - acc: 0.7968 - val_loss: 0.4238 - val_acc: 0.7879\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4069 - acc: 0.7972 - val_loss: 0.4246 - val_acc: 0.7875\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4069 - acc: 0.7973 - val_loss: 0.4225 - val_acc: 0.7876\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4063 - acc: 0.7977 - val_loss: 0.4240 - val_acc: 0.7877\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4065 - acc: 0.7972 - val_loss: 0.4231 - val_acc: 0.7891\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4061 - acc: 0.7974 - val_loss: 0.4243 - val_acc: 0.7878\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4063 - acc: 0.7981 - val_loss: 0.4240 - val_acc: 0.7873\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4059 - acc: 0.7973 - val_loss: 0.4255 - val_acc: 0.7877\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4058 - acc: 0.7975 - val_loss: 0.4284 - val_acc: 0.7850\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4057 - acc: 0.7977 - val_loss: 0.4259 - val_acc: 0.7889\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4061 - acc: 0.7973 - val_loss: 0.4243 - val_acc: 0.7878\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4053 - acc: 0.7980 - val_loss: 0.4254 - val_acc: 0.7882\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4051 - acc: 0.7983 - val_loss: 0.4270 - val_acc: 0.7877\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4054 - acc: 0.7974 - val_loss: 0.4249 - val_acc: 0.7886\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4052 - acc: 0.7982 - val_loss: 0.4259 - val_acc: 0.7887\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4051 - acc: 0.7979 - val_loss: 0.4260 - val_acc: 0.7878\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4047 - acc: 0.7983 - val_loss: 0.4283 - val_acc: 0.7872\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4047 - acc: 0.7986 - val_loss: 0.4282 - val_acc: 0.7881\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4050 - acc: 0.7979 - val_loss: 0.4295 - val_acc: 0.7869\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4049 - acc: 0.7981 - val_loss: 0.4269 - val_acc: 0.7881\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4049 - acc: 0.7982 - val_loss: 0.4269 - val_acc: 0.7877\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4039 - acc: 0.7988 - val_loss: 0.4271 - val_acc: 0.7888\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4042 - acc: 0.7986 - val_loss: 0.4259 - val_acc: 0.7876\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4040 - acc: 0.7978 - val_loss: 0.4293 - val_acc: 0.7887\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4042 - acc: 0.7987 - val_loss: 0.4288 - val_acc: 0.7885\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4041 - acc: 0.7983 - val_loss: 0.4274 - val_acc: 0.7886\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4037 - acc: 0.7987 - val_loss: 0.4279 - val_acc: 0.7889\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4035 - acc: 0.7991 - val_loss: 0.4272 - val_acc: 0.7879\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4037 - acc: 0.7989 - val_loss: 0.4290 - val_acc: 0.7881\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4037 - acc: 0.7989 - val_loss: 0.4292 - val_acc: 0.7877\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4036 - acc: 0.7981 - val_loss: 0.4274 - val_acc: 0.7878\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4031 - acc: 0.7991 - val_loss: 0.4279 - val_acc: 0.7869\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4033 - acc: 0.7988 - val_loss: 0.4282 - val_acc: 0.7878\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4031 - acc: 0.7996 - val_loss: 0.4275 - val_acc: 0.7881\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4030 - acc: 0.7994 - val_loss: 0.4282 - val_acc: 0.7886\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4032 - acc: 0.7995 - val_loss: 0.4276 - val_acc: 0.7878\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4031 - acc: 0.7998 - val_loss: 0.4302 - val_acc: 0.7874\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4031 - acc: 0.7991 - val_loss: 0.4298 - val_acc: 0.7861\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4033 - acc: 0.7985 - val_loss: 0.4290 - val_acc: 0.7892\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4030 - acc: 0.7991 - val_loss: 0.4279 - val_acc: 0.7885\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4030 - acc: 0.7991 - val_loss: 0.4286 - val_acc: 0.7889\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4029 - acc: 0.7989 - val_loss: 0.4314 - val_acc: 0.7888\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4027 - acc: 0.7992 - val_loss: 0.4310 - val_acc: 0.7885\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4026 - acc: 0.7994 - val_loss: 0.4288 - val_acc: 0.7886\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4029 - acc: 0.7994 - val_loss: 0.4284 - val_acc: 0.7890\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4023 - acc: 0.7995 - val_loss: 0.4285 - val_acc: 0.7886\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4026 - acc: 0.7995 - val_loss: 0.4273 - val_acc: 0.7889\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4028 - acc: 0.7990 - val_loss: 0.4273 - val_acc: 0.7889\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4025 - acc: 0.7995 - val_loss: 0.4311 - val_acc: 0.7880\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4022 - acc: 0.7994 - val_loss: 0.4298 - val_acc: 0.7884\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4020 - acc: 0.7999 - val_loss: 0.4286 - val_acc: 0.7890\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4023 - acc: 0.7996 - val_loss: 0.4292 - val_acc: 0.7879\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4020 - acc: 0.7993 - val_loss: 0.4300 - val_acc: 0.7883\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4022 - acc: 0.8002 - val_loss: 0.4287 - val_acc: 0.7889\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4025 - acc: 0.7994 - val_loss: 0.4300 - val_acc: 0.7885\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4020 - acc: 0.7993 - val_loss: 0.4295 - val_acc: 0.7889\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4018 - acc: 0.8000 - val_loss: 0.4303 - val_acc: 0.7886\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4017 - acc: 0.7995 - val_loss: 0.4342 - val_acc: 0.7895\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4019 - acc: 0.8002 - val_loss: 0.4313 - val_acc: 0.7890\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4017 - acc: 0.8001 - val_loss: 0.4353 - val_acc: 0.7879\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4021 - acc: 0.7995 - val_loss: 0.4310 - val_acc: 0.7886\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4019 - acc: 0.8002 - val_loss: 0.4324 - val_acc: 0.7882\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4014 - acc: 0.8007 - val_loss: 0.4345 - val_acc: 0.7891\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4018 - acc: 0.7995 - val_loss: 0.4341 - val_acc: 0.7893\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4015 - acc: 0.8003 - val_loss: 0.4346 - val_acc: 0.7874\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4017 - acc: 0.8001 - val_loss: 0.4301 - val_acc: 0.7887\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4017 - acc: 0.7999 - val_loss: 0.4318 - val_acc: 0.7889\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4016 - acc: 0.8000 - val_loss: 0.4352 - val_acc: 0.7880\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4016 - acc: 0.8003 - val_loss: 0.4326 - val_acc: 0.7879\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4012 - acc: 0.8000 - val_loss: 0.4327 - val_acc: 0.7885\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4014 - acc: 0.7995 - val_loss: 0.4342 - val_acc: 0.7875\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4013 - acc: 0.8002 - val_loss: 0.4386 - val_acc: 0.7880\n",
      "Epoch 101/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4016 - acc: 0.7993 - val_loss: 0.4373 - val_acc: 0.7889\n",
      "Epoch 102/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4015 - acc: 0.7999 - val_loss: 0.4364 - val_acc: 0.7887\n",
      "Epoch 103/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4011 - acc: 0.8005 - val_loss: 0.4372 - val_acc: 0.7870\n",
      "Epoch 104/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4016 - acc: 0.8002 - val_loss: 0.4342 - val_acc: 0.7882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4015 - acc: 0.7999 - val_loss: 0.4358 - val_acc: 0.7893\n",
      "Epoch 106/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4013 - acc: 0.7994 - val_loss: 0.4405 - val_acc: 0.7881\n",
      "Epoch 107/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4009 - acc: 0.8002 - val_loss: 0.4338 - val_acc: 0.7879\n",
      "Epoch 108/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4008 - acc: 0.8006 - val_loss: 0.4355 - val_acc: 0.7882\n",
      "Epoch 109/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4010 - acc: 0.8003 - val_loss: 0.4326 - val_acc: 0.7893\n",
      "Epoch 110/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4009 - acc: 0.8004 - val_loss: 0.4345 - val_acc: 0.7888\n",
      "Epoch 111/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4010 - acc: 0.8001 - val_loss: 0.4344 - val_acc: 0.7886\n",
      "Epoch 112/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4011 - acc: 0.8002 - val_loss: 0.4312 - val_acc: 0.7895\n",
      "Epoch 113/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4010 - acc: 0.8003 - val_loss: 0.4328 - val_acc: 0.7891\n",
      "Epoch 114/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4008 - acc: 0.8007 - val_loss: 0.4373 - val_acc: 0.7887\n",
      "Epoch 115/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4005 - acc: 0.8009 - val_loss: 0.4356 - val_acc: 0.7878\n",
      "Epoch 116/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4009 - acc: 0.8002 - val_loss: 0.4365 - val_acc: 0.7878\n",
      "Epoch 117/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4012 - acc: 0.7997 - val_loss: 0.4340 - val_acc: 0.7877\n",
      "Epoch 118/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4008 - acc: 0.8004 - val_loss: 0.4373 - val_acc: 0.7896\n",
      "Epoch 119/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4006 - acc: 0.8005 - val_loss: 0.4372 - val_acc: 0.7884\n",
      "Epoch 120/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4006 - acc: 0.8002 - val_loss: 0.4369 - val_acc: 0.7889\n",
      "Epoch 121/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4003 - acc: 0.8004 - val_loss: 0.4376 - val_acc: 0.7887\n",
      "Epoch 122/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4006 - acc: 0.8004 - val_loss: 0.4370 - val_acc: 0.7870\n",
      "Epoch 123/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4005 - acc: 0.8005 - val_loss: 0.4371 - val_acc: 0.7882\n",
      "Epoch 124/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4004 - acc: 0.8005 - val_loss: 0.4356 - val_acc: 0.7877\n",
      "Epoch 125/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4007 - acc: 0.8010 - val_loss: 0.4361 - val_acc: 0.7893\n",
      "Epoch 126/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4007 - acc: 0.8003 - val_loss: 0.4350 - val_acc: 0.7889\n",
      "Epoch 127/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4000 - acc: 0.8010 - val_loss: 0.4383 - val_acc: 0.7882\n",
      "Epoch 128/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4008 - acc: 0.8002 - val_loss: 0.4367 - val_acc: 0.7878\n",
      "Epoch 129/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4004 - acc: 0.8006 - val_loss: 0.4369 - val_acc: 0.7881\n",
      "Epoch 130/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4004 - acc: 0.8010 - val_loss: 0.4350 - val_acc: 0.7876\n",
      "Epoch 131/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4004 - acc: 0.8005 - val_loss: 0.4361 - val_acc: 0.7875\n",
      "Epoch 132/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4002 - acc: 0.8006 - val_loss: 0.4364 - val_acc: 0.7878\n",
      "Epoch 133/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4002 - acc: 0.8005 - val_loss: 0.4379 - val_acc: 0.7897\n",
      "Epoch 134/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4003 - acc: 0.8008 - val_loss: 0.4352 - val_acc: 0.7885\n",
      "Epoch 135/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4005 - acc: 0.8007 - val_loss: 0.4407 - val_acc: 0.7881\n",
      "Epoch 136/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4001 - acc: 0.8013 - val_loss: 0.4394 - val_acc: 0.7864\n",
      "Epoch 137/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4000 - acc: 0.8006 - val_loss: 0.4402 - val_acc: 0.7888\n",
      "Epoch 138/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4005 - acc: 0.8003 - val_loss: 0.4404 - val_acc: 0.7887\n",
      "Epoch 139/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4006 - acc: 0.8001 - val_loss: 0.4361 - val_acc: 0.7890\n",
      "Epoch 140/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4003 - acc: 0.8007 - val_loss: 0.4372 - val_acc: 0.7891\n",
      "Epoch 141/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4005 - acc: 0.8000 - val_loss: 0.4375 - val_acc: 0.7860\n",
      "Epoch 142/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4001 - acc: 0.8004 - val_loss: 0.4394 - val_acc: 0.7883\n",
      "Epoch 143/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4001 - acc: 0.8010 - val_loss: 0.4417 - val_acc: 0.7881\n",
      "Epoch 144/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4006 - acc: 0.7998 - val_loss: 0.4362 - val_acc: 0.7896\n",
      "Epoch 145/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4008 - acc: 0.8008 - val_loss: 0.4355 - val_acc: 0.7886\n",
      "Epoch 146/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4002 - acc: 0.8002 - val_loss: 0.4391 - val_acc: 0.7858\n",
      "Epoch 147/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3999 - acc: 0.8005 - val_loss: 0.4384 - val_acc: 0.7876\n",
      "Epoch 148/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4000 - acc: 0.8010 - val_loss: 0.4366 - val_acc: 0.7891\n",
      "Epoch 149/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4000 - acc: 0.8005 - val_loss: 0.4361 - val_acc: 0.7876\n",
      "Epoch 150/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4000 - acc: 0.8006 - val_loss: 0.4374 - val_acc: 0.7883\n",
      "Epoch 151/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3999 - acc: 0.8002 - val_loss: 0.4379 - val_acc: 0.7879\n",
      "Epoch 152/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3999 - acc: 0.8007 - val_loss: 0.4377 - val_acc: 0.7888\n",
      "Epoch 153/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4000 - acc: 0.8007 - val_loss: 0.4370 - val_acc: 0.7882\n",
      "Epoch 154/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4000 - acc: 0.8010 - val_loss: 0.4382 - val_acc: 0.7892\n",
      "Epoch 155/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4001 - acc: 0.8005 - val_loss: 0.4370 - val_acc: 0.7883\n",
      "Epoch 156/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3998 - acc: 0.8015 - val_loss: 0.4406 - val_acc: 0.7869\n",
      "Epoch 157/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3998 - acc: 0.8012 - val_loss: 0.4381 - val_acc: 0.7885\n",
      "Epoch 158/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3998 - acc: 0.8011 - val_loss: 0.4397 - val_acc: 0.7884\n",
      "Epoch 159/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3997 - acc: 0.8006 - val_loss: 0.4401 - val_acc: 0.7881\n",
      "Epoch 160/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4001 - acc: 0.8009 - val_loss: 0.4412 - val_acc: 0.7877\n",
      "Epoch 161/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3998 - acc: 0.8009 - val_loss: 0.4399 - val_acc: 0.7885\n",
      "Epoch 162/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4003 - acc: 0.8001 - val_loss: 0.4375 - val_acc: 0.7879\n",
      "Epoch 163/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3999 - acc: 0.8008 - val_loss: 0.4362 - val_acc: 0.7887\n",
      "Epoch 164/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3998 - acc: 0.8006 - val_loss: 0.4416 - val_acc: 0.7884\n",
      "Epoch 165/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3995 - acc: 0.8008 - val_loss: 0.4421 - val_acc: 0.7891\n",
      "Epoch 166/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3993 - acc: 0.8010 - val_loss: 0.4393 - val_acc: 0.7866\n",
      "Epoch 167/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3994 - acc: 0.8010 - val_loss: 0.4368 - val_acc: 0.7886\n",
      "Epoch 168/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3996 - acc: 0.8007 - val_loss: 0.4403 - val_acc: 0.7883\n",
      "Epoch 169/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3995 - acc: 0.8009 - val_loss: 0.4409 - val_acc: 0.7883\n",
      "Epoch 170/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3995 - acc: 0.8012 - val_loss: 0.4368 - val_acc: 0.7888\n",
      "Epoch 171/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3996 - acc: 0.8011 - val_loss: 0.4396 - val_acc: 0.7876\n",
      "Epoch 172/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3993 - acc: 0.8011 - val_loss: 0.4402 - val_acc: 0.7883\n",
      "Epoch 173/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3993 - acc: 0.8013 - val_loss: 0.4413 - val_acc: 0.7885\n",
      "Epoch 174/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3992 - acc: 0.8011 - val_loss: 0.4388 - val_acc: 0.7878\n",
      "Epoch 175/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4000 - acc: 0.8009 - val_loss: 0.4426 - val_acc: 0.7885\n",
      "Epoch 176/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4000 - acc: 0.8005 - val_loss: 0.4405 - val_acc: 0.7887\n",
      "Epoch 177/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3997 - acc: 0.8006 - val_loss: 0.4391 - val_acc: 0.7877\n",
      "Epoch 178/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4000 - acc: 0.8004 - val_loss: 0.4454 - val_acc: 0.7880\n",
      "Epoch 179/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3996 - acc: 0.8007 - val_loss: 0.4398 - val_acc: 0.7880\n",
      "Epoch 180/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3996 - acc: 0.8006 - val_loss: 0.4418 - val_acc: 0.7882\n",
      "Epoch 181/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3996 - acc: 0.8012 - val_loss: 0.4397 - val_acc: 0.7879\n",
      "Epoch 182/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3996 - acc: 0.8006 - val_loss: 0.4423 - val_acc: 0.7883\n",
      "Epoch 183/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3995 - acc: 0.8009 - val_loss: 0.4366 - val_acc: 0.7884\n"
     ]
    }
   ],
   "source": [
    "model5, results5 = build_model(hidden_layers=[25, 20, 15, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_accuracy_train_and_val(results5, '[25, 20, 15, 10]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7897230478206356"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results5.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_109 (Dense)            (None, 200)               44400     \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 150)               30150     \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 100)               15100     \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 94,751\n",
      "Trainable params: 94,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 7s 36us/step - loss: 0.4858 - acc: 0.7602 - val_loss: 0.4271 - val_acc: 0.7855\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4260 - acc: 0.7865 - val_loss: 0.4282 - val_acc: 0.7859\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4238 - acc: 0.7875 - val_loss: 0.4280 - val_acc: 0.7836\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4217 - acc: 0.7888 - val_loss: 0.4263 - val_acc: 0.7842\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4208 - acc: 0.7893 - val_loss: 0.4232 - val_acc: 0.7879\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4194 - acc: 0.7900 - val_loss: 0.4231 - val_acc: 0.7866\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4178 - acc: 0.7908 - val_loss: 0.4229 - val_acc: 0.7877\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4173 - acc: 0.7908 - val_loss: 0.4211 - val_acc: 0.7884\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4169 - acc: 0.7911 - val_loss: 0.4206 - val_acc: 0.7874\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4165 - acc: 0.7916 - val_loss: 0.4206 - val_acc: 0.7896\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4159 - acc: 0.7917 - val_loss: 0.4215 - val_acc: 0.7885\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4157 - acc: 0.7918 - val_loss: 0.4220 - val_acc: 0.7867\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4151 - acc: 0.7918 - val_loss: 0.4206 - val_acc: 0.7875\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4148 - acc: 0.7923 - val_loss: 0.4253 - val_acc: 0.7843\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4147 - acc: 0.7922 - val_loss: 0.4200 - val_acc: 0.7894\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4142 - acc: 0.7928 - val_loss: 0.4202 - val_acc: 0.7897\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4136 - acc: 0.7935 - val_loss: 0.4195 - val_acc: 0.7899\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4135 - acc: 0.7936 - val_loss: 0.4217 - val_acc: 0.7866\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4136 - acc: 0.7931 - val_loss: 0.4205 - val_acc: 0.7898\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4125 - acc: 0.7935 - val_loss: 0.4192 - val_acc: 0.7895\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4122 - acc: 0.7939 - val_loss: 0.4192 - val_acc: 0.7890\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4125 - acc: 0.7938 - val_loss: 0.4222 - val_acc: 0.7892\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4118 - acc: 0.7938 - val_loss: 0.4215 - val_acc: 0.7874\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4117 - acc: 0.7937 - val_loss: 0.4210 - val_acc: 0.7891\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4117 - acc: 0.7942 - val_loss: 0.4206 - val_acc: 0.7896\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4113 - acc: 0.7942 - val_loss: 0.4277 - val_acc: 0.7873\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 6s 31us/step - loss: 0.4113 - acc: 0.7946 - val_loss: 0.4224 - val_acc: 0.7890\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4106 - acc: 0.7946 - val_loss: 0.4222 - val_acc: 0.7901\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4110 - acc: 0.7942 - val_loss: 0.4202 - val_acc: 0.7899\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4105 - acc: 0.7946 - val_loss: 0.4223 - val_acc: 0.7887\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4104 - acc: 0.7949 - val_loss: 0.4215 - val_acc: 0.7880\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4100 - acc: 0.7946 - val_loss: 0.4223 - val_acc: 0.7887\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4102 - acc: 0.7952 - val_loss: 0.4202 - val_acc: 0.7894\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4099 - acc: 0.7951 - val_loss: 0.4229 - val_acc: 0.7870\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4095 - acc: 0.7949 - val_loss: 0.4205 - val_acc: 0.7899\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4095 - acc: 0.7958 - val_loss: 0.4224 - val_acc: 0.7882\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4094 - acc: 0.7954 - val_loss: 0.4217 - val_acc: 0.7894\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4094 - acc: 0.7957 - val_loss: 0.4275 - val_acc: 0.7877\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4092 - acc: 0.7950 - val_loss: 0.4258 - val_acc: 0.7884\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4089 - acc: 0.7955 - val_loss: 0.4224 - val_acc: 0.7894\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4094 - acc: 0.7946 - val_loss: 0.4225 - val_acc: 0.7888\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4087 - acc: 0.7957 - val_loss: 0.4214 - val_acc: 0.7893\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4087 - acc: 0.7956 - val_loss: 0.4216 - val_acc: 0.7903\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4083 - acc: 0.7952 - val_loss: 0.4223 - val_acc: 0.7890\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4086 - acc: 0.7953 - val_loss: 0.4237 - val_acc: 0.7879\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4082 - acc: 0.7955 - val_loss: 0.4253 - val_acc: 0.7879\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4084 - acc: 0.7953 - val_loss: 0.4226 - val_acc: 0.7888\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4079 - acc: 0.7955 - val_loss: 0.4237 - val_acc: 0.7899\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4081 - acc: 0.7959 - val_loss: 0.4232 - val_acc: 0.7886\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4077 - acc: 0.7961 - val_loss: 0.4241 - val_acc: 0.7898\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4081 - acc: 0.7955 - val_loss: 0.4246 - val_acc: 0.7884\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4079 - acc: 0.7959 - val_loss: 0.4230 - val_acc: 0.7890\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4075 - acc: 0.7957 - val_loss: 0.4277 - val_acc: 0.7889\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4075 - acc: 0.7961 - val_loss: 0.4243 - val_acc: 0.7873\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4075 - acc: 0.7963 - val_loss: 0.4243 - val_acc: 0.7895\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4075 - acc: 0.7963 - val_loss: 0.4232 - val_acc: 0.7889\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4073 - acc: 0.7961 - val_loss: 0.4251 - val_acc: 0.7904\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4078 - acc: 0.7955 - val_loss: 0.4228 - val_acc: 0.7888\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4072 - acc: 0.7959 - val_loss: 0.4249 - val_acc: 0.7895\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4067 - acc: 0.7965 - val_loss: 0.4241 - val_acc: 0.7893\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4068 - acc: 0.7960 - val_loss: 0.4264 - val_acc: 0.7888\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4067 - acc: 0.7962 - val_loss: 0.4264 - val_acc: 0.7890\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4065 - acc: 0.7969 - val_loss: 0.4263 - val_acc: 0.7884\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4068 - acc: 0.7965 - val_loss: 0.4254 - val_acc: 0.7881\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4070 - acc: 0.7960 - val_loss: 0.4287 - val_acc: 0.7888\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4063 - acc: 0.7970 - val_loss: 0.4265 - val_acc: 0.7893\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4063 - acc: 0.7964 - val_loss: 0.4227 - val_acc: 0.7883\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4067 - acc: 0.7966 - val_loss: 0.4257 - val_acc: 0.7898\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4068 - acc: 0.7962 - val_loss: 0.4247 - val_acc: 0.7901\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4064 - acc: 0.7967 - val_loss: 0.4313 - val_acc: 0.7903\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4066 - acc: 0.7968 - val_loss: 0.4270 - val_acc: 0.7892\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4066 - acc: 0.7964 - val_loss: 0.4262 - val_acc: 0.7890\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4069 - acc: 0.7968 - val_loss: 0.4256 - val_acc: 0.7897\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4059 - acc: 0.7970 - val_loss: 0.4259 - val_acc: 0.7892\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4061 - acc: 0.7969 - val_loss: 0.4259 - val_acc: 0.7891\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4057 - acc: 0.7972 - val_loss: 0.4252 - val_acc: 0.7899\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4058 - acc: 0.7971 - val_loss: 0.4280 - val_acc: 0.7900\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4063 - acc: 0.7970 - val_loss: 0.4271 - val_acc: 0.7885\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4060 - acc: 0.7971 - val_loss: 0.4348 - val_acc: 0.7881\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4059 - acc: 0.7966 - val_loss: 0.4301 - val_acc: 0.7889\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4060 - acc: 0.7971 - val_loss: 0.4278 - val_acc: 0.7862\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4058 - acc: 0.7970 - val_loss: 0.4286 - val_acc: 0.7891\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4062 - acc: 0.7973 - val_loss: 0.4256 - val_acc: 0.7891\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4062 - acc: 0.7967 - val_loss: 0.4270 - val_acc: 0.7896\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4054 - acc: 0.7970 - val_loss: 0.4279 - val_acc: 0.7880\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4056 - acc: 0.7968 - val_loss: 0.4276 - val_acc: 0.7890\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4056 - acc: 0.7967 - val_loss: 0.4278 - val_acc: 0.7894\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4056 - acc: 0.7967 - val_loss: 0.4309 - val_acc: 0.7875\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4056 - acc: 0.7971 - val_loss: 0.4290 - val_acc: 0.7887\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4053 - acc: 0.7971 - val_loss: 0.4286 - val_acc: 0.7894\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4050 - acc: 0.7970 - val_loss: 0.4299 - val_acc: 0.7883\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4061 - acc: 0.7966 - val_loss: 0.4331 - val_acc: 0.7893\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4058 - acc: 0.7970 - val_loss: 0.4299 - val_acc: 0.7897\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4052 - acc: 0.7975 - val_loss: 0.4268 - val_acc: 0.7887\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4053 - acc: 0.7978 - val_loss: 0.4288 - val_acc: 0.7864\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4052 - acc: 0.7970 - val_loss: 0.4346 - val_acc: 0.7878\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4052 - acc: 0.7973 - val_loss: 0.4312 - val_acc: 0.7881\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4055 - acc: 0.7968 - val_loss: 0.4293 - val_acc: 0.7887\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 6s 30us/step - loss: 0.4054 - acc: 0.7964 - val_loss: 0.4341 - val_acc: 0.7886\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4052 - acc: 0.7975 - val_loss: 0.4266 - val_acc: 0.7892\n",
      "Epoch 101/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4051 - acc: 0.7971 - val_loss: 0.4278 - val_acc: 0.7903\n",
      "Epoch 102/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4049 - acc: 0.7970 - val_loss: 0.4264 - val_acc: 0.7892\n",
      "Epoch 103/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4053 - acc: 0.7971 - val_loss: 0.4285 - val_acc: 0.7881\n",
      "Epoch 104/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4046 - acc: 0.7977 - val_loss: 0.4330 - val_acc: 0.7885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.4045 - acc: 0.7975 - val_loss: 0.4298 - val_acc: 0.7897\n",
      "Epoch 106/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4054 - acc: 0.7974 - val_loss: 0.4267 - val_acc: 0.7887\n",
      "Epoch 107/1000\n",
      "185736/185736 [==============================] - 5s 30us/step - loss: 0.4046 - acc: 0.7973 - val_loss: 0.4319 - val_acc: 0.7891\n"
     ]
    }
   ],
   "source": [
    "model6, results6 = build_model(hidden_layers=[200, 150, 100, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_accuracy_train_and_val(results6, '[200, 150, 100, 50]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7903906621612381"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results6.history['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4783 - acc: 0.7542 - val_loss: 0.4295 - val_acc: 0.7839\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4312 - acc: 0.7831 - val_loss: 0.4338 - val_acc: 0.7796\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4246 - acc: 0.7869 - val_loss: 0.4281 - val_acc: 0.7835\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4210 - acc: 0.7882 - val_loss: 0.4387 - val_acc: 0.7754\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4196 - acc: 0.7897 - val_loss: 0.4268 - val_acc: 0.7854\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4178 - acc: 0.7904 - val_loss: 0.4237 - val_acc: 0.7868\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4164 - acc: 0.7917 - val_loss: 0.4219 - val_acc: 0.7872\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4157 - acc: 0.7922 - val_loss: 0.4203 - val_acc: 0.7880\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4144 - acc: 0.7933 - val_loss: 0.4205 - val_acc: 0.7885\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4137 - acc: 0.7933 - val_loss: 0.4193 - val_acc: 0.7892\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4127 - acc: 0.7941 - val_loss: 0.4227 - val_acc: 0.7883\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4121 - acc: 0.7943 - val_loss: 0.4220 - val_acc: 0.7896\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4115 - acc: 0.7951 - val_loss: 0.4333 - val_acc: 0.7818\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4111 - acc: 0.7951 - val_loss: 0.4239 - val_acc: 0.7881\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4106 - acc: 0.7955 - val_loss: 0.4204 - val_acc: 0.7892\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4102 - acc: 0.7956 - val_loss: 0.4207 - val_acc: 0.7893\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4097 - acc: 0.7966 - val_loss: 0.4203 - val_acc: 0.7893\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4095 - acc: 0.7960 - val_loss: 0.4189 - val_acc: 0.7897\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4087 - acc: 0.7969 - val_loss: 0.4209 - val_acc: 0.7874\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4088 - acc: 0.7960 - val_loss: 0.4196 - val_acc: 0.7897\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4086 - acc: 0.7968 - val_loss: 0.4178 - val_acc: 0.7898\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4083 - acc: 0.7969 - val_loss: 0.4184 - val_acc: 0.7886\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4078 - acc: 0.7969 - val_loss: 0.4235 - val_acc: 0.7886\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4078 - acc: 0.7972 - val_loss: 0.4213 - val_acc: 0.7890\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4073 - acc: 0.7978 - val_loss: 0.4208 - val_acc: 0.7885\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4074 - acc: 0.7976 - val_loss: 0.4245 - val_acc: 0.7877\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4072 - acc: 0.7976 - val_loss: 0.4202 - val_acc: 0.7876\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4069 - acc: 0.7979 - val_loss: 0.4185 - val_acc: 0.7897\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4067 - acc: 0.7975 - val_loss: 0.4213 - val_acc: 0.7877\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4064 - acc: 0.7981 - val_loss: 0.4283 - val_acc: 0.7870\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4066 - acc: 0.7984 - val_loss: 0.4204 - val_acc: 0.7896\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4063 - acc: 0.7984 - val_loss: 0.4186 - val_acc: 0.7894\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4061 - acc: 0.7983 - val_loss: 0.4184 - val_acc: 0.7896\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4061 - acc: 0.7980 - val_loss: 0.4212 - val_acc: 0.7899\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4058 - acc: 0.7983 - val_loss: 0.4199 - val_acc: 0.7896\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4057 - acc: 0.7979 - val_loss: 0.4186 - val_acc: 0.7905\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4055 - acc: 0.7988 - val_loss: 0.4235 - val_acc: 0.7904\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4056 - acc: 0.7986 - val_loss: 0.4194 - val_acc: 0.7901\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4053 - acc: 0.7986 - val_loss: 0.4217 - val_acc: 0.7871\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4053 - acc: 0.7991 - val_loss: 0.4245 - val_acc: 0.7872\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4052 - acc: 0.7986 - val_loss: 0.4195 - val_acc: 0.7899\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4051 - acc: 0.7991 - val_loss: 0.4203 - val_acc: 0.7891\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4048 - acc: 0.7992 - val_loss: 0.4208 - val_acc: 0.7892\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4049 - acc: 0.7986 - val_loss: 0.4251 - val_acc: 0.7889\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4048 - acc: 0.7993 - val_loss: 0.4210 - val_acc: 0.7896\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4045 - acc: 0.7987 - val_loss: 0.4196 - val_acc: 0.7902\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4044 - acc: 0.7992 - val_loss: 0.4231 - val_acc: 0.7884\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4046 - acc: 0.7990 - val_loss: 0.4283 - val_acc: 0.7877\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4044 - acc: 0.7995 - val_loss: 0.4226 - val_acc: 0.7897\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4045 - acc: 0.7999 - val_loss: 0.4202 - val_acc: 0.7901\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4043 - acc: 0.7992 - val_loss: 0.4204 - val_acc: 0.7893\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4042 - acc: 0.7992 - val_loss: 0.4234 - val_acc: 0.7890\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4042 - acc: 0.7991 - val_loss: 0.4228 - val_acc: 0.7893\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4039 - acc: 0.7998 - val_loss: 0.4223 - val_acc: 0.7907\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4039 - acc: 0.7995 - val_loss: 0.4218 - val_acc: 0.7902\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4042 - acc: 0.7993 - val_loss: 0.4235 - val_acc: 0.7888\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4040 - acc: 0.7997 - val_loss: 0.4251 - val_acc: 0.7902\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4041 - acc: 0.7995 - val_loss: 0.4238 - val_acc: 0.7901\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4040 - acc: 0.7997 - val_loss: 0.4263 - val_acc: 0.7866\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4036 - acc: 0.8005 - val_loss: 0.4222 - val_acc: 0.7888\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4037 - acc: 0.7996 - val_loss: 0.4225 - val_acc: 0.7888\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4039 - acc: 0.7988 - val_loss: 0.4251 - val_acc: 0.7894\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4037 - acc: 0.7999 - val_loss: 0.4301 - val_acc: 0.7885\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4038 - acc: 0.8004 - val_loss: 0.4225 - val_acc: 0.7889\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4050 - acc: 0.7995 - val_loss: 0.4218 - val_acc: 0.7886\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4034 - acc: 0.7995 - val_loss: 0.4243 - val_acc: 0.7880\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4033 - acc: 0.7998 - val_loss: 0.4235 - val_acc: 0.7898\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4040 - acc: 0.7998 - val_loss: 0.4234 - val_acc: 0.7885\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4033 - acc: 0.7999 - val_loss: 0.4246 - val_acc: 0.7887\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4035 - acc: 0.8003 - val_loss: 0.4277 - val_acc: 0.7875\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4033 - acc: 0.8000 - val_loss: 0.4253 - val_acc: 0.7892\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4061 - acc: 0.7997 - val_loss: 0.4258 - val_acc: 0.7886\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4038 - acc: 0.7998 - val_loss: 0.4228 - val_acc: 0.7881\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4031 - acc: 0.7998 - val_loss: 0.4216 - val_acc: 0.7886\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4032 - acc: 0.8005 - val_loss: 0.4249 - val_acc: 0.7885\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4033 - acc: 0.8005 - val_loss: 0.4220 - val_acc: 0.7877\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4030 - acc: 0.8004 - val_loss: 0.4247 - val_acc: 0.7895\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4030 - acc: 0.8005 - val_loss: 0.4244 - val_acc: 0.7893\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4030 - acc: 0.8006 - val_loss: 0.4253 - val_acc: 0.7899\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4029 - acc: 0.8004 - val_loss: 0.4237 - val_acc: 0.7892\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4029 - acc: 0.8009 - val_loss: 0.4225 - val_acc: 0.7888\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4045 - acc: 0.8003 - val_loss: 0.4243 - val_acc: 0.7889\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4027 - acc: 0.8006 - val_loss: 0.4233 - val_acc: 0.7879\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4027 - acc: 0.8006 - val_loss: 0.4230 - val_acc: 0.7895\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4024 - acc: 0.8008 - val_loss: 0.4252 - val_acc: 0.7896\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4029 - acc: 0.8000 - val_loss: 0.4315 - val_acc: 0.7860\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4028 - acc: 0.8008 - val_loss: 0.4234 - val_acc: 0.7901\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4030 - acc: 0.8008 - val_loss: 0.4255 - val_acc: 0.7883\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4028 - acc: 0.8003 - val_loss: 0.4256 - val_acc: 0.7889\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4028 - acc: 0.8007 - val_loss: 0.4260 - val_acc: 0.7895\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4025 - acc: 0.8006 - val_loss: 0.4222 - val_acc: 0.7889\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4024 - acc: 0.8009 - val_loss: 0.4228 - val_acc: 0.7897\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4028 - acc: 0.8001 - val_loss: 0.4214 - val_acc: 0.7904\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4026 - acc: 0.8004 - val_loss: 0.4251 - val_acc: 0.7896\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4026 - acc: 0.8005 - val_loss: 0.4252 - val_acc: 0.7885\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4026 - acc: 0.8010 - val_loss: 0.4231 - val_acc: 0.7893\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4025 - acc: 0.8010 - val_loss: 0.4218 - val_acc: 0.7884\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4024 - acc: 0.8011 - val_loss: 0.4248 - val_acc: 0.7869\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4027 - acc: 0.8004 - val_loss: 0.4246 - val_acc: 0.7870\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4023 - acc: 0.8002 - val_loss: 0.4250 - val_acc: 0.7881\n",
      "Epoch 101/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4025 - acc: 0.8009 - val_loss: 0.4219 - val_acc: 0.7888\n",
      "Epoch 102/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4024 - acc: 0.8009 - val_loss: 0.4252 - val_acc: 0.7882\n",
      "Epoch 103/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4023 - acc: 0.8010 - val_loss: 0.4264 - val_acc: 0.7883\n",
      "Epoch 104/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4022 - acc: 0.8015 - val_loss: 0.4343 - val_acc: 0.7875\n"
     ]
    }
   ],
   "source": [
    "model7, results7 = build_model(hidden_layers=[20, 15, 10], optimizer=optimizers.RMSprop(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_accuracy_train_and_val(results7, '[20, 15, 10] with rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7907137011004988"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results7.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_118 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_92 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 4s 23us/step - loss: 0.6788 - acc: 0.5771 - val_loss: 0.6673 - val_acc: 0.5973\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.6616 - acc: 0.5949 - val_loss: 0.6548 - val_acc: 0.6006\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.6434 - acc: 0.6109 - val_loss: 0.6295 - val_acc: 0.6494\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.6058 - acc: 0.6832 - val_loss: 0.5806 - val_acc: 0.7104\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.5472 - acc: 0.7373 - val_loss: 0.5197 - val_acc: 0.7483\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4971 - acc: 0.7606 - val_loss: 0.4832 - val_acc: 0.7679\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4759 - acc: 0.7681 - val_loss: 0.4768 - val_acc: 0.7720\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4725 - acc: 0.7681 - val_loss: 0.4652 - val_acc: 0.7697\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4701 - acc: 0.7688 - val_loss: 0.4623 - val_acc: 0.7728\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4670 - acc: 0.7699 - val_loss: 0.4608 - val_acc: 0.7714\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4648 - acc: 0.7706 - val_loss: 0.4600 - val_acc: 0.7774\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4603 - acc: 0.7726 - val_loss: 0.4616 - val_acc: 0.7660\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4575 - acc: 0.7741 - val_loss: 0.4544 - val_acc: 0.7761\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4554 - acc: 0.7745 - val_loss: 0.4558 - val_acc: 0.7696\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4557 - acc: 0.7739 - val_loss: 0.4521 - val_acc: 0.7745\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4536 - acc: 0.7758 - val_loss: 0.4498 - val_acc: 0.7783\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4507 - acc: 0.7765 - val_loss: 0.4539 - val_acc: 0.7787\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4512 - acc: 0.7770 - val_loss: 0.4475 - val_acc: 0.7791\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4501 - acc: 0.7769 - val_loss: 0.4465 - val_acc: 0.7792\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4480 - acc: 0.7783 - val_loss: 0.4474 - val_acc: 0.7811\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4474 - acc: 0.7787 - val_loss: 0.4448 - val_acc: 0.7806\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4454 - acc: 0.7791 - val_loss: 0.4617 - val_acc: 0.7607\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4460 - acc: 0.7779 - val_loss: 0.4453 - val_acc: 0.7757\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4450 - acc: 0.7788 - val_loss: 0.4467 - val_acc: 0.7730\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4424 - acc: 0.7798 - val_loss: 0.4431 - val_acc: 0.7765\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4421 - acc: 0.7807 - val_loss: 0.4457 - val_acc: 0.7730\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4424 - acc: 0.7796 - val_loss: 0.4411 - val_acc: 0.7823\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4396 - acc: 0.7814 - val_loss: 0.4391 - val_acc: 0.7816\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4391 - acc: 0.7815 - val_loss: 0.4392 - val_acc: 0.7799\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4384 - acc: 0.7822 - val_loss: 0.4492 - val_acc: 0.7782\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4382 - acc: 0.7814 - val_loss: 0.4374 - val_acc: 0.7821\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4371 - acc: 0.7821 - val_loss: 0.4387 - val_acc: 0.7780\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4365 - acc: 0.7828 - val_loss: 0.4361 - val_acc: 0.7823\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4356 - acc: 0.7829 - val_loss: 0.4353 - val_acc: 0.7838\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4353 - acc: 0.7831 - val_loss: 0.4400 - val_acc: 0.7759\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4338 - acc: 0.7839 - val_loss: 0.4377 - val_acc: 0.7824\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4333 - acc: 0.7840 - val_loss: 0.4371 - val_acc: 0.7781\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4337 - acc: 0.7832 - val_loss: 0.4336 - val_acc: 0.7822\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4326 - acc: 0.7846 - val_loss: 0.4442 - val_acc: 0.7707\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4327 - acc: 0.7837 - val_loss: 0.4337 - val_acc: 0.7810\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4322 - acc: 0.7847 - val_loss: 0.4330 - val_acc: 0.7832\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4315 - acc: 0.7838 - val_loss: 0.4423 - val_acc: 0.7795\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4320 - acc: 0.7843 - val_loss: 0.4348 - val_acc: 0.7787\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4309 - acc: 0.7845 - val_loss: 0.4392 - val_acc: 0.7802\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4302 - acc: 0.7848 - val_loss: 0.4388 - val_acc: 0.7805\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4305 - acc: 0.7844 - val_loss: 0.4331 - val_acc: 0.7840\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4297 - acc: 0.7852 - val_loss: 0.4305 - val_acc: 0.7822\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4299 - acc: 0.7851 - val_loss: 0.4333 - val_acc: 0.7834\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4290 - acc: 0.7850 - val_loss: 0.4299 - val_acc: 0.7836\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4285 - acc: 0.7854 - val_loss: 0.4308 - val_acc: 0.7815\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4287 - acc: 0.7852 - val_loss: 0.4329 - val_acc: 0.7828\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4285 - acc: 0.7849 - val_loss: 0.4309 - val_acc: 0.7843\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4275 - acc: 0.7856 - val_loss: 0.4293 - val_acc: 0.7831\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4278 - acc: 0.7864 - val_loss: 0.4317 - val_acc: 0.7803\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4275 - acc: 0.7857 - val_loss: 0.4292 - val_acc: 0.7824\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4277 - acc: 0.7856 - val_loss: 0.4354 - val_acc: 0.7765\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4271 - acc: 0.7858 - val_loss: 0.4280 - val_acc: 0.7841\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4265 - acc: 0.7860 - val_loss: 0.4282 - val_acc: 0.7845\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4264 - acc: 0.7861 - val_loss: 0.4277 - val_acc: 0.7844\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4266 - acc: 0.7861 - val_loss: 0.4276 - val_acc: 0.7839\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4264 - acc: 0.7856 - val_loss: 0.4290 - val_acc: 0.7818\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4263 - acc: 0.7863 - val_loss: 0.4283 - val_acc: 0.7846\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4260 - acc: 0.7859 - val_loss: 0.4310 - val_acc: 0.7807\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4265 - acc: 0.7860 - val_loss: 0.4342 - val_acc: 0.7809\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4260 - acc: 0.7861 - val_loss: 0.4285 - val_acc: 0.7815\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4254 - acc: 0.7862 - val_loss: 0.4389 - val_acc: 0.7771\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4259 - acc: 0.7861 - val_loss: 0.4269 - val_acc: 0.7841\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4257 - acc: 0.7867 - val_loss: 0.4315 - val_acc: 0.7796\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4251 - acc: 0.7866 - val_loss: 0.4296 - val_acc: 0.7834\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4245 - acc: 0.7869 - val_loss: 0.4288 - val_acc: 0.7839\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4250 - acc: 0.7867 - val_loss: 0.4269 - val_acc: 0.7837\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4246 - acc: 0.7872 - val_loss: 0.4269 - val_acc: 0.7835\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4249 - acc: 0.7864 - val_loss: 0.4271 - val_acc: 0.7848\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4247 - acc: 0.7867 - val_loss: 0.4287 - val_acc: 0.7823\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4247 - acc: 0.7867 - val_loss: 0.4271 - val_acc: 0.7849\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4242 - acc: 0.7874 - val_loss: 0.4302 - val_acc: 0.7815\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4243 - acc: 0.7871 - val_loss: 0.4259 - val_acc: 0.7840\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4246 - acc: 0.7871 - val_loss: 0.4275 - val_acc: 0.7847\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4236 - acc: 0.7876 - val_loss: 0.4264 - val_acc: 0.7842\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4241 - acc: 0.7872 - val_loss: 0.4271 - val_acc: 0.7835\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4240 - acc: 0.7871 - val_loss: 0.4306 - val_acc: 0.7818\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4235 - acc: 0.7873 - val_loss: 0.4256 - val_acc: 0.7834\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4237 - acc: 0.7873 - val_loss: 0.4277 - val_acc: 0.7824\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4236 - acc: 0.7874 - val_loss: 0.4256 - val_acc: 0.7837\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4234 - acc: 0.7872 - val_loss: 0.4259 - val_acc: 0.7842\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4238 - acc: 0.7874 - val_loss: 0.4317 - val_acc: 0.7806\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4235 - acc: 0.7873 - val_loss: 0.4287 - val_acc: 0.7830\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4231 - acc: 0.7872 - val_loss: 0.4258 - val_acc: 0.7844\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4227 - acc: 0.7879 - val_loss: 0.4253 - val_acc: 0.7845\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4231 - acc: 0.7875 - val_loss: 0.4252 - val_acc: 0.7842\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4229 - acc: 0.7880 - val_loss: 0.4259 - val_acc: 0.7841\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4231 - acc: 0.7875 - val_loss: 0.4252 - val_acc: 0.7845\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4225 - acc: 0.7876 - val_loss: 0.4254 - val_acc: 0.7839\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4227 - acc: 0.7875 - val_loss: 0.4257 - val_acc: 0.7839\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4225 - acc: 0.7877 - val_loss: 0.4252 - val_acc: 0.7845\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4225 - acc: 0.7878 - val_loss: 0.4259 - val_acc: 0.7841\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4223 - acc: 0.7881 - val_loss: 0.4263 - val_acc: 0.7832\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4222 - acc: 0.7879 - val_loss: 0.4340 - val_acc: 0.7786\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4220 - acc: 0.7880 - val_loss: 0.4250 - val_acc: 0.7837\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4221 - acc: 0.7878 - val_loss: 0.4252 - val_acc: 0.7849\n",
      "Epoch 101/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4222 - acc: 0.7880 - val_loss: 0.4249 - val_acc: 0.7842\n",
      "Epoch 102/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4221 - acc: 0.7881 - val_loss: 0.4259 - val_acc: 0.7824\n",
      "Epoch 103/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4222 - acc: 0.7881 - val_loss: 0.4265 - val_acc: 0.7830\n",
      "Epoch 104/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4221 - acc: 0.7875 - val_loss: 0.4253 - val_acc: 0.7829\n",
      "Epoch 105/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4222 - acc: 0.7874 - val_loss: 0.4267 - val_acc: 0.7836\n",
      "Epoch 106/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4216 - acc: 0.7883 - val_loss: 0.4247 - val_acc: 0.7841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4218 - acc: 0.7877 - val_loss: 0.4246 - val_acc: 0.7844\n",
      "Epoch 108/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4218 - acc: 0.7883 - val_loss: 0.4249 - val_acc: 0.7854\n",
      "Epoch 109/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4219 - acc: 0.7882 - val_loss: 0.4248 - val_acc: 0.7845\n",
      "Epoch 110/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4216 - acc: 0.7883 - val_loss: 0.4255 - val_acc: 0.7831\n",
      "Epoch 111/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4217 - acc: 0.7874 - val_loss: 0.4249 - val_acc: 0.7836\n",
      "Epoch 112/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4214 - acc: 0.7889 - val_loss: 0.4256 - val_acc: 0.7840\n",
      "Epoch 113/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4219 - acc: 0.7884 - val_loss: 0.4253 - val_acc: 0.7843\n",
      "Epoch 114/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4212 - acc: 0.7887 - val_loss: 0.4260 - val_acc: 0.7834\n",
      "Epoch 115/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4214 - acc: 0.7889 - val_loss: 0.4265 - val_acc: 0.7834\n",
      "Epoch 116/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4212 - acc: 0.7882 - val_loss: 0.4248 - val_acc: 0.7841\n",
      "Epoch 117/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4212 - acc: 0.7887 - val_loss: 0.4249 - val_acc: 0.7832\n",
      "Epoch 118/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4212 - acc: 0.7889 - val_loss: 0.4333 - val_acc: 0.7788\n",
      "Epoch 119/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4209 - acc: 0.7886 - val_loss: 0.4243 - val_acc: 0.7835\n",
      "Epoch 120/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4209 - acc: 0.7889 - val_loss: 0.4261 - val_acc: 0.7827\n",
      "Epoch 121/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4212 - acc: 0.7880 - val_loss: 0.4276 - val_acc: 0.7830\n",
      "Epoch 122/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4212 - acc: 0.7884 - val_loss: 0.4242 - val_acc: 0.7843\n",
      "Epoch 123/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4209 - acc: 0.7888 - val_loss: 0.4275 - val_acc: 0.7818\n",
      "Epoch 124/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4207 - acc: 0.7888 - val_loss: 0.4247 - val_acc: 0.7835\n",
      "Epoch 125/1000\n",
      "185736/185736 [==============================] - 3s 14us/step - loss: 0.4208 - acc: 0.7887 - val_loss: 0.4241 - val_acc: 0.7839\n",
      "Epoch 126/1000\n",
      "185736/185736 [==============================] - 3s 14us/step - loss: 0.4211 - acc: 0.7885 - val_loss: 0.4255 - val_acc: 0.7839\n",
      "Epoch 127/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4206 - acc: 0.7887 - val_loss: 0.4306 - val_acc: 0.7815\n",
      "Epoch 128/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4206 - acc: 0.7889 - val_loss: 0.4248 - val_acc: 0.7833\n",
      "Epoch 129/1000\n",
      "185736/185736 [==============================] - 3s 15us/step - loss: 0.4206 - acc: 0.7884 - val_loss: 0.4241 - val_acc: 0.7850\n",
      "Epoch 130/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4204 - acc: 0.7889 - val_loss: 0.4245 - val_acc: 0.7845\n",
      "Epoch 131/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4204 - acc: 0.7893 - val_loss: 0.4243 - val_acc: 0.7843\n",
      "Epoch 132/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4207 - acc: 0.7889 - val_loss: 0.4257 - val_acc: 0.7824\n",
      "Epoch 133/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4204 - acc: 0.7888 - val_loss: 0.4290 - val_acc: 0.7818\n",
      "Epoch 134/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4201 - acc: 0.7892 - val_loss: 0.4250 - val_acc: 0.7847\n",
      "Epoch 135/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4204 - acc: 0.7890 - val_loss: 0.4240 - val_acc: 0.7840\n",
      "Epoch 136/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4200 - acc: 0.7892 - val_loss: 0.4251 - val_acc: 0.7827\n",
      "Epoch 137/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4202 - acc: 0.7890 - val_loss: 0.4268 - val_acc: 0.7810\n",
      "Epoch 138/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4199 - acc: 0.7888 - val_loss: 0.4251 - val_acc: 0.7832\n",
      "Epoch 139/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4204 - acc: 0.7887 - val_loss: 0.4263 - val_acc: 0.7831\n",
      "Epoch 140/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4201 - acc: 0.7893 - val_loss: 0.4240 - val_acc: 0.7838\n",
      "Epoch 141/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4200 - acc: 0.7890 - val_loss: 0.4240 - val_acc: 0.7851\n",
      "Epoch 142/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4199 - acc: 0.7890 - val_loss: 0.4249 - val_acc: 0.7842\n",
      "Epoch 143/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4200 - acc: 0.7895 - val_loss: 0.4237 - val_acc: 0.7847\n",
      "Epoch 144/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4201 - acc: 0.7890 - val_loss: 0.4254 - val_acc: 0.7846\n",
      "Epoch 145/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4199 - acc: 0.7893 - val_loss: 0.4255 - val_acc: 0.7837\n",
      "Epoch 146/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4199 - acc: 0.7888 - val_loss: 0.4276 - val_acc: 0.7829\n",
      "Epoch 147/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4196 - acc: 0.7893 - val_loss: 0.4266 - val_acc: 0.7816\n",
      "Epoch 148/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4196 - acc: 0.7893 - val_loss: 0.4256 - val_acc: 0.7847\n",
      "Epoch 149/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4198 - acc: 0.7892 - val_loss: 0.4236 - val_acc: 0.7841\n",
      "Epoch 150/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4197 - acc: 0.7894 - val_loss: 0.4235 - val_acc: 0.7847\n",
      "Epoch 151/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4196 - acc: 0.7897 - val_loss: 0.4244 - val_acc: 0.7841\n",
      "Epoch 152/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4195 - acc: 0.7893 - val_loss: 0.4240 - val_acc: 0.7847\n",
      "Epoch 153/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4199 - acc: 0.7889 - val_loss: 0.4251 - val_acc: 0.7840\n",
      "Epoch 154/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4196 - acc: 0.7892 - val_loss: 0.4241 - val_acc: 0.7845\n",
      "Epoch 155/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4195 - acc: 0.7894 - val_loss: 0.4233 - val_acc: 0.7854\n",
      "Epoch 156/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4197 - acc: 0.7894 - val_loss: 0.4244 - val_acc: 0.7847\n",
      "Epoch 157/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4197 - acc: 0.7890 - val_loss: 0.4236 - val_acc: 0.7854\n",
      "Epoch 158/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4194 - acc: 0.7897 - val_loss: 0.4243 - val_acc: 0.7844\n",
      "Epoch 159/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4195 - acc: 0.7890 - val_loss: 0.4234 - val_acc: 0.7847\n",
      "Epoch 160/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4193 - acc: 0.7895 - val_loss: 0.4254 - val_acc: 0.7831\n",
      "Epoch 161/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4192 - acc: 0.7896 - val_loss: 0.4234 - val_acc: 0.7847\n",
      "Epoch 162/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4193 - acc: 0.7897 - val_loss: 0.4283 - val_acc: 0.7822\n",
      "Epoch 163/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4192 - acc: 0.7897 - val_loss: 0.4259 - val_acc: 0.7837\n",
      "Epoch 164/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4192 - acc: 0.7896 - val_loss: 0.4239 - val_acc: 0.7851\n",
      "Epoch 165/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4190 - acc: 0.7895 - val_loss: 0.4268 - val_acc: 0.7837\n",
      "Epoch 166/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4190 - acc: 0.7898 - val_loss: 0.4232 - val_acc: 0.7847\n",
      "Epoch 167/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4188 - acc: 0.7901 - val_loss: 0.4230 - val_acc: 0.7855\n",
      "Epoch 168/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4189 - acc: 0.7896 - val_loss: 0.4306 - val_acc: 0.7794\n",
      "Epoch 169/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4187 - acc: 0.7903 - val_loss: 0.4247 - val_acc: 0.7850\n",
      "Epoch 170/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4191 - acc: 0.7896 - val_loss: 0.4275 - val_acc: 0.7826\n",
      "Epoch 171/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4190 - acc: 0.7896 - val_loss: 0.4234 - val_acc: 0.7859\n",
      "Epoch 172/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4189 - acc: 0.7900 - val_loss: 0.4275 - val_acc: 0.7828\n",
      "Epoch 173/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4187 - acc: 0.7901 - val_loss: 0.4232 - val_acc: 0.7861\n",
      "Epoch 174/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4188 - acc: 0.7900 - val_loss: 0.4284 - val_acc: 0.7818\n",
      "Epoch 175/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4188 - acc: 0.7894 - val_loss: 0.4229 - val_acc: 0.7847\n",
      "Epoch 176/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4186 - acc: 0.7896 - val_loss: 0.4230 - val_acc: 0.7848\n",
      "Epoch 177/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4185 - acc: 0.7896 - val_loss: 0.4231 - val_acc: 0.7856\n",
      "Epoch 178/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4184 - acc: 0.7903 - val_loss: 0.4295 - val_acc: 0.7816\n",
      "Epoch 179/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4186 - acc: 0.7902 - val_loss: 0.4249 - val_acc: 0.7837\n",
      "Epoch 180/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4186 - acc: 0.7900 - val_loss: 0.4237 - val_acc: 0.7844\n",
      "Epoch 181/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4185 - acc: 0.7900 - val_loss: 0.4230 - val_acc: 0.7849\n",
      "Epoch 182/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4187 - acc: 0.7901 - val_loss: 0.4236 - val_acc: 0.7858\n",
      "Epoch 183/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4187 - acc: 0.7899 - val_loss: 0.4228 - val_acc: 0.7854\n",
      "Epoch 184/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4186 - acc: 0.7897 - val_loss: 0.4226 - val_acc: 0.7856\n",
      "Epoch 185/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4186 - acc: 0.7897 - val_loss: 0.4253 - val_acc: 0.7846\n",
      "Epoch 186/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4183 - acc: 0.7898 - val_loss: 0.4227 - val_acc: 0.7859\n",
      "Epoch 187/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4184 - acc: 0.7899 - val_loss: 0.4229 - val_acc: 0.7861\n",
      "Epoch 188/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4183 - acc: 0.7904 - val_loss: 0.4239 - val_acc: 0.7837\n",
      "Epoch 189/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4182 - acc: 0.7902 - val_loss: 0.4244 - val_acc: 0.7843\n",
      "Epoch 190/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4184 - acc: 0.7902 - val_loss: 0.4230 - val_acc: 0.7855\n",
      "Epoch 191/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4181 - acc: 0.7905 - val_loss: 0.4225 - val_acc: 0.7859\n",
      "Epoch 192/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4182 - acc: 0.7901 - val_loss: 0.4228 - val_acc: 0.7850\n",
      "Epoch 193/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4180 - acc: 0.7910 - val_loss: 0.4275 - val_acc: 0.7828\n",
      "Epoch 194/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4182 - acc: 0.7901 - val_loss: 0.4259 - val_acc: 0.7828\n",
      "Epoch 195/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4181 - acc: 0.7899 - val_loss: 0.4230 - val_acc: 0.7845\n",
      "Epoch 196/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4180 - acc: 0.7905 - val_loss: 0.4222 - val_acc: 0.7864\n",
      "Epoch 197/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4180 - acc: 0.7900 - val_loss: 0.4227 - val_acc: 0.7855\n",
      "Epoch 198/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4182 - acc: 0.7906 - val_loss: 0.4226 - val_acc: 0.7856\n",
      "Epoch 199/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4179 - acc: 0.7900 - val_loss: 0.4225 - val_acc: 0.7855\n",
      "Epoch 200/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4180 - acc: 0.7903 - val_loss: 0.4224 - val_acc: 0.7861\n",
      "Epoch 201/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4179 - acc: 0.7903 - val_loss: 0.4236 - val_acc: 0.7850\n",
      "Epoch 202/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4177 - acc: 0.7906 - val_loss: 0.4223 - val_acc: 0.7859\n",
      "Epoch 203/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4178 - acc: 0.7901 - val_loss: 0.4223 - val_acc: 0.7853\n",
      "Epoch 204/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4177 - acc: 0.7906 - val_loss: 0.4223 - val_acc: 0.7868\n",
      "Epoch 205/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4177 - acc: 0.7900 - val_loss: 0.4221 - val_acc: 0.7869\n",
      "Epoch 206/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4179 - acc: 0.7905 - val_loss: 0.4224 - val_acc: 0.7854\n",
      "Epoch 207/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4178 - acc: 0.7899 - val_loss: 0.4264 - val_acc: 0.7827\n",
      "Epoch 208/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4176 - acc: 0.7902 - val_loss: 0.4236 - val_acc: 0.7844\n",
      "Epoch 209/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4176 - acc: 0.7904 - val_loss: 0.4221 - val_acc: 0.7848\n",
      "Epoch 210/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4177 - acc: 0.7906 - val_loss: 0.4224 - val_acc: 0.7865\n",
      "Epoch 211/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4175 - acc: 0.7904 - val_loss: 0.4220 - val_acc: 0.7862\n",
      "Epoch 212/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4177 - acc: 0.7903 - val_loss: 0.4260 - val_acc: 0.7835\n",
      "Epoch 213/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4174 - acc: 0.7903 - val_loss: 0.4222 - val_acc: 0.7859\n",
      "Epoch 214/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4175 - acc: 0.7900 - val_loss: 0.4226 - val_acc: 0.7859\n",
      "Epoch 215/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4173 - acc: 0.7911 - val_loss: 0.4229 - val_acc: 0.7864\n",
      "Epoch 216/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4175 - acc: 0.7902 - val_loss: 0.4250 - val_acc: 0.7851\n",
      "Epoch 217/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4175 - acc: 0.7906 - val_loss: 0.4224 - val_acc: 0.7857\n",
      "Epoch 218/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4171 - acc: 0.7907 - val_loss: 0.4251 - val_acc: 0.7839\n",
      "Epoch 219/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4172 - acc: 0.7908 - val_loss: 0.4235 - val_acc: 0.7848\n",
      "Epoch 220/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4178 - acc: 0.7905 - val_loss: 0.4229 - val_acc: 0.7863\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4173 - acc: 0.7913 - val_loss: 0.4223 - val_acc: 0.7854\n",
      "Epoch 222/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4176 - acc: 0.7900 - val_loss: 0.4264 - val_acc: 0.7830\n",
      "Epoch 223/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4172 - acc: 0.7904 - val_loss: 0.4236 - val_acc: 0.7850\n",
      "Epoch 224/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4173 - acc: 0.7910 - val_loss: 0.4228 - val_acc: 0.7858\n",
      "Epoch 225/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4168 - acc: 0.7910 - val_loss: 0.4316 - val_acc: 0.7802\n",
      "Epoch 226/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4170 - acc: 0.7908 - val_loss: 0.4243 - val_acc: 0.7845\n",
      "Epoch 227/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4173 - acc: 0.7909 - val_loss: 0.4218 - val_acc: 0.7876\n",
      "Epoch 228/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4171 - acc: 0.7910 - val_loss: 0.4225 - val_acc: 0.7857\n",
      "Epoch 229/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4170 - acc: 0.7902 - val_loss: 0.4215 - val_acc: 0.7871\n",
      "Epoch 230/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4169 - acc: 0.7905 - val_loss: 0.4224 - val_acc: 0.7861\n",
      "Epoch 231/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4171 - acc: 0.7910 - val_loss: 0.4221 - val_acc: 0.7862\n",
      "Epoch 232/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4169 - acc: 0.7910 - val_loss: 0.4217 - val_acc: 0.7868\n",
      "Epoch 233/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4169 - acc: 0.7909 - val_loss: 0.4231 - val_acc: 0.7850\n",
      "Epoch 234/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4168 - acc: 0.7907 - val_loss: 0.4221 - val_acc: 0.7868\n",
      "Epoch 235/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4168 - acc: 0.7905 - val_loss: 0.4224 - val_acc: 0.7866\n",
      "Epoch 236/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4167 - acc: 0.7910 - val_loss: 0.4214 - val_acc: 0.7875\n",
      "Epoch 237/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4167 - acc: 0.7909 - val_loss: 0.4213 - val_acc: 0.7864\n",
      "Epoch 238/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4167 - acc: 0.7913 - val_loss: 0.4234 - val_acc: 0.7850\n",
      "Epoch 239/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4170 - acc: 0.7911 - val_loss: 0.4217 - val_acc: 0.7849\n",
      "Epoch 240/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4165 - acc: 0.7917 - val_loss: 0.4238 - val_acc: 0.7855\n",
      "Epoch 241/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4166 - acc: 0.7913 - val_loss: 0.4223 - val_acc: 0.7857\n",
      "Epoch 242/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4169 - acc: 0.7907 - val_loss: 0.4214 - val_acc: 0.7874\n",
      "Epoch 243/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4166 - acc: 0.7911 - val_loss: 0.4224 - val_acc: 0.7854\n",
      "Epoch 244/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4166 - acc: 0.7909 - val_loss: 0.4254 - val_acc: 0.7838\n",
      "Epoch 245/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4165 - acc: 0.7912 - val_loss: 0.4216 - val_acc: 0.7871\n",
      "Epoch 246/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4164 - acc: 0.7913 - val_loss: 0.4213 - val_acc: 0.7863\n",
      "Epoch 247/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4165 - acc: 0.7912 - val_loss: 0.4247 - val_acc: 0.7836\n",
      "Epoch 248/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4165 - acc: 0.7910 - val_loss: 0.4231 - val_acc: 0.7856\n",
      "Epoch 249/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4166 - acc: 0.7907 - val_loss: 0.4214 - val_acc: 0.7869\n",
      "Epoch 250/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4165 - acc: 0.7912 - val_loss: 0.4238 - val_acc: 0.7854\n",
      "Epoch 251/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4165 - acc: 0.7906 - val_loss: 0.4243 - val_acc: 0.7852\n",
      "Epoch 252/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4163 - acc: 0.7920 - val_loss: 0.4224 - val_acc: 0.7871\n",
      "Epoch 253/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4163 - acc: 0.7914 - val_loss: 0.4226 - val_acc: 0.7870\n",
      "Epoch 254/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4164 - acc: 0.7908 - val_loss: 0.4223 - val_acc: 0.7864\n",
      "Epoch 255/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4164 - acc: 0.7909 - val_loss: 0.4218 - val_acc: 0.7878\n",
      "Epoch 256/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4159 - acc: 0.7918 - val_loss: 0.4212 - val_acc: 0.7864\n",
      "Epoch 257/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4162 - acc: 0.7914 - val_loss: 0.4250 - val_acc: 0.7847\n",
      "Epoch 258/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4161 - acc: 0.7916 - val_loss: 0.4209 - val_acc: 0.7877\n",
      "Epoch 259/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4163 - acc: 0.7914 - val_loss: 0.4281 - val_acc: 0.7811\n",
      "Epoch 260/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4163 - acc: 0.7918 - val_loss: 0.4212 - val_acc: 0.7877\n",
      "Epoch 261/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4161 - acc: 0.7920 - val_loss: 0.4224 - val_acc: 0.7873\n",
      "Epoch 262/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4161 - acc: 0.7914 - val_loss: 0.4236 - val_acc: 0.7842\n",
      "Epoch 263/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4160 - acc: 0.7908 - val_loss: 0.4226 - val_acc: 0.7851\n",
      "Epoch 264/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4160 - acc: 0.7914 - val_loss: 0.4211 - val_acc: 0.7864\n",
      "Epoch 265/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4158 - acc: 0.7916 - val_loss: 0.4215 - val_acc: 0.7865\n",
      "Epoch 266/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4159 - acc: 0.7917 - val_loss: 0.4209 - val_acc: 0.7885\n",
      "Epoch 267/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4161 - acc: 0.7915 - val_loss: 0.4215 - val_acc: 0.7881\n",
      "Epoch 268/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4158 - acc: 0.7912 - val_loss: 0.4210 - val_acc: 0.7879\n",
      "Epoch 269/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4158 - acc: 0.7916 - val_loss: 0.4212 - val_acc: 0.7868\n",
      "Epoch 270/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4157 - acc: 0.7917 - val_loss: 0.4218 - val_acc: 0.7892\n",
      "Epoch 271/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4159 - acc: 0.7912 - val_loss: 0.4220 - val_acc: 0.7865\n",
      "Epoch 272/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4157 - acc: 0.7918 - val_loss: 0.4221 - val_acc: 0.7863\n",
      "Epoch 273/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4157 - acc: 0.7919 - val_loss: 0.4220 - val_acc: 0.7872\n",
      "Epoch 274/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4156 - acc: 0.7914 - val_loss: 0.4233 - val_acc: 0.7849\n",
      "Epoch 275/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4156 - acc: 0.7915 - val_loss: 0.4213 - val_acc: 0.7874\n",
      "Epoch 276/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4158 - acc: 0.7920 - val_loss: 0.4214 - val_acc: 0.7881\n",
      "Epoch 277/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4156 - acc: 0.7916 - val_loss: 0.4218 - val_acc: 0.7869\n",
      "Epoch 278/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4157 - acc: 0.7915 - val_loss: 0.4241 - val_acc: 0.7853\n",
      "Epoch 279/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4158 - acc: 0.7915 - val_loss: 0.4216 - val_acc: 0.7872\n",
      "Epoch 280/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4155 - acc: 0.7919 - val_loss: 0.4230 - val_acc: 0.7856\n",
      "Epoch 281/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4156 - acc: 0.7910 - val_loss: 0.4209 - val_acc: 0.7866\n",
      "Epoch 282/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4157 - acc: 0.7917 - val_loss: 0.4204 - val_acc: 0.7879\n",
      "Epoch 283/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4155 - acc: 0.7921 - val_loss: 0.4207 - val_acc: 0.7869\n",
      "Epoch 284/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4155 - acc: 0.7917 - val_loss: 0.4235 - val_acc: 0.7851\n",
      "Epoch 285/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4153 - acc: 0.7914 - val_loss: 0.4202 - val_acc: 0.7889\n",
      "Epoch 286/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4154 - acc: 0.7914 - val_loss: 0.4222 - val_acc: 0.7869\n",
      "Epoch 287/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4152 - acc: 0.7918 - val_loss: 0.4224 - val_acc: 0.7857\n",
      "Epoch 288/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4154 - acc: 0.7918 - val_loss: 0.4223 - val_acc: 0.7887\n",
      "Epoch 289/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4154 - acc: 0.7915 - val_loss: 0.4268 - val_acc: 0.7830\n",
      "Epoch 290/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4155 - acc: 0.7915 - val_loss: 0.4206 - val_acc: 0.7883\n",
      "Epoch 291/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4153 - acc: 0.7921 - val_loss: 0.4216 - val_acc: 0.7877\n",
      "Epoch 292/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4152 - acc: 0.7920 - val_loss: 0.4212 - val_acc: 0.7878\n",
      "Epoch 293/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4154 - acc: 0.7912 - val_loss: 0.4209 - val_acc: 0.7880\n",
      "Epoch 294/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4154 - acc: 0.7919 - val_loss: 0.4234 - val_acc: 0.7851\n",
      "Epoch 295/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4153 - acc: 0.7915 - val_loss: 0.4211 - val_acc: 0.7883\n",
      "Epoch 296/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4152 - acc: 0.7916 - val_loss: 0.4205 - val_acc: 0.7890\n",
      "Epoch 297/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4149 - acc: 0.7921 - val_loss: 0.4252 - val_acc: 0.7838\n",
      "Epoch 298/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4150 - acc: 0.7917 - val_loss: 0.4205 - val_acc: 0.7883\n",
      "Epoch 299/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4151 - acc: 0.7923 - val_loss: 0.4201 - val_acc: 0.7891\n",
      "Epoch 300/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4151 - acc: 0.7923 - val_loss: 0.4243 - val_acc: 0.7846\n",
      "Epoch 301/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4151 - acc: 0.7918 - val_loss: 0.4221 - val_acc: 0.7879\n",
      "Epoch 302/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4149 - acc: 0.7919 - val_loss: 0.4200 - val_acc: 0.7882\n",
      "Epoch 303/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4148 - acc: 0.7921 - val_loss: 0.4252 - val_acc: 0.7835\n",
      "Epoch 304/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4151 - acc: 0.7916 - val_loss: 0.4216 - val_acc: 0.7875\n",
      "Epoch 305/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4150 - acc: 0.7923 - val_loss: 0.4198 - val_acc: 0.7885\n",
      "Epoch 306/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4149 - acc: 0.7925 - val_loss: 0.4233 - val_acc: 0.7861\n",
      "Epoch 307/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4150 - acc: 0.7920 - val_loss: 0.4244 - val_acc: 0.7848\n",
      "Epoch 308/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4149 - acc: 0.7921 - val_loss: 0.4236 - val_acc: 0.7846\n",
      "Epoch 309/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4149 - acc: 0.7925 - val_loss: 0.4236 - val_acc: 0.7850\n",
      "Epoch 310/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4147 - acc: 0.7920 - val_loss: 0.4237 - val_acc: 0.7869\n",
      "Epoch 311/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4149 - acc: 0.7921 - val_loss: 0.4197 - val_acc: 0.7891\n",
      "Epoch 312/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4150 - acc: 0.7919 - val_loss: 0.4198 - val_acc: 0.7884\n",
      "Epoch 313/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4147 - acc: 0.7925 - val_loss: 0.4208 - val_acc: 0.7887\n",
      "Epoch 314/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4148 - acc: 0.7925 - val_loss: 0.4199 - val_acc: 0.7889\n",
      "Epoch 315/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4148 - acc: 0.7924 - val_loss: 0.4202 - val_acc: 0.7875\n",
      "Epoch 316/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4147 - acc: 0.7921 - val_loss: 0.4242 - val_acc: 0.7848\n",
      "Epoch 317/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4146 - acc: 0.7923 - val_loss: 0.4201 - val_acc: 0.7894\n",
      "Epoch 318/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4145 - acc: 0.7917 - val_loss: 0.4216 - val_acc: 0.7870\n",
      "Epoch 319/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4147 - acc: 0.7918 - val_loss: 0.4200 - val_acc: 0.7880\n",
      "Epoch 320/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4146 - acc: 0.7921 - val_loss: 0.4199 - val_acc: 0.7894\n",
      "Epoch 321/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4145 - acc: 0.7922 - val_loss: 0.4198 - val_acc: 0.7885\n",
      "Epoch 322/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4145 - acc: 0.7926 - val_loss: 0.4218 - val_acc: 0.7871\n",
      "Epoch 323/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4145 - acc: 0.7923 - val_loss: 0.4205 - val_acc: 0.7876\n",
      "Epoch 324/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4145 - acc: 0.7918 - val_loss: 0.4237 - val_acc: 0.7851\n",
      "Epoch 325/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4142 - acc: 0.7921 - val_loss: 0.4195 - val_acc: 0.7903\n",
      "Epoch 326/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4145 - acc: 0.7924 - val_loss: 0.4229 - val_acc: 0.7854\n",
      "Epoch 327/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4142 - acc: 0.7929 - val_loss: 0.4213 - val_acc: 0.7876\n",
      "Epoch 328/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4143 - acc: 0.7926 - val_loss: 0.4199 - val_acc: 0.7894\n",
      "Epoch 329/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4145 - acc: 0.7919 - val_loss: 0.4194 - val_acc: 0.7888\n",
      "Epoch 330/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4141 - acc: 0.7929 - val_loss: 0.4198 - val_acc: 0.7902\n",
      "Epoch 331/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4144 - acc: 0.7927 - val_loss: 0.4194 - val_acc: 0.7903\n",
      "Epoch 332/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4144 - acc: 0.7924 - val_loss: 0.4199 - val_acc: 0.7882\n",
      "Epoch 333/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4142 - acc: 0.7925 - val_loss: 0.4206 - val_acc: 0.7881\n",
      "Epoch 334/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4144 - acc: 0.7925 - val_loss: 0.4195 - val_acc: 0.7887\n",
      "Epoch 335/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4140 - acc: 0.7922 - val_loss: 0.4202 - val_acc: 0.7894\n",
      "Epoch 336/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4144 - acc: 0.7929 - val_loss: 0.4207 - val_acc: 0.7877\n",
      "Epoch 337/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4142 - acc: 0.7925 - val_loss: 0.4200 - val_acc: 0.7875\n",
      "Epoch 338/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4140 - acc: 0.7931 - val_loss: 0.4193 - val_acc: 0.7895\n",
      "Epoch 339/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4141 - acc: 0.7927 - val_loss: 0.4201 - val_acc: 0.7891\n",
      "Epoch 340/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4140 - acc: 0.7928 - val_loss: 0.4192 - val_acc: 0.7900\n",
      "Epoch 341/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4141 - acc: 0.7927 - val_loss: 0.4199 - val_acc: 0.7877\n",
      "Epoch 342/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4138 - acc: 0.7931 - val_loss: 0.4199 - val_acc: 0.7888\n",
      "Epoch 343/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4138 - acc: 0.7929 - val_loss: 0.4212 - val_acc: 0.7876\n",
      "Epoch 344/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4139 - acc: 0.7925 - val_loss: 0.4211 - val_acc: 0.7875\n",
      "Epoch 345/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4138 - acc: 0.7929 - val_loss: 0.4271 - val_acc: 0.7816\n",
      "Epoch 346/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4138 - acc: 0.7925 - val_loss: 0.4193 - val_acc: 0.7907\n",
      "Epoch 347/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4138 - acc: 0.7927 - val_loss: 0.4195 - val_acc: 0.7893\n",
      "Epoch 348/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4139 - acc: 0.7925 - val_loss: 0.4200 - val_acc: 0.7877\n",
      "Epoch 349/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4139 - acc: 0.7930 - val_loss: 0.4192 - val_acc: 0.7901\n",
      "Epoch 350/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4139 - acc: 0.7926 - val_loss: 0.4192 - val_acc: 0.7892\n",
      "Epoch 351/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4139 - acc: 0.7929 - val_loss: 0.4198 - val_acc: 0.7903\n",
      "Epoch 352/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4138 - acc: 0.7932 - val_loss: 0.4189 - val_acc: 0.7906\n",
      "Epoch 353/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4137 - acc: 0.7933 - val_loss: 0.4189 - val_acc: 0.7892\n",
      "Epoch 354/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4136 - acc: 0.7931 - val_loss: 0.4197 - val_acc: 0.7889\n",
      "Epoch 355/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4137 - acc: 0.7930 - val_loss: 0.4194 - val_acc: 0.7889\n",
      "Epoch 356/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4138 - acc: 0.7932 - val_loss: 0.4201 - val_acc: 0.7884\n",
      "Epoch 357/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4137 - acc: 0.7930 - val_loss: 0.4205 - val_acc: 0.7885\n",
      "Epoch 358/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4135 - acc: 0.7933 - val_loss: 0.4207 - val_acc: 0.7884\n",
      "Epoch 359/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4137 - acc: 0.7928 - val_loss: 0.4193 - val_acc: 0.7889\n",
      "Epoch 360/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4137 - acc: 0.7927 - val_loss: 0.4197 - val_acc: 0.7878\n",
      "Epoch 361/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4134 - acc: 0.7929 - val_loss: 0.4199 - val_acc: 0.7892\n",
      "Epoch 362/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4134 - acc: 0.7930 - val_loss: 0.4189 - val_acc: 0.7897\n",
      "Epoch 363/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4135 - acc: 0.7932 - val_loss: 0.4200 - val_acc: 0.7881\n",
      "Epoch 364/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4133 - acc: 0.7936 - val_loss: 0.4198 - val_acc: 0.7886\n",
      "Epoch 365/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4133 - acc: 0.7931 - val_loss: 0.4201 - val_acc: 0.7887\n",
      "Epoch 366/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4134 - acc: 0.7932 - val_loss: 0.4209 - val_acc: 0.7897\n",
      "Epoch 367/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4133 - acc: 0.7936 - val_loss: 0.4195 - val_acc: 0.7884\n",
      "Epoch 368/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4133 - acc: 0.7931 - val_loss: 0.4193 - val_acc: 0.7884\n",
      "Epoch 369/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4131 - acc: 0.7932 - val_loss: 0.4184 - val_acc: 0.7902\n",
      "Epoch 370/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4133 - acc: 0.7934 - val_loss: 0.4188 - val_acc: 0.7902\n",
      "Epoch 371/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4133 - acc: 0.7935 - val_loss: 0.4205 - val_acc: 0.7879\n",
      "Epoch 372/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4134 - acc: 0.7928 - val_loss: 0.4190 - val_acc: 0.7891\n",
      "Epoch 373/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4130 - acc: 0.7933 - val_loss: 0.4213 - val_acc: 0.7879\n",
      "Epoch 374/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4131 - acc: 0.7939 - val_loss: 0.4185 - val_acc: 0.7895\n",
      "Epoch 375/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4130 - acc: 0.7937 - val_loss: 0.4196 - val_acc: 0.7895\n",
      "Epoch 376/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4133 - acc: 0.7930 - val_loss: 0.4190 - val_acc: 0.7903\n",
      "Epoch 377/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4129 - acc: 0.7934 - val_loss: 0.4195 - val_acc: 0.7891\n",
      "Epoch 378/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4130 - acc: 0.7937 - val_loss: 0.4206 - val_acc: 0.7877\n",
      "Epoch 379/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4131 - acc: 0.7936 - val_loss: 0.4193 - val_acc: 0.7907\n",
      "Epoch 380/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4131 - acc: 0.7938 - val_loss: 0.4203 - val_acc: 0.7877\n",
      "Epoch 381/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4129 - acc: 0.7931 - val_loss: 0.4190 - val_acc: 0.7889\n",
      "Epoch 382/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4129 - acc: 0.7934 - val_loss: 0.4188 - val_acc: 0.7894\n",
      "Epoch 383/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4130 - acc: 0.7933 - val_loss: 0.4209 - val_acc: 0.7872\n",
      "Epoch 384/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4128 - acc: 0.7937 - val_loss: 0.4190 - val_acc: 0.7896\n",
      "Epoch 385/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4129 - acc: 0.7939 - val_loss: 0.4192 - val_acc: 0.7887\n",
      "Epoch 386/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4128 - acc: 0.7932 - val_loss: 0.4191 - val_acc: 0.7901\n",
      "Epoch 387/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4127 - acc: 0.7938 - val_loss: 0.4191 - val_acc: 0.7887\n",
      "Epoch 388/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4127 - acc: 0.7939 - val_loss: 0.4206 - val_acc: 0.7868\n",
      "Epoch 389/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4127 - acc: 0.7942 - val_loss: 0.4182 - val_acc: 0.7908\n",
      "Epoch 390/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4126 - acc: 0.7937 - val_loss: 0.4188 - val_acc: 0.7893\n",
      "Epoch 391/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4127 - acc: 0.7939 - val_loss: 0.4191 - val_acc: 0.7901\n",
      "Epoch 392/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4128 - acc: 0.7934 - val_loss: 0.4187 - val_acc: 0.7902\n",
      "Epoch 393/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4126 - acc: 0.7935 - val_loss: 0.4181 - val_acc: 0.7903\n",
      "Epoch 394/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4126 - acc: 0.7939 - val_loss: 0.4221 - val_acc: 0.7854\n",
      "Epoch 395/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4127 - acc: 0.7935 - val_loss: 0.4185 - val_acc: 0.7904\n",
      "Epoch 396/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4124 - acc: 0.7943 - val_loss: 0.4189 - val_acc: 0.7908\n",
      "Epoch 397/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4126 - acc: 0.7938 - val_loss: 0.4183 - val_acc: 0.7903\n",
      "Epoch 398/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4125 - acc: 0.7940 - val_loss: 0.4184 - val_acc: 0.7899\n",
      "Epoch 399/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4124 - acc: 0.7939 - val_loss: 0.4185 - val_acc: 0.7904\n",
      "Epoch 400/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4123 - acc: 0.7939 - val_loss: 0.4190 - val_acc: 0.7888\n",
      "Epoch 401/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4126 - acc: 0.7941 - val_loss: 0.4207 - val_acc: 0.7882\n",
      "Epoch 402/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4125 - acc: 0.7939 - val_loss: 0.4182 - val_acc: 0.7909\n",
      "Epoch 403/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4124 - acc: 0.7940 - val_loss: 0.4213 - val_acc: 0.7880\n",
      "Epoch 404/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4124 - acc: 0.7941 - val_loss: 0.4187 - val_acc: 0.7894\n",
      "Epoch 405/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4124 - acc: 0.7939 - val_loss: 0.4187 - val_acc: 0.7889\n",
      "Epoch 406/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4123 - acc: 0.7944 - val_loss: 0.4211 - val_acc: 0.7872\n",
      "Epoch 407/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4122 - acc: 0.7940 - val_loss: 0.4183 - val_acc: 0.7900\n",
      "Epoch 408/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4123 - acc: 0.7940 - val_loss: 0.4181 - val_acc: 0.7904\n",
      "Epoch 409/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4123 - acc: 0.7936 - val_loss: 0.4192 - val_acc: 0.7895\n",
      "Epoch 410/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4124 - acc: 0.7943 - val_loss: 0.4186 - val_acc: 0.7897\n",
      "Epoch 411/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4123 - acc: 0.7941 - val_loss: 0.4194 - val_acc: 0.7882\n",
      "Epoch 412/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4123 - acc: 0.7938 - val_loss: 0.4197 - val_acc: 0.7889\n",
      "Epoch 413/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4121 - acc: 0.7938 - val_loss: 0.4188 - val_acc: 0.7902\n",
      "Epoch 414/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4119 - acc: 0.7943 - val_loss: 0.4189 - val_acc: 0.7889\n",
      "Epoch 415/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4120 - acc: 0.7942 - val_loss: 0.4186 - val_acc: 0.7896\n",
      "Epoch 416/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4121 - acc: 0.7942 - val_loss: 0.4182 - val_acc: 0.7893\n",
      "Epoch 417/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4121 - acc: 0.7943 - val_loss: 0.4181 - val_acc: 0.7912\n",
      "Epoch 418/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4120 - acc: 0.7942 - val_loss: 0.4190 - val_acc: 0.7893\n",
      "Epoch 419/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4120 - acc: 0.7943 - val_loss: 0.4184 - val_acc: 0.7891\n",
      "Epoch 420/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4121 - acc: 0.7945 - val_loss: 0.4187 - val_acc: 0.7896\n",
      "Epoch 421/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4120 - acc: 0.7945 - val_loss: 0.4199 - val_acc: 0.7889\n",
      "Epoch 422/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4119 - acc: 0.7940 - val_loss: 0.4178 - val_acc: 0.7901\n",
      "Epoch 423/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4118 - acc: 0.7949 - val_loss: 0.4188 - val_acc: 0.7892\n",
      "Epoch 424/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4117 - acc: 0.7942 - val_loss: 0.4196 - val_acc: 0.7881\n",
      "Epoch 425/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4121 - acc: 0.7944 - val_loss: 0.4184 - val_acc: 0.7906\n",
      "Epoch 426/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4119 - acc: 0.7943 - val_loss: 0.4194 - val_acc: 0.7886\n",
      "Epoch 427/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4118 - acc: 0.7950 - val_loss: 0.4200 - val_acc: 0.7882\n",
      "Epoch 428/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4118 - acc: 0.7942 - val_loss: 0.4185 - val_acc: 0.7896\n",
      "Epoch 429/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4120 - acc: 0.7942 - val_loss: 0.4206 - val_acc: 0.7884\n",
      "Epoch 430/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4118 - acc: 0.7946 - val_loss: 0.4184 - val_acc: 0.7890\n",
      "Epoch 431/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4120 - acc: 0.7947 - val_loss: 0.4181 - val_acc: 0.7903\n",
      "Epoch 432/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4117 - acc: 0.7942 - val_loss: 0.4201 - val_acc: 0.7884\n",
      "Epoch 433/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4118 - acc: 0.7946 - val_loss: 0.4179 - val_acc: 0.7898\n",
      "Epoch 434/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4119 - acc: 0.7943 - val_loss: 0.4180 - val_acc: 0.7906\n",
      "Epoch 435/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4119 - acc: 0.7944 - val_loss: 0.4183 - val_acc: 0.7898\n",
      "Epoch 436/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4119 - acc: 0.7942 - val_loss: 0.4180 - val_acc: 0.7901\n",
      "Epoch 437/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4116 - acc: 0.7942 - val_loss: 0.4227 - val_acc: 0.7863\n",
      "Epoch 438/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4117 - acc: 0.7938 - val_loss: 0.4188 - val_acc: 0.7883\n",
      "Epoch 439/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4115 - acc: 0.7947 - val_loss: 0.4183 - val_acc: 0.7905\n",
      "Epoch 440/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4117 - acc: 0.7946 - val_loss: 0.4177 - val_acc: 0.7907\n",
      "Epoch 441/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4116 - acc: 0.7945 - val_loss: 0.4210 - val_acc: 0.7883\n",
      "Epoch 442/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4116 - acc: 0.7946 - val_loss: 0.4177 - val_acc: 0.7904\n",
      "Epoch 443/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4113 - acc: 0.7951 - val_loss: 0.4189 - val_acc: 0.7911\n",
      "Epoch 444/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4116 - acc: 0.7943 - val_loss: 0.4194 - val_acc: 0.7885\n",
      "Epoch 445/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4116 - acc: 0.7944 - val_loss: 0.4175 - val_acc: 0.7908\n",
      "Epoch 446/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4114 - acc: 0.7945 - val_loss: 0.4176 - val_acc: 0.7912\n",
      "Epoch 447/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4115 - acc: 0.7945 - val_loss: 0.4178 - val_acc: 0.7909\n",
      "Epoch 448/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4115 - acc: 0.7947 - val_loss: 0.4177 - val_acc: 0.7905\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4115 - acc: 0.7947 - val_loss: 0.4219 - val_acc: 0.7877\n",
      "Epoch 450/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4118 - acc: 0.7949 - val_loss: 0.4177 - val_acc: 0.7910\n",
      "Epoch 451/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4115 - acc: 0.7948 - val_loss: 0.4189 - val_acc: 0.7891\n",
      "Epoch 452/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4113 - acc: 0.7946 - val_loss: 0.4213 - val_acc: 0.7867\n",
      "Epoch 453/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4113 - acc: 0.7949 - val_loss: 0.4193 - val_acc: 0.7890\n",
      "Epoch 454/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4113 - acc: 0.7945 - val_loss: 0.4188 - val_acc: 0.7906\n",
      "Epoch 455/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4114 - acc: 0.7944 - val_loss: 0.4179 - val_acc: 0.7900\n",
      "Epoch 456/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4113 - acc: 0.7945 - val_loss: 0.4177 - val_acc: 0.7901\n",
      "Epoch 457/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4113 - acc: 0.7949 - val_loss: 0.4189 - val_acc: 0.7889\n",
      "Epoch 458/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4113 - acc: 0.7949 - val_loss: 0.4202 - val_acc: 0.7885\n",
      "Epoch 459/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4113 - acc: 0.7943 - val_loss: 0.4202 - val_acc: 0.7882\n",
      "Epoch 460/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4112 - acc: 0.7945 - val_loss: 0.4183 - val_acc: 0.7899\n",
      "Epoch 461/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4113 - acc: 0.7946 - val_loss: 0.4186 - val_acc: 0.7898\n",
      "Epoch 462/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4112 - acc: 0.7941 - val_loss: 0.4194 - val_acc: 0.7893\n",
      "Epoch 463/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4111 - acc: 0.7945 - val_loss: 0.4176 - val_acc: 0.7910\n",
      "Epoch 464/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4111 - acc: 0.7953 - val_loss: 0.4211 - val_acc: 0.7877\n",
      "Epoch 465/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4113 - acc: 0.7944 - val_loss: 0.4207 - val_acc: 0.7872\n",
      "Epoch 466/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4110 - acc: 0.7946 - val_loss: 0.4298 - val_acc: 0.7806\n",
      "Epoch 467/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4112 - acc: 0.7945 - val_loss: 0.4186 - val_acc: 0.7902\n",
      "Epoch 468/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4112 - acc: 0.7945 - val_loss: 0.4188 - val_acc: 0.7897\n",
      "Epoch 469/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4111 - acc: 0.7945 - val_loss: 0.4179 - val_acc: 0.7899\n",
      "Epoch 470/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4111 - acc: 0.7950 - val_loss: 0.4182 - val_acc: 0.7894\n",
      "Epoch 471/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4113 - acc: 0.7943 - val_loss: 0.4195 - val_acc: 0.7884\n",
      "Epoch 472/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4111 - acc: 0.7945 - val_loss: 0.4183 - val_acc: 0.7893\n",
      "Epoch 473/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4112 - acc: 0.7947 - val_loss: 0.4198 - val_acc: 0.7893\n",
      "Epoch 474/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4110 - acc: 0.7953 - val_loss: 0.4206 - val_acc: 0.7877\n",
      "Epoch 475/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4108 - acc: 0.7951 - val_loss: 0.4214 - val_acc: 0.7871\n",
      "Epoch 476/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4109 - acc: 0.7953 - val_loss: 0.4201 - val_acc: 0.7885\n",
      "Epoch 477/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4110 - acc: 0.7949 - val_loss: 0.4186 - val_acc: 0.7899\n",
      "Epoch 478/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4109 - acc: 0.7944 - val_loss: 0.4185 - val_acc: 0.7903\n",
      "Epoch 479/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4112 - acc: 0.7948 - val_loss: 0.4203 - val_acc: 0.7883\n",
      "Epoch 480/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4110 - acc: 0.7945 - val_loss: 0.4190 - val_acc: 0.7890\n",
      "Epoch 481/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4109 - acc: 0.7948 - val_loss: 0.4173 - val_acc: 0.7908\n",
      "Epoch 482/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4108 - acc: 0.7949 - val_loss: 0.4188 - val_acc: 0.7884\n",
      "Epoch 483/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4107 - acc: 0.7949 - val_loss: 0.4193 - val_acc: 0.7888\n",
      "Epoch 484/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4110 - acc: 0.7947 - val_loss: 0.4180 - val_acc: 0.7903\n",
      "Epoch 485/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4108 - acc: 0.7948 - val_loss: 0.4190 - val_acc: 0.7891\n",
      "Epoch 486/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4108 - acc: 0.7955 - val_loss: 0.4179 - val_acc: 0.7904\n",
      "Epoch 487/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4107 - acc: 0.7955 - val_loss: 0.4184 - val_acc: 0.7892\n",
      "Epoch 488/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4105 - acc: 0.7953 - val_loss: 0.4192 - val_acc: 0.7878\n",
      "Epoch 489/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4109 - acc: 0.7948 - val_loss: 0.4177 - val_acc: 0.7901\n",
      "Epoch 490/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4107 - acc: 0.7952 - val_loss: 0.4188 - val_acc: 0.7905\n",
      "Epoch 491/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4107 - acc: 0.7947 - val_loss: 0.4203 - val_acc: 0.7888\n",
      "Epoch 492/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4106 - acc: 0.7948 - val_loss: 0.4182 - val_acc: 0.7903\n",
      "Epoch 493/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4108 - acc: 0.7945 - val_loss: 0.4181 - val_acc: 0.7893\n",
      "Epoch 494/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4108 - acc: 0.7946 - val_loss: 0.4179 - val_acc: 0.7910\n",
      "Epoch 495/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4108 - acc: 0.7955 - val_loss: 0.4177 - val_acc: 0.7897\n",
      "Epoch 496/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4106 - acc: 0.7951 - val_loss: 0.4174 - val_acc: 0.7909\n"
     ]
    }
   ],
   "source": [
    "model8, results8 = build_model(hidden_layers=[20,15,10], optimizer=optimizers.SGD(lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_accuracy_train_and_val(results8, '[20, 15, 10] with sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7912090278007615"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results8.history['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_208 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_158 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_159 (Dropout)        (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 7s 35us/step - loss: 0.4480 - acc: 0.7740 - val_loss: 0.4292 - val_acc: 0.7836\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4240 - acc: 0.7869 - val_loss: 0.4239 - val_acc: 0.7855\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4202 - acc: 0.7892 - val_loss: 0.4249 - val_acc: 0.7866\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4192 - acc: 0.7894 - val_loss: 0.4273 - val_acc: 0.7826\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4168 - acc: 0.7913 - val_loss: 0.4222 - val_acc: 0.7853\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4156 - acc: 0.7921 - val_loss: 0.4206 - val_acc: 0.7878\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4151 - acc: 0.7920 - val_loss: 0.4226 - val_acc: 0.7889\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 5s 24us/step - loss: 0.4144 - acc: 0.7922 - val_loss: 0.4196 - val_acc: 0.7891\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 5s 24us/step - loss: 0.4138 - acc: 0.7928 - val_loss: 0.4210 - val_acc: 0.7885\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4131 - acc: 0.7929 - val_loss: 0.4194 - val_acc: 0.7891\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 5s 24us/step - loss: 0.4123 - acc: 0.7940 - val_loss: 0.4210 - val_acc: 0.7898\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4113 - acc: 0.7935 - val_loss: 0.4192 - val_acc: 0.7899\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4110 - acc: 0.7943 - val_loss: 0.4211 - val_acc: 0.7882\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4103 - acc: 0.7947 - val_loss: 0.4243 - val_acc: 0.7870\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4095 - acc: 0.7950 - val_loss: 0.4196 - val_acc: 0.7888\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4093 - acc: 0.7951 - val_loss: 0.4233 - val_acc: 0.7880\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4088 - acc: 0.7960 - val_loss: 0.4213 - val_acc: 0.7888\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4084 - acc: 0.7963 - val_loss: 0.4201 - val_acc: 0.7888\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4080 - acc: 0.7959 - val_loss: 0.4187 - val_acc: 0.7903\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4074 - acc: 0.7962 - val_loss: 0.4192 - val_acc: 0.7903\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4073 - acc: 0.7966 - val_loss: 0.4189 - val_acc: 0.7890\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4068 - acc: 0.7962 - val_loss: 0.4248 - val_acc: 0.7874\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4064 - acc: 0.7972 - val_loss: 0.4194 - val_acc: 0.7902\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4062 - acc: 0.7966 - val_loss: 0.4203 - val_acc: 0.7904\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4056 - acc: 0.7975 - val_loss: 0.4194 - val_acc: 0.7905\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4056 - acc: 0.7976 - val_loss: 0.4279 - val_acc: 0.7873\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4054 - acc: 0.7973 - val_loss: 0.4232 - val_acc: 0.7886\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4051 - acc: 0.7979 - val_loss: 0.4206 - val_acc: 0.7903\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4049 - acc: 0.7979 - val_loss: 0.4219 - val_acc: 0.7888\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4048 - acc: 0.7982 - val_loss: 0.4209 - val_acc: 0.7897\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4049 - acc: 0.7981 - val_loss: 0.4226 - val_acc: 0.7899\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4040 - acc: 0.7982 - val_loss: 0.4219 - val_acc: 0.7887\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4041 - acc: 0.7985 - val_loss: 0.4227 - val_acc: 0.7903\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4041 - acc: 0.7978 - val_loss: 0.4240 - val_acc: 0.7884\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4035 - acc: 0.7982 - val_loss: 0.4253 - val_acc: 0.7879\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4040 - acc: 0.7984 - val_loss: 0.4220 - val_acc: 0.7896\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4033 - acc: 0.7985 - val_loss: 0.4237 - val_acc: 0.7887\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4034 - acc: 0.7983 - val_loss: 0.4212 - val_acc: 0.7904\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4033 - acc: 0.7984 - val_loss: 0.4237 - val_acc: 0.7893\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4028 - acc: 0.7990 - val_loss: 0.4240 - val_acc: 0.7880\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4028 - acc: 0.7988 - val_loss: 0.4230 - val_acc: 0.7876\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4026 - acc: 0.7995 - val_loss: 0.4250 - val_acc: 0.7898\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4024 - acc: 0.7989 - val_loss: 0.4248 - val_acc: 0.7863\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4025 - acc: 0.7994 - val_loss: 0.4250 - val_acc: 0.7909\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4023 - acc: 0.7986 - val_loss: 0.4231 - val_acc: 0.7893\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 5s 27us/step - loss: 0.4021 - acc: 0.7994 - val_loss: 0.4327 - val_acc: 0.7889\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4019 - acc: 0.7998 - val_loss: 0.4248 - val_acc: 0.7892\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4018 - acc: 0.7995 - val_loss: 0.4248 - val_acc: 0.7887\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4019 - acc: 0.7998 - val_loss: 0.4268 - val_acc: 0.7892\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 5s 27us/step - loss: 0.4018 - acc: 0.7997 - val_loss: 0.4249 - val_acc: 0.7890\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4019 - acc: 0.7995 - val_loss: 0.4266 - val_acc: 0.7891\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 5s 27us/step - loss: 0.4014 - acc: 0.7996 - val_loss: 0.4265 - val_acc: 0.7878\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4012 - acc: 0.7996 - val_loss: 0.4329 - val_acc: 0.7883\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4014 - acc: 0.7994 - val_loss: 0.4250 - val_acc: 0.7894\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4012 - acc: 0.7996 - val_loss: 0.4334 - val_acc: 0.7875\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 5s 27us/step - loss: 0.4013 - acc: 0.7997 - val_loss: 0.4264 - val_acc: 0.7882\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4009 - acc: 0.7997 - val_loss: 0.4274 - val_acc: 0.7872\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4006 - acc: 0.8000 - val_loss: 0.4261 - val_acc: 0.7875\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4009 - acc: 0.7998 - val_loss: 0.4291 - val_acc: 0.7885\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 5s 27us/step - loss: 0.4007 - acc: 0.8001 - val_loss: 0.4280 - val_acc: 0.7879\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4004 - acc: 0.8005 - val_loss: 0.4282 - val_acc: 0.7883\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.4002 - acc: 0.8000 - val_loss: 0.4262 - val_acc: 0.7885\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4007 - acc: 0.7993 - val_loss: 0.4278 - val_acc: 0.7887\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4002 - acc: 0.8005 - val_loss: 0.4277 - val_acc: 0.7891\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4005 - acc: 0.8000 - val_loss: 0.4270 - val_acc: 0.7881\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4000 - acc: 0.7996 - val_loss: 0.4274 - val_acc: 0.7889\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4001 - acc: 0.7998 - val_loss: 0.4298 - val_acc: 0.7891\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 5s 27us/step - loss: 0.4000 - acc: 0.8000 - val_loss: 0.4248 - val_acc: 0.7892\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 5s 27us/step - loss: 0.3999 - acc: 0.8002 - val_loss: 0.4299 - val_acc: 0.7882\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 5s 27us/step - loss: 0.4001 - acc: 0.8002 - val_loss: 0.4289 - val_acc: 0.7888\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.3997 - acc: 0.7999 - val_loss: 0.4310 - val_acc: 0.7884\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.3999 - acc: 0.8005 - val_loss: 0.4281 - val_acc: 0.7892\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.3995 - acc: 0.8003 - val_loss: 0.4277 - val_acc: 0.7890\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.3997 - acc: 0.8003 - val_loss: 0.4313 - val_acc: 0.7884\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.3996 - acc: 0.8003 - val_loss: 0.4312 - val_acc: 0.7894\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.3991 - acc: 0.7999 - val_loss: 0.4330 - val_acc: 0.7887\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.3993 - acc: 0.8007 - val_loss: 0.4315 - val_acc: 0.7893\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.3992 - acc: 0.8003 - val_loss: 0.4271 - val_acc: 0.7883\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.3994 - acc: 0.8003 - val_loss: 0.4351 - val_acc: 0.7896\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.3994 - acc: 0.8003 - val_loss: 0.4308 - val_acc: 0.7883\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.3991 - acc: 0.8000 - val_loss: 0.4332 - val_acc: 0.7888\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.3993 - acc: 0.8006 - val_loss: 0.4296 - val_acc: 0.7883\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.3993 - acc: 0.8008 - val_loss: 0.4349 - val_acc: 0.7872\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.3993 - acc: 0.8006 - val_loss: 0.4301 - val_acc: 0.7886\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 5s 24us/step - loss: 0.3987 - acc: 0.8005 - val_loss: 0.4312 - val_acc: 0.7882\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 5s 24us/step - loss: 0.3989 - acc: 0.8010 - val_loss: 0.4351 - val_acc: 0.7885\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.3985 - acc: 0.8008 - val_loss: 0.4322 - val_acc: 0.7885\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.3987 - acc: 0.8008 - val_loss: 0.4402 - val_acc: 0.7888\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 5s 27us/step - loss: 0.3988 - acc: 0.8005 - val_loss: 0.4361 - val_acc: 0.7875\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.3988 - acc: 0.8004 - val_loss: 0.4351 - val_acc: 0.7883\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 5s 27us/step - loss: 0.3987 - acc: 0.8008 - val_loss: 0.4334 - val_acc: 0.7895\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.3989 - acc: 0.8005 - val_loss: 0.4316 - val_acc: 0.7889\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.3985 - acc: 0.8015 - val_loss: 0.4355 - val_acc: 0.7877\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.3983 - acc: 0.8013 - val_loss: 0.4319 - val_acc: 0.7894\n"
     ]
    }
   ],
   "source": [
    "model9, results9 = build_model(hidden_layers=[20, 15, 10], batch_size=256, file_name='model9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7908644527254648"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results9.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_212 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_161 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_162 (Dropout)        (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_163 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 10s 51us/step - loss: 0.4400 - acc: 0.7774 - val_loss: 0.4255 - val_acc: 0.7861\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4216 - acc: 0.7891 - val_loss: 0.4238 - val_acc: 0.7879\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4196 - acc: 0.7905 - val_loss: 0.4256 - val_acc: 0.7879\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4178 - acc: 0.7909 - val_loss: 0.4247 - val_acc: 0.7853\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4168 - acc: 0.7914 - val_loss: 0.4215 - val_acc: 0.7855\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4163 - acc: 0.7910 - val_loss: 0.4221 - val_acc: 0.7876\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4155 - acc: 0.7918 - val_loss: 0.4241 - val_acc: 0.7871\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4147 - acc: 0.7926 - val_loss: 0.4219 - val_acc: 0.7883\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4142 - acc: 0.7930 - val_loss: 0.4208 - val_acc: 0.7889\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4140 - acc: 0.7928 - val_loss: 0.4202 - val_acc: 0.7879\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4133 - acc: 0.7932 - val_loss: 0.4237 - val_acc: 0.7885\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 8s 43us/step - loss: 0.4127 - acc: 0.7936 - val_loss: 0.4216 - val_acc: 0.7883\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4126 - acc: 0.7935 - val_loss: 0.4224 - val_acc: 0.7880\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4128 - acc: 0.7938 - val_loss: 0.4232 - val_acc: 0.7862\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4120 - acc: 0.7940 - val_loss: 0.4198 - val_acc: 0.7896\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4119 - acc: 0.7945 - val_loss: 0.4229 - val_acc: 0.7866\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4116 - acc: 0.7945 - val_loss: 0.4207 - val_acc: 0.7893\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4111 - acc: 0.7948 - val_loss: 0.4203 - val_acc: 0.7878\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4111 - acc: 0.7947 - val_loss: 0.4206 - val_acc: 0.7874\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4113 - acc: 0.7943 - val_loss: 0.4210 - val_acc: 0.7894\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 8s 40us/step - loss: 0.4107 - acc: 0.7955 - val_loss: 0.4227 - val_acc: 0.7872\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4106 - acc: 0.7952 - val_loss: 0.4218 - val_acc: 0.7887\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4106 - acc: 0.7947 - val_loss: 0.4218 - val_acc: 0.7876\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4102 - acc: 0.7952 - val_loss: 0.4235 - val_acc: 0.7858\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 8s 43us/step - loss: 0.4101 - acc: 0.7954 - val_loss: 0.4237 - val_acc: 0.7890\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4103 - acc: 0.7956 - val_loss: 0.4215 - val_acc: 0.7879\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4098 - acc: 0.7951 - val_loss: 0.4217 - val_acc: 0.7898\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4097 - acc: 0.7953 - val_loss: 0.4210 - val_acc: 0.7894\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4095 - acc: 0.7960 - val_loss: 0.4201 - val_acc: 0.7885\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 7s 40us/step - loss: 0.4096 - acc: 0.7955 - val_loss: 0.4232 - val_acc: 0.7898\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4089 - acc: 0.7972 - val_loss: 0.4224 - val_acc: 0.7869\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 7s 40us/step - loss: 0.4093 - acc: 0.7958 - val_loss: 0.4210 - val_acc: 0.7899\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 8s 40us/step - loss: 0.4096 - acc: 0.7959 - val_loss: 0.4193 - val_acc: 0.7897\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 8s 40us/step - loss: 0.4089 - acc: 0.7969 - val_loss: 0.4230 - val_acc: 0.7892\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 8s 40us/step - loss: 0.4089 - acc: 0.7965 - val_loss: 0.4224 - val_acc: 0.7882\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4089 - acc: 0.7964 - val_loss: 0.4318 - val_acc: 0.7867\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4089 - acc: 0.7964 - val_loss: 0.4216 - val_acc: 0.7887\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4087 - acc: 0.7964 - val_loss: 0.4212 - val_acc: 0.7891\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4086 - acc: 0.7964 - val_loss: 0.4217 - val_acc: 0.7874\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4087 - acc: 0.7962 - val_loss: 0.4237 - val_acc: 0.7899\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 7s 40us/step - loss: 0.4088 - acc: 0.7963 - val_loss: 0.4227 - val_acc: 0.7882\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 7s 40us/step - loss: 0.4084 - acc: 0.7968 - val_loss: 0.4255 - val_acc: 0.7866\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4083 - acc: 0.7965 - val_loss: 0.4215 - val_acc: 0.7893\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 7s 40us/step - loss: 0.4085 - acc: 0.7965 - val_loss: 0.4219 - val_acc: 0.7891\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4080 - acc: 0.7969 - val_loss: 0.4212 - val_acc: 0.7885\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4080 - acc: 0.7965 - val_loss: 0.4228 - val_acc: 0.7887\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4080 - acc: 0.7964 - val_loss: 0.4212 - val_acc: 0.7896\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4077 - acc: 0.7970 - val_loss: 0.4207 - val_acc: 0.7887\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4076 - acc: 0.7969 - val_loss: 0.4202 - val_acc: 0.7899\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4082 - acc: 0.7970 - val_loss: 0.4241 - val_acc: 0.7889\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4078 - acc: 0.7970 - val_loss: 0.4247 - val_acc: 0.7892\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4078 - acc: 0.7970 - val_loss: 0.4219 - val_acc: 0.7903\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 7s 40us/step - loss: 0.4074 - acc: 0.7967 - val_loss: 0.4222 - val_acc: 0.7888\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4078 - acc: 0.7975 - val_loss: 0.4230 - val_acc: 0.7883\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4074 - acc: 0.7973 - val_loss: 0.4217 - val_acc: 0.7883\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4073 - acc: 0.7972 - val_loss: 0.4223 - val_acc: 0.7900\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 7s 40us/step - loss: 0.4077 - acc: 0.7970 - val_loss: 0.4224 - val_acc: 0.7893\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4073 - acc: 0.7979 - val_loss: 0.4214 - val_acc: 0.7907\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4074 - acc: 0.7979 - val_loss: 0.4223 - val_acc: 0.7896\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4072 - acc: 0.7972 - val_loss: 0.4222 - val_acc: 0.7886\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4076 - acc: 0.7975 - val_loss: 0.4294 - val_acc: 0.7868\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4070 - acc: 0.7973 - val_loss: 0.4240 - val_acc: 0.7894\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4073 - acc: 0.7978 - val_loss: 0.4226 - val_acc: 0.7888\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4071 - acc: 0.7976 - val_loss: 0.4218 - val_acc: 0.7885\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4072 - acc: 0.7972 - val_loss: 0.4236 - val_acc: 0.7887\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4072 - acc: 0.7976 - val_loss: 0.4300 - val_acc: 0.7890\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4068 - acc: 0.7975 - val_loss: 0.4246 - val_acc: 0.7891\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 7s 40us/step - loss: 0.4070 - acc: 0.7974 - val_loss: 0.4214 - val_acc: 0.7896\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4072 - acc: 0.7972 - val_loss: 0.4225 - val_acc: 0.7885\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4071 - acc: 0.7975 - val_loss: 0.4255 - val_acc: 0.7903\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4069 - acc: 0.7979 - val_loss: 0.4232 - val_acc: 0.7906\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4072 - acc: 0.7971 - val_loss: 0.4239 - val_acc: 0.7885\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4070 - acc: 0.7976 - val_loss: 0.4249 - val_acc: 0.7872\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4069 - acc: 0.7979 - val_loss: 0.4277 - val_acc: 0.7850\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4068 - acc: 0.7976 - val_loss: 0.4234 - val_acc: 0.7885\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4070 - acc: 0.7973 - val_loss: 0.4264 - val_acc: 0.7886\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4069 - acc: 0.7976 - val_loss: 0.4256 - val_acc: 0.7883\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4067 - acc: 0.7972 - val_loss: 0.4232 - val_acc: 0.7887\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4066 - acc: 0.7977 - val_loss: 0.4231 - val_acc: 0.7901\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 8s 43us/step - loss: 0.4069 - acc: 0.7975 - val_loss: 0.4226 - val_acc: 0.7903\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4071 - acc: 0.7978 - val_loss: 0.4226 - val_acc: 0.7889\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4065 - acc: 0.7978 - val_loss: 0.4260 - val_acc: 0.7882\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4065 - acc: 0.7986 - val_loss: 0.4256 - val_acc: 0.7904\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4065 - acc: 0.7976 - val_loss: 0.4227 - val_acc: 0.7907\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4062 - acc: 0.7982 - val_loss: 0.4254 - val_acc: 0.7869\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4063 - acc: 0.7979 - val_loss: 0.4293 - val_acc: 0.7885\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4066 - acc: 0.7975 - val_loss: 0.4260 - val_acc: 0.7894\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4067 - acc: 0.7978 - val_loss: 0.4248 - val_acc: 0.7888\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4062 - acc: 0.7980 - val_loss: 0.4214 - val_acc: 0.7895\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4066 - acc: 0.7981 - val_loss: 0.4292 - val_acc: 0.7837\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4064 - acc: 0.7980 - val_loss: 0.4285 - val_acc: 0.7882\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4065 - acc: 0.7980 - val_loss: 0.4247 - val_acc: 0.7898\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4063 - acc: 0.7983 - val_loss: 0.4250 - val_acc: 0.7868\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4063 - acc: 0.7980 - val_loss: 0.4241 - val_acc: 0.7877\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4068 - acc: 0.7976 - val_loss: 0.4229 - val_acc: 0.7892\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 7s 40us/step - loss: 0.4065 - acc: 0.7978 - val_loss: 0.4257 - val_acc: 0.7884\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 7s 40us/step - loss: 0.4065 - acc: 0.7983 - val_loss: 0.4258 - val_acc: 0.7868\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4065 - acc: 0.7988 - val_loss: 0.4277 - val_acc: 0.7869\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4065 - acc: 0.7985 - val_loss: 0.4229 - val_acc: 0.7890\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 7s 40us/step - loss: 0.4066 - acc: 0.7981 - val_loss: 0.4340 - val_acc: 0.7870\n",
      "Epoch 101/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4063 - acc: 0.7979 - val_loss: 0.4243 - val_acc: 0.7888\n",
      "Epoch 102/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4060 - acc: 0.7982 - val_loss: 0.4234 - val_acc: 0.7889\n",
      "Epoch 103/1000\n",
      "185736/185736 [==============================] - 8s 40us/step - loss: 0.4067 - acc: 0.7979 - val_loss: 0.4230 - val_acc: 0.7892\n",
      "Epoch 104/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4060 - acc: 0.7981 - val_loss: 0.4235 - val_acc: 0.7896\n",
      "Epoch 105/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4060 - acc: 0.7983 - val_loss: 0.4265 - val_acc: 0.7881\n",
      "Epoch 106/1000\n",
      "185736/185736 [==============================] - 7s 40us/step - loss: 0.4063 - acc: 0.7975 - val_loss: 0.4283 - val_acc: 0.7879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4069 - acc: 0.7978 - val_loss: 0.4227 - val_acc: 0.7890\n",
      "Epoch 108/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4061 - acc: 0.7985 - val_loss: 0.4245 - val_acc: 0.7896\n",
      "Epoch 109/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4061 - acc: 0.7984 - val_loss: 0.4256 - val_acc: 0.7893\n",
      "Epoch 110/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4062 - acc: 0.7977 - val_loss: 0.4265 - val_acc: 0.7896\n",
      "Epoch 111/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4060 - acc: 0.7982 - val_loss: 0.4234 - val_acc: 0.7881\n",
      "Epoch 112/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4060 - acc: 0.7979 - val_loss: 0.4316 - val_acc: 0.7873\n",
      "Epoch 113/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4061 - acc: 0.7986 - val_loss: 0.4240 - val_acc: 0.7891\n",
      "Epoch 114/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4062 - acc: 0.7988 - val_loss: 0.4239 - val_acc: 0.7895\n",
      "Epoch 115/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4058 - acc: 0.7990 - val_loss: 0.4238 - val_acc: 0.7892\n",
      "Epoch 116/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4060 - acc: 0.7987 - val_loss: 0.4267 - val_acc: 0.7884\n",
      "Epoch 117/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4057 - acc: 0.7979 - val_loss: 0.4249 - val_acc: 0.7889\n",
      "Epoch 118/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4058 - acc: 0.7982 - val_loss: 0.4237 - val_acc: 0.7899\n",
      "Epoch 119/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4058 - acc: 0.7982 - val_loss: 0.4253 - val_acc: 0.7895\n",
      "Epoch 120/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4060 - acc: 0.7982 - val_loss: 0.4222 - val_acc: 0.7888\n",
      "Epoch 121/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4059 - acc: 0.7985 - val_loss: 0.4270 - val_acc: 0.7891\n",
      "Epoch 122/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4059 - acc: 0.7985 - val_loss: 0.4263 - val_acc: 0.7888\n",
      "Epoch 123/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4060 - acc: 0.7983 - val_loss: 0.4274 - val_acc: 0.7867\n",
      "Epoch 124/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4062 - acc: 0.7983 - val_loss: 0.4250 - val_acc: 0.7902\n",
      "Epoch 125/1000\n",
      "185736/185736 [==============================] - 8s 40us/step - loss: 0.4056 - acc: 0.7986 - val_loss: 0.4247 - val_acc: 0.7892\n",
      "Epoch 126/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4060 - acc: 0.7989 - val_loss: 0.4285 - val_acc: 0.7895\n",
      "Epoch 127/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4060 - acc: 0.7985 - val_loss: 0.4241 - val_acc: 0.7892\n",
      "Epoch 128/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4061 - acc: 0.7987 - val_loss: 0.4256 - val_acc: 0.7891\n",
      "Epoch 129/1000\n",
      "185736/185736 [==============================] - 8s 43us/step - loss: 0.4057 - acc: 0.7981 - val_loss: 0.4265 - val_acc: 0.7897\n",
      "Epoch 130/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4057 - acc: 0.7978 - val_loss: 0.4246 - val_acc: 0.7887\n",
      "Epoch 131/1000\n",
      "185736/185736 [==============================] - 8s 42us/step - loss: 0.4057 - acc: 0.7982 - val_loss: 0.4264 - val_acc: 0.7891\n",
      "Epoch 132/1000\n",
      "185736/185736 [==============================] - 8s 43us/step - loss: 0.4055 - acc: 0.7991 - val_loss: 0.4253 - val_acc: 0.7898\n",
      "Epoch 133/1000\n",
      "185736/185736 [==============================] - 8s 43us/step - loss: 0.4057 - acc: 0.7984 - val_loss: 0.4240 - val_acc: 0.7899\n",
      "Epoch 134/1000\n",
      "185736/185736 [==============================] - 8s 41us/step - loss: 0.4056 - acc: 0.7990 - val_loss: 0.4238 - val_acc: 0.7897\n"
     ]
    }
   ],
   "source": [
    "model10, results10 = build_model(hidden_layers=[20, 15, 10], batch_size=128, file_name='model10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7907137011107679"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results10.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_216 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_164 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_165 (Dropout)        (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_166 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 25s 135us/step - loss: 0.4382 - acc: 0.7799 - val_loss: 0.4397 - val_acc: 0.7787\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 22s 120us/step - loss: 0.4260 - acc: 0.7865 - val_loss: 0.4292 - val_acc: 0.7824\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 23s 125us/step - loss: 0.4245 - acc: 0.7872 - val_loss: 0.4250 - val_acc: 0.7846\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 23s 121us/step - loss: 0.4238 - acc: 0.7879 - val_loss: 0.4245 - val_acc: 0.7863\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 23s 126us/step - loss: 0.4228 - acc: 0.7879 - val_loss: 0.4255 - val_acc: 0.7846\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 23s 126us/step - loss: 0.4220 - acc: 0.7883 - val_loss: 0.4240 - val_acc: 0.7864\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 23s 125us/step - loss: 0.4210 - acc: 0.7889 - val_loss: 0.4247 - val_acc: 0.7836\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 23s 125us/step - loss: 0.4205 - acc: 0.7894 - val_loss: 0.4222 - val_acc: 0.7866\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4200 - acc: 0.7896 - val_loss: 0.4239 - val_acc: 0.7861\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 24s 127us/step - loss: 0.4201 - acc: 0.7887 - val_loss: 0.4296 - val_acc: 0.7837\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4196 - acc: 0.7890 - val_loss: 0.4242 - val_acc: 0.7868\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 23s 126us/step - loss: 0.4194 - acc: 0.7901 - val_loss: 0.4222 - val_acc: 0.7876\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 24s 127us/step - loss: 0.4194 - acc: 0.7896 - val_loss: 0.4224 - val_acc: 0.7868\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 24s 127us/step - loss: 0.4191 - acc: 0.7893 - val_loss: 0.4231 - val_acc: 0.7861\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 23s 122us/step - loss: 0.4186 - acc: 0.7898 - val_loss: 0.4253 - val_acc: 0.7856\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4184 - acc: 0.7895 - val_loss: 0.4255 - val_acc: 0.7872\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4182 - acc: 0.7906 - val_loss: 0.4232 - val_acc: 0.7878\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4182 - acc: 0.7902 - val_loss: 0.4227 - val_acc: 0.7883\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 23s 121us/step - loss: 0.4179 - acc: 0.7903 - val_loss: 0.4230 - val_acc: 0.7868\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4178 - acc: 0.7903 - val_loss: 0.4256 - val_acc: 0.7843\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4175 - acc: 0.7908 - val_loss: 0.4265 - val_acc: 0.7875\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 22s 120us/step - loss: 0.4175 - acc: 0.7909 - val_loss: 0.4251 - val_acc: 0.7878\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4173 - acc: 0.7910 - val_loss: 0.4268 - val_acc: 0.7850\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4175 - acc: 0.7914 - val_loss: 0.4246 - val_acc: 0.7841\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4169 - acc: 0.7913 - val_loss: 0.4227 - val_acc: 0.7878\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4170 - acc: 0.7910 - val_loss: 0.4269 - val_acc: 0.7861\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 22s 117us/step - loss: 0.4169 - acc: 0.7913 - val_loss: 0.4221 - val_acc: 0.7874\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4169 - acc: 0.7915 - val_loss: 0.4248 - val_acc: 0.7833\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 22s 120us/step - loss: 0.4165 - acc: 0.7913 - val_loss: 0.4236 - val_acc: 0.7866\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 22s 117us/step - loss: 0.4162 - acc: 0.7922 - val_loss: 0.4212 - val_acc: 0.7871\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 22s 116us/step - loss: 0.4156 - acc: 0.7921 - val_loss: 0.4257 - val_acc: 0.7877\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4158 - acc: 0.7918 - val_loss: 0.4222 - val_acc: 0.7876\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4153 - acc: 0.7918 - val_loss: 0.4219 - val_acc: 0.7865\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 22s 116us/step - loss: 0.4153 - acc: 0.7926 - val_loss: 0.4264 - val_acc: 0.7868\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 22s 116us/step - loss: 0.4154 - acc: 0.7917 - val_loss: 0.4226 - val_acc: 0.7895\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 22s 117us/step - loss: 0.4148 - acc: 0.7921 - val_loss: 0.4236 - val_acc: 0.7877\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4151 - acc: 0.7919 - val_loss: 0.4248 - val_acc: 0.7880\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 21s 114us/step - loss: 0.4151 - acc: 0.7916 - val_loss: 0.4261 - val_acc: 0.7887\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 22s 117us/step - loss: 0.4150 - acc: 0.7925 - val_loss: 0.4236 - val_acc: 0.7862\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4151 - acc: 0.7923 - val_loss: 0.4259 - val_acc: 0.7875\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 23s 126us/step - loss: 0.4147 - acc: 0.7920 - val_loss: 0.4226 - val_acc: 0.7876\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4144 - acc: 0.7927 - val_loss: 0.4254 - val_acc: 0.7892\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4146 - acc: 0.7920 - val_loss: 0.4257 - val_acc: 0.7896\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4147 - acc: 0.7921 - val_loss: 0.4216 - val_acc: 0.7891\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 22s 120us/step - loss: 0.4143 - acc: 0.7924 - val_loss: 0.4206 - val_acc: 0.7899\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 22s 117us/step - loss: 0.4139 - acc: 0.7923 - val_loss: 0.4236 - val_acc: 0.7884\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4145 - acc: 0.7922 - val_loss: 0.4204 - val_acc: 0.7895\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4142 - acc: 0.7926 - val_loss: 0.4232 - val_acc: 0.7882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4143 - acc: 0.7922 - val_loss: 0.4213 - val_acc: 0.7889\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 22s 116us/step - loss: 0.4141 - acc: 0.7919 - val_loss: 0.4241 - val_acc: 0.7881\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4145 - acc: 0.7920 - val_loss: 0.4216 - val_acc: 0.7872\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 23s 125us/step - loss: 0.4150 - acc: 0.7921 - val_loss: 0.4199 - val_acc: 0.7882\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 22s 120us/step - loss: 0.4141 - acc: 0.7926 - val_loss: 0.4249 - val_acc: 0.7866\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4142 - acc: 0.7927 - val_loss: 0.4231 - val_acc: 0.7878\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4141 - acc: 0.7922 - val_loss: 0.4234 - val_acc: 0.7868\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 23s 122us/step - loss: 0.4140 - acc: 0.7924 - val_loss: 0.4272 - val_acc: 0.7895\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 24s 127us/step - loss: 0.4138 - acc: 0.7927 - val_loss: 0.4247 - val_acc: 0.7889\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 23s 122us/step - loss: 0.4139 - acc: 0.7929 - val_loss: 0.4204 - val_acc: 0.7880\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 23s 125us/step - loss: 0.4136 - acc: 0.7928 - val_loss: 0.4210 - val_acc: 0.7869\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 23s 126us/step - loss: 0.4145 - acc: 0.7925 - val_loss: 0.4214 - val_acc: 0.7881\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 23s 125us/step - loss: 0.4142 - acc: 0.7932 - val_loss: 0.4225 - val_acc: 0.7871\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4137 - acc: 0.7925 - val_loss: 0.4290 - val_acc: 0.7887\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 24s 127us/step - loss: 0.4143 - acc: 0.7924 - val_loss: 0.4227 - val_acc: 0.7891\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4137 - acc: 0.7929 - val_loss: 0.4228 - val_acc: 0.7884\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4137 - acc: 0.7929 - val_loss: 0.4217 - val_acc: 0.7875\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 24s 129us/step - loss: 0.4137 - acc: 0.7925 - val_loss: 0.4223 - val_acc: 0.7883\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 23s 123us/step - loss: 0.4145 - acc: 0.7927 - val_loss: 0.4218 - val_acc: 0.7885\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 22s 117us/step - loss: 0.4138 - acc: 0.7928 - val_loss: 0.4246 - val_acc: 0.7896\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 22s 116us/step - loss: 0.4139 - acc: 0.7922 - val_loss: 0.4246 - val_acc: 0.7886\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 22s 116us/step - loss: 0.4138 - acc: 0.7922 - val_loss: 0.4269 - val_acc: 0.7869\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4137 - acc: 0.7924 - val_loss: 0.4223 - val_acc: 0.7862\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4137 - acc: 0.7929 - val_loss: 0.4280 - val_acc: 0.7888\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4138 - acc: 0.7928 - val_loss: 0.4213 - val_acc: 0.7878\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 23s 124us/step - loss: 0.4139 - acc: 0.7925 - val_loss: 0.4243 - val_acc: 0.7896\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 23s 125us/step - loss: 0.4137 - acc: 0.7925 - val_loss: 0.4226 - val_acc: 0.7865\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 23s 121us/step - loss: 0.4134 - acc: 0.7928 - val_loss: 0.4242 - val_acc: 0.7887\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 22s 120us/step - loss: 0.4134 - acc: 0.7929 - val_loss: 0.4212 - val_acc: 0.7887\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4133 - acc: 0.7923 - val_loss: 0.4237 - val_acc: 0.7890\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 22s 120us/step - loss: 0.4136 - acc: 0.7927 - val_loss: 0.4221 - val_acc: 0.7868\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4135 - acc: 0.7924 - val_loss: 0.4246 - val_acc: 0.7868\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4134 - acc: 0.7928 - val_loss: 0.4250 - val_acc: 0.7878\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 22s 116us/step - loss: 0.4132 - acc: 0.7927 - val_loss: 0.4214 - val_acc: 0.7886\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 22s 121us/step - loss: 0.4138 - acc: 0.7923 - val_loss: 0.4205 - val_acc: 0.7881\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 22s 116us/step - loss: 0.4133 - acc: 0.7931 - val_loss: 0.4213 - val_acc: 0.7888\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 22s 120us/step - loss: 0.4138 - acc: 0.7931 - val_loss: 0.4241 - val_acc: 0.7869\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 23s 122us/step - loss: 0.4137 - acc: 0.7927 - val_loss: 0.4226 - val_acc: 0.7875\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4135 - acc: 0.7931 - val_loss: 0.4228 - val_acc: 0.7857\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 21s 115us/step - loss: 0.4131 - acc: 0.7929 - val_loss: 0.4210 - val_acc: 0.7891\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 22s 121us/step - loss: 0.4133 - acc: 0.7924 - val_loss: 0.4205 - val_acc: 0.7888\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4132 - acc: 0.7925 - val_loss: 0.4229 - val_acc: 0.7881\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4135 - acc: 0.7922 - val_loss: 0.4215 - val_acc: 0.7897\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4136 - acc: 0.7928 - val_loss: 0.4227 - val_acc: 0.7888\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4133 - acc: 0.7925 - val_loss: 0.4211 - val_acc: 0.7888\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 22s 118us/step - loss: 0.4134 - acc: 0.7923 - val_loss: 0.4210 - val_acc: 0.7890\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 22s 119us/step - loss: 0.4136 - acc: 0.7929 - val_loss: 0.4260 - val_acc: 0.7867\n"
     ]
    }
   ],
   "source": [
    "model11, results11 = build_model(hidden_layers=[20, 15, 10], batch_size=32, file_name='model11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7899168712581298"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results11.history['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the dropout, L2 regulization and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_137 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_104 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_105 (Dropout)        (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_106 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.4700 - acc: 0.7605 - val_loss: 0.4317 - val_acc: 0.7814\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4339 - acc: 0.7840 - val_loss: 0.4270 - val_acc: 0.7827\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4308 - acc: 0.7849 - val_loss: 0.4261 - val_acc: 0.7847\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4288 - acc: 0.7860 - val_loss: 0.4226 - val_acc: 0.7856\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4265 - acc: 0.7875 - val_loss: 0.4290 - val_acc: 0.7803\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4267 - acc: 0.7878 - val_loss: 0.4229 - val_acc: 0.7877\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4249 - acc: 0.7877 - val_loss: 0.4234 - val_acc: 0.7860\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4248 - acc: 0.7891 - val_loss: 0.4218 - val_acc: 0.7871\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4242 - acc: 0.7882 - val_loss: 0.4245 - val_acc: 0.7852\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4245 - acc: 0.7882 - val_loss: 0.4210 - val_acc: 0.7879\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4238 - acc: 0.7890 - val_loss: 0.4238 - val_acc: 0.7866\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4234 - acc: 0.7891 - val_loss: 0.4223 - val_acc: 0.7864\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4228 - acc: 0.7892 - val_loss: 0.4222 - val_acc: 0.7870\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4222 - acc: 0.7891 - val_loss: 0.4213 - val_acc: 0.7877\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4227 - acc: 0.7886 - val_loss: 0.4212 - val_acc: 0.7880\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4218 - acc: 0.7895 - val_loss: 0.4207 - val_acc: 0.7886\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4219 - acc: 0.7895 - val_loss: 0.4210 - val_acc: 0.7869\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4207 - acc: 0.7903 - val_loss: 0.4229 - val_acc: 0.7881\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4199 - acc: 0.7901 - val_loss: 0.4203 - val_acc: 0.7892\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4202 - acc: 0.7908 - val_loss: 0.4240 - val_acc: 0.7863\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4191 - acc: 0.7911 - val_loss: 0.4206 - val_acc: 0.7880\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4196 - acc: 0.7906 - val_loss: 0.4211 - val_acc: 0.7874\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4195 - acc: 0.7910 - val_loss: 0.4270 - val_acc: 0.7874\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4180 - acc: 0.7919 - val_loss: 0.4205 - val_acc: 0.7879\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4192 - acc: 0.7911 - val_loss: 0.4213 - val_acc: 0.7873\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4180 - acc: 0.7916 - val_loss: 0.4219 - val_acc: 0.7879\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4185 - acc: 0.7914 - val_loss: 0.4197 - val_acc: 0.7891\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4183 - acc: 0.7921 - val_loss: 0.4220 - val_acc: 0.7869\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4186 - acc: 0.7906 - val_loss: 0.4198 - val_acc: 0.7874\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4179 - acc: 0.7921 - val_loss: 0.4208 - val_acc: 0.7891\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4173 - acc: 0.7918 - val_loss: 0.4214 - val_acc: 0.7878\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4178 - acc: 0.7918 - val_loss: 0.4216 - val_acc: 0.7889\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4178 - acc: 0.7925 - val_loss: 0.4235 - val_acc: 0.7868\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4166 - acc: 0.7925 - val_loss: 0.4192 - val_acc: 0.7897\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4170 - acc: 0.7921 - val_loss: 0.4215 - val_acc: 0.7883\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4173 - acc: 0.7928 - val_loss: 0.4206 - val_acc: 0.7888\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4168 - acc: 0.7924 - val_loss: 0.4204 - val_acc: 0.7884\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4169 - acc: 0.7920 - val_loss: 0.4208 - val_acc: 0.7886\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4173 - acc: 0.7925 - val_loss: 0.4200 - val_acc: 0.7884\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4170 - acc: 0.7930 - val_loss: 0.4200 - val_acc: 0.7890\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4173 - acc: 0.7925 - val_loss: 0.4225 - val_acc: 0.7884\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4168 - acc: 0.7925 - val_loss: 0.4216 - val_acc: 0.7874\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4164 - acc: 0.7926 - val_loss: 0.4193 - val_acc: 0.7900\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4169 - acc: 0.7926 - val_loss: 0.4214 - val_acc: 0.7880\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4170 - acc: 0.7918 - val_loss: 0.4209 - val_acc: 0.7879\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4164 - acc: 0.7925 - val_loss: 0.4207 - val_acc: 0.7889\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4169 - acc: 0.7922 - val_loss: 0.4210 - val_acc: 0.7882\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4166 - acc: 0.7921 - val_loss: 0.4190 - val_acc: 0.7896\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4164 - acc: 0.7915 - val_loss: 0.4204 - val_acc: 0.7891\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4167 - acc: 0.7919 - val_loss: 0.4198 - val_acc: 0.7913\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4167 - acc: 0.7926 - val_loss: 0.4229 - val_acc: 0.7883\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4167 - acc: 0.7924 - val_loss: 0.4205 - val_acc: 0.7892\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4159 - acc: 0.7931 - val_loss: 0.4224 - val_acc: 0.7879\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4159 - acc: 0.7923 - val_loss: 0.4225 - val_acc: 0.7901\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4159 - acc: 0.7929 - val_loss: 0.4210 - val_acc: 0.7891\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4163 - acc: 0.7925 - val_loss: 0.4221 - val_acc: 0.7880\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4164 - acc: 0.7929 - val_loss: 0.4202 - val_acc: 0.7881\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4160 - acc: 0.7926 - val_loss: 0.4210 - val_acc: 0.7879\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4156 - acc: 0.7926 - val_loss: 0.4224 - val_acc: 0.7886\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4153 - acc: 0.7929 - val_loss: 0.4224 - val_acc: 0.7885\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4157 - acc: 0.7932 - val_loss: 0.4224 - val_acc: 0.7867\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4157 - acc: 0.7934 - val_loss: 0.4200 - val_acc: 0.7883\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4155 - acc: 0.7924 - val_loss: 0.4200 - val_acc: 0.7889\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4157 - acc: 0.7930 - val_loss: 0.4210 - val_acc: 0.7880\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4157 - acc: 0.7931 - val_loss: 0.4221 - val_acc: 0.7889\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4152 - acc: 0.7931 - val_loss: 0.4229 - val_acc: 0.7883\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4157 - acc: 0.7926 - val_loss: 0.4208 - val_acc: 0.7882\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4156 - acc: 0.7926 - val_loss: 0.4217 - val_acc: 0.7887\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4156 - acc: 0.7930 - val_loss: 0.4233 - val_acc: 0.7870\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4159 - acc: 0.7926 - val_loss: 0.4225 - val_acc: 0.7888\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4158 - acc: 0.7921 - val_loss: 0.4213 - val_acc: 0.7883\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4148 - acc: 0.7927 - val_loss: 0.4202 - val_acc: 0.7892\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4156 - acc: 0.7932 - val_loss: 0.4204 - val_acc: 0.7886\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4153 - acc: 0.7931 - val_loss: 0.4219 - val_acc: 0.7869\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4151 - acc: 0.7931 - val_loss: 0.4236 - val_acc: 0.7873\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4149 - acc: 0.7935 - val_loss: 0.4230 - val_acc: 0.7879\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4155 - acc: 0.7931 - val_loss: 0.4203 - val_acc: 0.7892\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4150 - acc: 0.7930 - val_loss: 0.4225 - val_acc: 0.7875\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4155 - acc: 0.7930 - val_loss: 0.4231 - val_acc: 0.7886\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4145 - acc: 0.7935 - val_loss: 0.4212 - val_acc: 0.7892\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4153 - acc: 0.7927 - val_loss: 0.4209 - val_acc: 0.7888\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4149 - acc: 0.7925 - val_loss: 0.4212 - val_acc: 0.7886\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4152 - acc: 0.7927 - val_loss: 0.4216 - val_acc: 0.7882\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4153 - acc: 0.7926 - val_loss: 0.4224 - val_acc: 0.7888\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4145 - acc: 0.7930 - val_loss: 0.4220 - val_acc: 0.7896\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4146 - acc: 0.7939 - val_loss: 0.4237 - val_acc: 0.7890\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4152 - acc: 0.7932 - val_loss: 0.4207 - val_acc: 0.7883\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4152 - acc: 0.7930 - val_loss: 0.4205 - val_acc: 0.7898\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4145 - acc: 0.7929 - val_loss: 0.4219 - val_acc: 0.7879\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4151 - acc: 0.7932 - val_loss: 0.4215 - val_acc: 0.7901\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4146 - acc: 0.7931 - val_loss: 0.4244 - val_acc: 0.7861\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4147 - acc: 0.7935 - val_loss: 0.4240 - val_acc: 0.7869\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4150 - acc: 0.7925 - val_loss: 0.4223 - val_acc: 0.7885\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4144 - acc: 0.7929 - val_loss: 0.4210 - val_acc: 0.7877\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4147 - acc: 0.7938 - val_loss: 0.4209 - val_acc: 0.7896\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4148 - acc: 0.7936 - val_loss: 0.4213 - val_acc: 0.7894\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4143 - acc: 0.7933 - val_loss: 0.4212 - val_acc: 0.7891\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4147 - acc: 0.7933 - val_loss: 0.4213 - val_acc: 0.7884\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4143 - acc: 0.7943 - val_loss: 0.4212 - val_acc: 0.7884\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4141 - acc: 0.7937 - val_loss: 0.4217 - val_acc: 0.7894\n"
     ]
    }
   ],
   "source": [
    "model12, results12 = build_model(hidden_layers=[20, 15, 10], drop_out=0.1, file_name='model12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7913382434616996"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results12.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_141 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_108 (Dropout)        (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_109 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 4s 24us/step - loss: 0.4635 - acc: 0.7697 - val_loss: 0.4399 - val_acc: 0.7804\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4349 - acc: 0.7859 - val_loss: 0.4376 - val_acc: 0.7816\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4325 - acc: 0.7863 - val_loss: 0.4332 - val_acc: 0.7854\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4311 - acc: 0.7866 - val_loss: 0.4311 - val_acc: 0.7866\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4306 - acc: 0.7875 - val_loss: 0.4373 - val_acc: 0.7803\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4295 - acc: 0.7868 - val_loss: 0.4494 - val_acc: 0.7708\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4290 - acc: 0.7876 - val_loss: 0.4306 - val_acc: 0.7861\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4282 - acc: 0.7881 - val_loss: 0.4295 - val_acc: 0.7855\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4274 - acc: 0.7892 - val_loss: 0.4312 - val_acc: 0.7868\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4289 - acc: 0.7881 - val_loss: 0.4347 - val_acc: 0.7809\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4281 - acc: 0.7890 - val_loss: 0.4320 - val_acc: 0.7849\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4271 - acc: 0.7892 - val_loss: 0.4340 - val_acc: 0.7822\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4272 - acc: 0.7891 - val_loss: 0.4296 - val_acc: 0.7867\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4269 - acc: 0.7887 - val_loss: 0.4299 - val_acc: 0.7869\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4272 - acc: 0.7887 - val_loss: 0.4299 - val_acc: 0.7852\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4275 - acc: 0.7888 - val_loss: 0.4301 - val_acc: 0.7856\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4269 - acc: 0.7884 - val_loss: 0.4290 - val_acc: 0.7869\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4269 - acc: 0.7887 - val_loss: 0.4293 - val_acc: 0.7875\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4268 - acc: 0.7882 - val_loss: 0.4292 - val_acc: 0.7877\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4269 - acc: 0.7881 - val_loss: 0.4363 - val_acc: 0.7832\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4267 - acc: 0.7895 - val_loss: 0.4310 - val_acc: 0.7858\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4255 - acc: 0.7893 - val_loss: 0.4310 - val_acc: 0.7846\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4267 - acc: 0.7886 - val_loss: 0.4272 - val_acc: 0.7886\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4257 - acc: 0.7901 - val_loss: 0.4283 - val_acc: 0.7867\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4261 - acc: 0.7894 - val_loss: 0.4277 - val_acc: 0.7876\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4257 - acc: 0.7894 - val_loss: 0.4289 - val_acc: 0.7861\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4259 - acc: 0.7893 - val_loss: 0.4279 - val_acc: 0.7882\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4255 - acc: 0.7900 - val_loss: 0.4266 - val_acc: 0.7883\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4258 - acc: 0.7895 - val_loss: 0.4287 - val_acc: 0.7890\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4251 - acc: 0.7902 - val_loss: 0.4270 - val_acc: 0.7888\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4253 - acc: 0.7895 - val_loss: 0.4265 - val_acc: 0.7879\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4247 - acc: 0.7899 - val_loss: 0.4282 - val_acc: 0.7861\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4248 - acc: 0.7896 - val_loss: 0.4266 - val_acc: 0.7869\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4260 - acc: 0.7892 - val_loss: 0.4282 - val_acc: 0.7872\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4253 - acc: 0.7896 - val_loss: 0.4283 - val_acc: 0.7879\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4249 - acc: 0.7892 - val_loss: 0.4272 - val_acc: 0.7863\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4248 - acc: 0.7898 - val_loss: 0.4263 - val_acc: 0.7876\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4251 - acc: 0.7896 - val_loss: 0.4318 - val_acc: 0.7834\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4248 - acc: 0.7900 - val_loss: 0.4272 - val_acc: 0.7872\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4251 - acc: 0.7893 - val_loss: 0.4261 - val_acc: 0.7875\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4252 - acc: 0.7895 - val_loss: 0.4262 - val_acc: 0.7872\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4253 - acc: 0.7890 - val_loss: 0.4274 - val_acc: 0.7864\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4245 - acc: 0.7898 - val_loss: 0.4298 - val_acc: 0.7869\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4251 - acc: 0.7892 - val_loss: 0.4258 - val_acc: 0.7878\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4244 - acc: 0.7906 - val_loss: 0.4276 - val_acc: 0.7874\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4243 - acc: 0.7905 - val_loss: 0.4273 - val_acc: 0.7867\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4248 - acc: 0.7902 - val_loss: 0.4280 - val_acc: 0.7854\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4251 - acc: 0.7890 - val_loss: 0.4282 - val_acc: 0.7867\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4252 - acc: 0.7890 - val_loss: 0.4264 - val_acc: 0.7870\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4241 - acc: 0.7899 - val_loss: 0.4283 - val_acc: 0.7855\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4248 - acc: 0.7898 - val_loss: 0.4273 - val_acc: 0.7871\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4239 - acc: 0.7907 - val_loss: 0.4257 - val_acc: 0.7873\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4247 - acc: 0.7894 - val_loss: 0.4327 - val_acc: 0.7832\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4251 - acc: 0.7892 - val_loss: 0.4316 - val_acc: 0.7826\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4240 - acc: 0.7901 - val_loss: 0.4284 - val_acc: 0.7868\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4248 - acc: 0.7902 - val_loss: 0.4265 - val_acc: 0.7878\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4249 - acc: 0.7896 - val_loss: 0.4310 - val_acc: 0.7852\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4248 - acc: 0.7897 - val_loss: 0.4278 - val_acc: 0.7862\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4243 - acc: 0.7903 - val_loss: 0.4283 - val_acc: 0.7864\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4242 - acc: 0.7897 - val_loss: 0.4255 - val_acc: 0.7887\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4249 - acc: 0.7897 - val_loss: 0.4269 - val_acc: 0.7869\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4243 - acc: 0.7895 - val_loss: 0.4254 - val_acc: 0.7865\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4244 - acc: 0.7898 - val_loss: 0.4279 - val_acc: 0.7872\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4244 - acc: 0.7902 - val_loss: 0.4290 - val_acc: 0.7847\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4246 - acc: 0.7893 - val_loss: 0.4279 - val_acc: 0.7877\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4248 - acc: 0.7888 - val_loss: 0.4269 - val_acc: 0.7876\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4250 - acc: 0.7889 - val_loss: 0.4281 - val_acc: 0.7873\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4244 - acc: 0.7900 - val_loss: 0.4261 - val_acc: 0.7880\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4248 - acc: 0.7895 - val_loss: 0.4258 - val_acc: 0.7885\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4256 - acc: 0.7890 - val_loss: 0.4276 - val_acc: 0.7868\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4248 - acc: 0.7894 - val_loss: 0.4271 - val_acc: 0.7863\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4244 - acc: 0.7897 - val_loss: 0.4282 - val_acc: 0.7846\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4250 - acc: 0.7898 - val_loss: 0.4259 - val_acc: 0.7876\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4244 - acc: 0.7896 - val_loss: 0.4271 - val_acc: 0.7860\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4249 - acc: 0.7901 - val_loss: 0.4339 - val_acc: 0.7850\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4246 - acc: 0.7896 - val_loss: 0.4253 - val_acc: 0.7882\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4240 - acc: 0.7901 - val_loss: 0.4266 - val_acc: 0.7862\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4246 - acc: 0.7899 - val_loss: 0.4291 - val_acc: 0.7840\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4245 - acc: 0.7893 - val_loss: 0.4278 - val_acc: 0.7870\n"
     ]
    }
   ],
   "source": [
    "model13, results13 = build_model(hidden_layers=[20, 15, 10], l2_val=0.0001,file_name='model13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7889908255006616"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results13.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_145 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_110 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_111 (Dropout)        (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_112 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 5s 27us/step - loss: 0.4777 - acc: 0.7619 - val_loss: 0.4437 - val_acc: 0.7814\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4508 - acc: 0.7797 - val_loss: 0.4402 - val_acc: 0.7834\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4470 - acc: 0.7816 - val_loss: 0.4427 - val_acc: 0.7789\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4463 - acc: 0.7808 - val_loss: 0.4381 - val_acc: 0.7823\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4443 - acc: 0.7826 - val_loss: 0.4396 - val_acc: 0.7814\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4443 - acc: 0.7825 - val_loss: 0.4343 - val_acc: 0.7858\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4434 - acc: 0.7816 - val_loss: 0.4338 - val_acc: 0.7847\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4431 - acc: 0.7821 - val_loss: 0.4383 - val_acc: 0.7864\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4444 - acc: 0.7811 - val_loss: 0.4377 - val_acc: 0.7824\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4432 - acc: 0.7816 - val_loss: 0.4349 - val_acc: 0.7833\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4430 - acc: 0.7811 - val_loss: 0.4352 - val_acc: 0.7841\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4434 - acc: 0.7823 - val_loss: 0.4367 - val_acc: 0.7818\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4425 - acc: 0.7820 - val_loss: 0.4381 - val_acc: 0.7843\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4430 - acc: 0.7819 - val_loss: 0.4334 - val_acc: 0.7855\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4422 - acc: 0.7828 - val_loss: 0.4408 - val_acc: 0.7820\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4430 - acc: 0.7820 - val_loss: 0.4339 - val_acc: 0.7838\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4424 - acc: 0.7818 - val_loss: 0.4346 - val_acc: 0.7853\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4417 - acc: 0.7827 - val_loss: 0.4388 - val_acc: 0.7791\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4428 - acc: 0.7819 - val_loss: 0.4320 - val_acc: 0.7864\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4422 - acc: 0.7823 - val_loss: 0.4361 - val_acc: 0.7845\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4421 - acc: 0.7826 - val_loss: 0.4357 - val_acc: 0.7842\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4421 - acc: 0.7829 - val_loss: 0.4348 - val_acc: 0.7822\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4432 - acc: 0.7814 - val_loss: 0.4332 - val_acc: 0.7854\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4420 - acc: 0.7823 - val_loss: 0.4389 - val_acc: 0.7782\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4421 - acc: 0.7821 - val_loss: 0.4347 - val_acc: 0.7861\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4420 - acc: 0.7819 - val_loss: 0.4329 - val_acc: 0.7844\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4424 - acc: 0.7817 - val_loss: 0.4368 - val_acc: 0.7826\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4418 - acc: 0.7819 - val_loss: 0.4336 - val_acc: 0.7854\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4426 - acc: 0.7823 - val_loss: 0.4322 - val_acc: 0.7860\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4416 - acc: 0.7824 - val_loss: 0.4352 - val_acc: 0.7841\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4425 - acc: 0.7813 - val_loss: 0.4489 - val_acc: 0.7718\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4416 - acc: 0.7819 - val_loss: 0.4358 - val_acc: 0.7862\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4421 - acc: 0.7822 - val_loss: 0.4341 - val_acc: 0.7836\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4412 - acc: 0.7829 - val_loss: 0.4342 - val_acc: 0.7841\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4427 - acc: 0.7819 - val_loss: 0.4370 - val_acc: 0.7848\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4426 - acc: 0.7820 - val_loss: 0.4334 - val_acc: 0.7853\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4419 - acc: 0.7825 - val_loss: 0.4341 - val_acc: 0.7819\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4422 - acc: 0.7823 - val_loss: 0.4355 - val_acc: 0.7856\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4422 - acc: 0.7821 - val_loss: 0.4351 - val_acc: 0.7832\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4425 - acc: 0.7824 - val_loss: 0.4338 - val_acc: 0.7838\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4423 - acc: 0.7828 - val_loss: 0.4344 - val_acc: 0.7850\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4426 - acc: 0.7825 - val_loss: 0.4359 - val_acc: 0.7815\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4418 - acc: 0.7820 - val_loss: 0.4352 - val_acc: 0.7843\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4417 - acc: 0.7832 - val_loss: 0.4326 - val_acc: 0.7860\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4423 - acc: 0.7820 - val_loss: 0.4335 - val_acc: 0.7841\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4423 - acc: 0.7823 - val_loss: 0.4423 - val_acc: 0.7798\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4418 - acc: 0.7823 - val_loss: 0.4358 - val_acc: 0.7817\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4422 - acc: 0.7831 - val_loss: 0.4369 - val_acc: 0.7810\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4426 - acc: 0.7815 - val_loss: 0.4374 - val_acc: 0.7826\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4414 - acc: 0.7824 - val_loss: 0.4361 - val_acc: 0.7796\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4423 - acc: 0.7830 - val_loss: 0.4332 - val_acc: 0.7854\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4411 - acc: 0.7829 - val_loss: 0.4345 - val_acc: 0.7840\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4423 - acc: 0.7818 - val_loss: 0.4349 - val_acc: 0.7849\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4426 - acc: 0.7811 - val_loss: 0.4316 - val_acc: 0.7865\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4419 - acc: 0.7825 - val_loss: 0.4343 - val_acc: 0.7836\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4418 - acc: 0.7825 - val_loss: 0.4332 - val_acc: 0.7847\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4420 - acc: 0.7825 - val_loss: 0.4365 - val_acc: 0.7837\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4424 - acc: 0.7827 - val_loss: 0.4359 - val_acc: 0.7839\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4418 - acc: 0.7823 - val_loss: 0.4339 - val_acc: 0.7859\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4424 - acc: 0.7828 - val_loss: 0.4339 - val_acc: 0.7852\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4422 - acc: 0.7819 - val_loss: 0.4351 - val_acc: 0.7822\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4429 - acc: 0.7814 - val_loss: 0.4340 - val_acc: 0.7814\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4421 - acc: 0.7824 - val_loss: 0.4339 - val_acc: 0.7832\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4416 - acc: 0.7821 - val_loss: 0.4349 - val_acc: 0.7852\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4428 - acc: 0.7815 - val_loss: 0.4351 - val_acc: 0.7848\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4417 - acc: 0.7827 - val_loss: 0.4379 - val_acc: 0.7808\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4429 - acc: 0.7809 - val_loss: 0.4398 - val_acc: 0.7827\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4420 - acc: 0.7815 - val_loss: 0.4343 - val_acc: 0.7828\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4416 - acc: 0.7826 - val_loss: 0.4426 - val_acc: 0.7781\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4431 - acc: 0.7815 - val_loss: 0.4371 - val_acc: 0.7858\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4419 - acc: 0.7824 - val_loss: 0.4439 - val_acc: 0.7737\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4429 - acc: 0.7818 - val_loss: 0.4395 - val_acc: 0.7781\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4415 - acc: 0.7828 - val_loss: 0.4352 - val_acc: 0.7836\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4423 - acc: 0.7825 - val_loss: 0.4340 - val_acc: 0.7847\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4420 - acc: 0.7813 - val_loss: 0.4351 - val_acc: 0.7849\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4421 - acc: 0.7821 - val_loss: 0.4338 - val_acc: 0.7840\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4429 - acc: 0.7817 - val_loss: 0.4326 - val_acc: 0.7860\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4416 - acc: 0.7811 - val_loss: 0.4326 - val_acc: 0.7833\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4425 - acc: 0.7822 - val_loss: 0.4343 - val_acc: 0.7840\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4421 - acc: 0.7810 - val_loss: 0.4345 - val_acc: 0.7849\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4426 - acc: 0.7806 - val_loss: 0.4434 - val_acc: 0.7826\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4426 - acc: 0.7830 - val_loss: 0.4342 - val_acc: 0.7849\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4421 - acc: 0.7821 - val_loss: 0.4357 - val_acc: 0.7813\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4419 - acc: 0.7830 - val_loss: 0.4338 - val_acc: 0.7850\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4426 - acc: 0.7821 - val_loss: 0.4356 - val_acc: 0.7826\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4425 - acc: 0.7827 - val_loss: 0.4330 - val_acc: 0.7858\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4421 - acc: 0.7817 - val_loss: 0.4328 - val_acc: 0.7833\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4434 - acc: 0.7813 - val_loss: 0.4394 - val_acc: 0.7838\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4426 - acc: 0.7819 - val_loss: 0.4340 - val_acc: 0.7821\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4418 - acc: 0.7826 - val_loss: 0.4372 - val_acc: 0.7829\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4418 - acc: 0.7819 - val_loss: 0.4371 - val_acc: 0.7821\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4432 - acc: 0.7815 - val_loss: 0.4371 - val_acc: 0.7860\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4430 - acc: 0.7813 - val_loss: 0.4355 - val_acc: 0.7848\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4423 - acc: 0.7810 - val_loss: 0.4329 - val_acc: 0.7830\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4417 - acc: 0.7817 - val_loss: 0.4363 - val_acc: 0.7860\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4432 - acc: 0.7812 - val_loss: 0.4342 - val_acc: 0.7844\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4420 - acc: 0.7824 - val_loss: 0.4357 - val_acc: 0.7836\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4423 - acc: 0.7821 - val_loss: 0.4396 - val_acc: 0.7705\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4428 - acc: 0.7821 - val_loss: 0.4355 - val_acc: 0.7847\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4429 - acc: 0.7806 - val_loss: 0.4323 - val_acc: 0.7841\n",
      "Epoch 101/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4426 - acc: 0.7819 - val_loss: 0.4366 - val_acc: 0.7840\n",
      "Epoch 102/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4420 - acc: 0.7819 - val_loss: 0.4334 - val_acc: 0.7840\n",
      "Epoch 103/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4430 - acc: 0.7816 - val_loss: 0.4360 - val_acc: 0.7824\n",
      "Epoch 104/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4416 - acc: 0.7825 - val_loss: 0.4348 - val_acc: 0.7842\n"
     ]
    }
   ],
   "source": [
    "model14, results14 = build_model(hidden_layers=[20,15,10], drop_out=0.1, l2_val=0.0001,file_name='model14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7864711204461156"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results14.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_149 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_113 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_115 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 5s 25us/step - loss: 0.5156 - acc: 0.7328 - val_loss: 0.4503 - val_acc: 0.7768\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4395 - acc: 0.7833 - val_loss: 0.4358 - val_acc: 0.7837\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4283 - acc: 0.7875 - val_loss: 0.4290 - val_acc: 0.7864\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4232 - acc: 0.7884 - val_loss: 0.4272 - val_acc: 0.7852\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4195 - acc: 0.7895 - val_loss: 0.4243 - val_acc: 0.7866\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4173 - acc: 0.7917 - val_loss: 0.4207 - val_acc: 0.7885\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4156 - acc: 0.7921 - val_loss: 0.4212 - val_acc: 0.7875\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4143 - acc: 0.7933 - val_loss: 0.4190 - val_acc: 0.7891\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4135 - acc: 0.7934 - val_loss: 0.4191 - val_acc: 0.7884\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4122 - acc: 0.7939 - val_loss: 0.4181 - val_acc: 0.7890\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4119 - acc: 0.7946 - val_loss: 0.4185 - val_acc: 0.7898\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4113 - acc: 0.7946 - val_loss: 0.4211 - val_acc: 0.7891\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4106 - acc: 0.7950 - val_loss: 0.4188 - val_acc: 0.7896\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4101 - acc: 0.7952 - val_loss: 0.4190 - val_acc: 0.7897\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4095 - acc: 0.7959 - val_loss: 0.4187 - val_acc: 0.7897\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4099 - acc: 0.7952 - val_loss: 0.4179 - val_acc: 0.7892\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4087 - acc: 0.7961 - val_loss: 0.4176 - val_acc: 0.7903\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4084 - acc: 0.7961 - val_loss: 0.4178 - val_acc: 0.7905\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4081 - acc: 0.7959 - val_loss: 0.4181 - val_acc: 0.7905\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4076 - acc: 0.7968 - val_loss: 0.4198 - val_acc: 0.7902\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.4075 - acc: 0.7971 - val_loss: 0.4195 - val_acc: 0.7893\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4075 - acc: 0.7966 - val_loss: 0.4170 - val_acc: 0.7915\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4067 - acc: 0.7971 - val_loss: 0.4192 - val_acc: 0.7908\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4065 - acc: 0.7973 - val_loss: 0.4173 - val_acc: 0.7906\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4065 - acc: 0.7974 - val_loss: 0.4183 - val_acc: 0.7904\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4063 - acc: 0.7973 - val_loss: 0.4174 - val_acc: 0.7908\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4060 - acc: 0.7976 - val_loss: 0.4179 - val_acc: 0.7912\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4056 - acc: 0.7977 - val_loss: 0.4170 - val_acc: 0.7910\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4054 - acc: 0.7979 - val_loss: 0.4186 - val_acc: 0.7904\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4052 - acc: 0.7985 - val_loss: 0.4179 - val_acc: 0.7905\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4053 - acc: 0.7979 - val_loss: 0.4182 - val_acc: 0.7909\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4051 - acc: 0.7981 - val_loss: 0.4171 - val_acc: 0.7909\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4048 - acc: 0.7982 - val_loss: 0.4177 - val_acc: 0.7916\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4047 - acc: 0.7983 - val_loss: 0.4185 - val_acc: 0.7895\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4043 - acc: 0.7980 - val_loss: 0.4178 - val_acc: 0.7908\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4045 - acc: 0.7986 - val_loss: 0.4191 - val_acc: 0.7914\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4042 - acc: 0.7981 - val_loss: 0.4178 - val_acc: 0.7909\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4044 - acc: 0.7987 - val_loss: 0.4184 - val_acc: 0.7910\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4038 - acc: 0.7988 - val_loss: 0.4178 - val_acc: 0.7898\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4036 - acc: 0.7993 - val_loss: 0.4191 - val_acc: 0.7900\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4035 - acc: 0.7990 - val_loss: 0.4188 - val_acc: 0.7904\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4029 - acc: 0.7993 - val_loss: 0.4179 - val_acc: 0.7906\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4032 - acc: 0.7995 - val_loss: 0.4176 - val_acc: 0.7917\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4029 - acc: 0.7988 - val_loss: 0.4186 - val_acc: 0.7912\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4028 - acc: 0.7989 - val_loss: 0.4189 - val_acc: 0.7915\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4029 - acc: 0.7994 - val_loss: 0.4189 - val_acc: 0.7901\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4029 - acc: 0.7995 - val_loss: 0.4188 - val_acc: 0.7895\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4027 - acc: 0.7996 - val_loss: 0.4215 - val_acc: 0.7891\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4023 - acc: 0.7996 - val_loss: 0.4230 - val_acc: 0.7882\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4022 - acc: 0.8005 - val_loss: 0.4198 - val_acc: 0.7891\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4023 - acc: 0.8000 - val_loss: 0.4210 - val_acc: 0.7899\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4016 - acc: 0.8001 - val_loss: 0.4195 - val_acc: 0.7898\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4020 - acc: 0.8000 - val_loss: 0.4187 - val_acc: 0.7900\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4015 - acc: 0.7998 - val_loss: 0.4185 - val_acc: 0.7910\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4014 - acc: 0.8005 - val_loss: 0.4179 - val_acc: 0.7902\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4014 - acc: 0.8006 - val_loss: 0.4190 - val_acc: 0.7909\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4013 - acc: 0.8004 - val_loss: 0.4192 - val_acc: 0.7901\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4012 - acc: 0.8003 - val_loss: 0.4187 - val_acc: 0.7910\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4010 - acc: 0.8007 - val_loss: 0.4188 - val_acc: 0.7895\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4010 - acc: 0.8011 - val_loss: 0.4183 - val_acc: 0.7899\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4008 - acc: 0.8008 - val_loss: 0.4187 - val_acc: 0.7903\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4010 - acc: 0.8012 - val_loss: 0.4181 - val_acc: 0.7911\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4007 - acc: 0.8010 - val_loss: 0.4191 - val_acc: 0.7903\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4007 - acc: 0.8008 - val_loss: 0.4192 - val_acc: 0.7906\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4004 - acc: 0.8008 - val_loss: 0.4188 - val_acc: 0.7902\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4007 - acc: 0.8005 - val_loss: 0.4207 - val_acc: 0.7904\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4005 - acc: 0.8011 - val_loss: 0.4187 - val_acc: 0.7921\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4005 - acc: 0.8009 - val_loss: 0.4185 - val_acc: 0.7913\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4006 - acc: 0.8012 - val_loss: 0.4196 - val_acc: 0.7909\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4002 - acc: 0.8012 - val_loss: 0.4190 - val_acc: 0.7903\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4001 - acc: 0.8016 - val_loss: 0.4194 - val_acc: 0.7910\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3998 - acc: 0.8008 - val_loss: 0.4202 - val_acc: 0.7902\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4001 - acc: 0.8010 - val_loss: 0.4204 - val_acc: 0.7900\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3997 - acc: 0.8015 - val_loss: 0.4213 - val_acc: 0.7884\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4000 - acc: 0.8012 - val_loss: 0.4222 - val_acc: 0.7880\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3997 - acc: 0.8012 - val_loss: 0.4200 - val_acc: 0.7908\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3995 - acc: 0.8018 - val_loss: 0.4185 - val_acc: 0.7899\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3995 - acc: 0.8016 - val_loss: 0.4195 - val_acc: 0.7899\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3992 - acc: 0.8016 - val_loss: 0.4208 - val_acc: 0.7894\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3992 - acc: 0.8018 - val_loss: 0.4193 - val_acc: 0.7901\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.3995 - acc: 0.8012 - val_loss: 0.4199 - val_acc: 0.7901\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3991 - acc: 0.8019 - val_loss: 0.4195 - val_acc: 0.7902\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3991 - acc: 0.8015 - val_loss: 0.4218 - val_acc: 0.7901\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3988 - acc: 0.8020 - val_loss: 0.4229 - val_acc: 0.7896\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3987 - acc: 0.8017 - val_loss: 0.4190 - val_acc: 0.7905\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3989 - acc: 0.8018 - val_loss: 0.4206 - val_acc: 0.7914\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3988 - acc: 0.8019 - val_loss: 0.4184 - val_acc: 0.7901\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3985 - acc: 0.8022 - val_loss: 0.4199 - val_acc: 0.7901\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3987 - acc: 0.8018 - val_loss: 0.4189 - val_acc: 0.7907\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3985 - acc: 0.8020 - val_loss: 0.4196 - val_acc: 0.7908\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.3982 - acc: 0.8025 - val_loss: 0.4206 - val_acc: 0.7903\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3983 - acc: 0.8018 - val_loss: 0.4191 - val_acc: 0.7913\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3981 - acc: 0.8023 - val_loss: 0.4198 - val_acc: 0.7905\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3982 - acc: 0.8021 - val_loss: 0.4188 - val_acc: 0.7911\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3982 - acc: 0.8021 - val_loss: 0.4197 - val_acc: 0.7905\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3979 - acc: 0.8023 - val_loss: 0.4196 - val_acc: 0.7912\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3980 - acc: 0.8027 - val_loss: 0.4192 - val_acc: 0.7916\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3977 - acc: 0.8023 - val_loss: 0.4209 - val_acc: 0.7888\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3981 - acc: 0.8022 - val_loss: 0.4197 - val_acc: 0.7911\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3978 - acc: 0.8030 - val_loss: 0.4189 - val_acc: 0.7910\n",
      "Epoch 101/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3977 - acc: 0.8022 - val_loss: 0.4215 - val_acc: 0.7892\n",
      "Epoch 102/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3978 - acc: 0.8023 - val_loss: 0.4191 - val_acc: 0.7908\n",
      "Epoch 103/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3977 - acc: 0.8031 - val_loss: 0.4194 - val_acc: 0.7913\n",
      "Epoch 104/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3974 - acc: 0.8021 - val_loss: 0.4195 - val_acc: 0.7906\n",
      "Epoch 105/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3976 - acc: 0.8028 - val_loss: 0.4200 - val_acc: 0.7911\n",
      "Epoch 106/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3974 - acc: 0.8026 - val_loss: 0.4209 - val_acc: 0.7900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3975 - acc: 0.8024 - val_loss: 0.4200 - val_acc: 0.7912\n",
      "Epoch 108/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3976 - acc: 0.8023 - val_loss: 0.4233 - val_acc: 0.7902\n",
      "Epoch 109/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3975 - acc: 0.8026 - val_loss: 0.4197 - val_acc: 0.7912\n",
      "Epoch 110/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3970 - acc: 0.8027 - val_loss: 0.4203 - val_acc: 0.7900\n",
      "Epoch 111/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3973 - acc: 0.8027 - val_loss: 0.4219 - val_acc: 0.7908\n",
      "Epoch 112/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3974 - acc: 0.8025 - val_loss: 0.4218 - val_acc: 0.7895\n",
      "Epoch 113/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3971 - acc: 0.8025 - val_loss: 0.4197 - val_acc: 0.7910\n",
      "Epoch 114/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3972 - acc: 0.8029 - val_loss: 0.4189 - val_acc: 0.7908\n",
      "Epoch 115/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3970 - acc: 0.8028 - val_loss: 0.4197 - val_acc: 0.7910\n",
      "Epoch 116/1000\n",
      "185736/185736 [==============================] - 3s 16us/step - loss: 0.3968 - acc: 0.8030 - val_loss: 0.4199 - val_acc: 0.7903\n",
      "Epoch 117/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.3970 - acc: 0.8024 - val_loss: 0.4199 - val_acc: 0.7907\n"
     ]
    }
   ],
   "source": [
    "model15, results15 = build_model(hidden_layers=[20,15,10], optimizer=optimizers.Adam(lr=0.001),file_name='model15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7920920014838385"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results15.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_153 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 5s 28us/step - loss: 0.5428 - acc: 0.7172 - val_loss: 0.4470 - val_acc: 0.7798\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4491 - acc: 0.7786 - val_loss: 0.4327 - val_acc: 0.7807\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4365 - acc: 0.7840 - val_loss: 0.4272 - val_acc: 0.7833\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4314 - acc: 0.7858 - val_loss: 0.4257 - val_acc: 0.7853\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4275 - acc: 0.7877 - val_loss: 0.4244 - val_acc: 0.7847\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4253 - acc: 0.7884 - val_loss: 0.4224 - val_acc: 0.7861\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4241 - acc: 0.7900 - val_loss: 0.4226 - val_acc: 0.7862\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4223 - acc: 0.7907 - val_loss: 0.4227 - val_acc: 0.7867\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4218 - acc: 0.7906 - val_loss: 0.4214 - val_acc: 0.7875\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4207 - acc: 0.7907 - val_loss: 0.4208 - val_acc: 0.7883\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4201 - acc: 0.7918 - val_loss: 0.4218 - val_acc: 0.7860\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4195 - acc: 0.7912 - val_loss: 0.4203 - val_acc: 0.7893\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4196 - acc: 0.7920 - val_loss: 0.4200 - val_acc: 0.7891\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4176 - acc: 0.7931 - val_loss: 0.4201 - val_acc: 0.7880\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4177 - acc: 0.7921 - val_loss: 0.4197 - val_acc: 0.7881\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4176 - acc: 0.7930 - val_loss: 0.4186 - val_acc: 0.7900\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4162 - acc: 0.7930 - val_loss: 0.4196 - val_acc: 0.7875\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4162 - acc: 0.7935 - val_loss: 0.4190 - val_acc: 0.7884\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4157 - acc: 0.7933 - val_loss: 0.4190 - val_acc: 0.7882\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4155 - acc: 0.7935 - val_loss: 0.4194 - val_acc: 0.7876\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4149 - acc: 0.7948 - val_loss: 0.4183 - val_acc: 0.7892\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4147 - acc: 0.7940 - val_loss: 0.4192 - val_acc: 0.7890\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4145 - acc: 0.7943 - val_loss: 0.4194 - val_acc: 0.7888\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4137 - acc: 0.7947 - val_loss: 0.4185 - val_acc: 0.7900\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4141 - acc: 0.7936 - val_loss: 0.4185 - val_acc: 0.7890\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4136 - acc: 0.7946 - val_loss: 0.4182 - val_acc: 0.7890\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4133 - acc: 0.7942 - val_loss: 0.4185 - val_acc: 0.7883\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4130 - acc: 0.7950 - val_loss: 0.4196 - val_acc: 0.7893\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4127 - acc: 0.7949 - val_loss: 0.4185 - val_acc: 0.7896\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4128 - acc: 0.7943 - val_loss: 0.4178 - val_acc: 0.7894\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4120 - acc: 0.7961 - val_loss: 0.4180 - val_acc: 0.7907\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4123 - acc: 0.7950 - val_loss: 0.4184 - val_acc: 0.7895\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4121 - acc: 0.7956 - val_loss: 0.4188 - val_acc: 0.7898\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4122 - acc: 0.7956 - val_loss: 0.4180 - val_acc: 0.7905\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4123 - acc: 0.7951 - val_loss: 0.4185 - val_acc: 0.7899\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4119 - acc: 0.7948 - val_loss: 0.4178 - val_acc: 0.7892\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4115 - acc: 0.7958 - val_loss: 0.4185 - val_acc: 0.7903\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4115 - acc: 0.7962 - val_loss: 0.4180 - val_acc: 0.7892\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4109 - acc: 0.7958 - val_loss: 0.4178 - val_acc: 0.7912\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4114 - acc: 0.7962 - val_loss: 0.4178 - val_acc: 0.7903\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4107 - acc: 0.7967 - val_loss: 0.4185 - val_acc: 0.7904\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4106 - acc: 0.7965 - val_loss: 0.4187 - val_acc: 0.7917\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4111 - acc: 0.7962 - val_loss: 0.4188 - val_acc: 0.7902\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4104 - acc: 0.7965 - val_loss: 0.4178 - val_acc: 0.7906\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4106 - acc: 0.7963 - val_loss: 0.4183 - val_acc: 0.7904\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4101 - acc: 0.7967 - val_loss: 0.4190 - val_acc: 0.7892\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4100 - acc: 0.7964 - val_loss: 0.4181 - val_acc: 0.7905\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4103 - acc: 0.7965 - val_loss: 0.4190 - val_acc: 0.7892\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4101 - acc: 0.7962 - val_loss: 0.4188 - val_acc: 0.7908\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4099 - acc: 0.7966 - val_loss: 0.4181 - val_acc: 0.7901\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4099 - acc: 0.7973 - val_loss: 0.4179 - val_acc: 0.7910\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4101 - acc: 0.7965 - val_loss: 0.4196 - val_acc: 0.7916\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4096 - acc: 0.7969 - val_loss: 0.4180 - val_acc: 0.7912\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4100 - acc: 0.7972 - val_loss: 0.4180 - val_acc: 0.7912\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4094 - acc: 0.7973 - val_loss: 0.4176 - val_acc: 0.7911\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4093 - acc: 0.7974 - val_loss: 0.4179 - val_acc: 0.7906\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4091 - acc: 0.7968 - val_loss: 0.4178 - val_acc: 0.7915\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4095 - acc: 0.7971 - val_loss: 0.4193 - val_acc: 0.7913\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4092 - acc: 0.7973 - val_loss: 0.4184 - val_acc: 0.7901\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4090 - acc: 0.7971 - val_loss: 0.4180 - val_acc: 0.7912\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4091 - acc: 0.7976 - val_loss: 0.4181 - val_acc: 0.7907\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4088 - acc: 0.7977 - val_loss: 0.4189 - val_acc: 0.7907\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4090 - acc: 0.7971 - val_loss: 0.4177 - val_acc: 0.7902\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4088 - acc: 0.7966 - val_loss: 0.4181 - val_acc: 0.7917\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4085 - acc: 0.7982 - val_loss: 0.4190 - val_acc: 0.7897\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4088 - acc: 0.7972 - val_loss: 0.4173 - val_acc: 0.7918\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4088 - acc: 0.7974 - val_loss: 0.4180 - val_acc: 0.7920\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4087 - acc: 0.7979 - val_loss: 0.4190 - val_acc: 0.7905\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4086 - acc: 0.7974 - val_loss: 0.4175 - val_acc: 0.7923\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4085 - acc: 0.7973 - val_loss: 0.4185 - val_acc: 0.7910\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4081 - acc: 0.7981 - val_loss: 0.4181 - val_acc: 0.7913\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4085 - acc: 0.7980 - val_loss: 0.4180 - val_acc: 0.7915\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4085 - acc: 0.7981 - val_loss: 0.4189 - val_acc: 0.7909\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4078 - acc: 0.7978 - val_loss: 0.4195 - val_acc: 0.7895\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4087 - acc: 0.7979 - val_loss: 0.4197 - val_acc: 0.7891\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4084 - acc: 0.7982 - val_loss: 0.4188 - val_acc: 0.7900\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4086 - acc: 0.7977 - val_loss: 0.4171 - val_acc: 0.7924\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4083 - acc: 0.7977 - val_loss: 0.4187 - val_acc: 0.7908\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4075 - acc: 0.7984 - val_loss: 0.4181 - val_acc: 0.7917\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4080 - acc: 0.7982 - val_loss: 0.4184 - val_acc: 0.7896\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4078 - acc: 0.7978 - val_loss: 0.4185 - val_acc: 0.7911\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4079 - acc: 0.7981 - val_loss: 0.4197 - val_acc: 0.7891\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4082 - acc: 0.7976 - val_loss: 0.4182 - val_acc: 0.7912\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4081 - acc: 0.7977 - val_loss: 0.4183 - val_acc: 0.7903\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4075 - acc: 0.7981 - val_loss: 0.4186 - val_acc: 0.7903\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4077 - acc: 0.7977 - val_loss: 0.4198 - val_acc: 0.7891\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4077 - acc: 0.7979 - val_loss: 0.4183 - val_acc: 0.7910\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4077 - acc: 0.7979 - val_loss: 0.4182 - val_acc: 0.7904\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4076 - acc: 0.7976 - val_loss: 0.4184 - val_acc: 0.7902\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4073 - acc: 0.7981 - val_loss: 0.4193 - val_acc: 0.7892\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4072 - acc: 0.7981 - val_loss: 0.4190 - val_acc: 0.7913\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4078 - acc: 0.7983 - val_loss: 0.4188 - val_acc: 0.7903\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4076 - acc: 0.7983 - val_loss: 0.4191 - val_acc: 0.7918\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4076 - acc: 0.7977 - val_loss: 0.4190 - val_acc: 0.7913\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4076 - acc: 0.7980 - val_loss: 0.4188 - val_acc: 0.7913\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4070 - acc: 0.7976 - val_loss: 0.4184 - val_acc: 0.7909\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4072 - acc: 0.7983 - val_loss: 0.4188 - val_acc: 0.7904\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4074 - acc: 0.7980 - val_loss: 0.4186 - val_acc: 0.7902\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4074 - acc: 0.7984 - val_loss: 0.4187 - val_acc: 0.7912\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4075 - acc: 0.7976 - val_loss: 0.4192 - val_acc: 0.7908\n",
      "Epoch 101/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4070 - acc: 0.7987 - val_loss: 0.4195 - val_acc: 0.7906\n",
      "Epoch 102/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4069 - acc: 0.7984 - val_loss: 0.4185 - val_acc: 0.7912\n",
      "Epoch 103/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4070 - acc: 0.7982 - val_loss: 0.4206 - val_acc: 0.7897\n",
      "Epoch 104/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4068 - acc: 0.7986 - val_loss: 0.4190 - val_acc: 0.7906\n",
      "Epoch 105/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4072 - acc: 0.7985 - val_loss: 0.4200 - val_acc: 0.7909\n",
      "Epoch 106/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4069 - acc: 0.7983 - val_loss: 0.4196 - val_acc: 0.7908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4074 - acc: 0.7979 - val_loss: 0.4193 - val_acc: 0.7906\n",
      "Epoch 108/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4071 - acc: 0.7984 - val_loss: 0.4200 - val_acc: 0.7906\n",
      "Epoch 109/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4074 - acc: 0.7981 - val_loss: 0.4186 - val_acc: 0.7913\n",
      "Epoch 110/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4067 - acc: 0.7988 - val_loss: 0.4192 - val_acc: 0.7917\n",
      "Epoch 111/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4068 - acc: 0.7988 - val_loss: 0.4195 - val_acc: 0.7911\n",
      "Epoch 112/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4066 - acc: 0.7986 - val_loss: 0.4202 - val_acc: 0.7911\n",
      "Epoch 113/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4073 - acc: 0.7987 - val_loss: 0.4199 - val_acc: 0.7915\n",
      "Epoch 114/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4066 - acc: 0.7986 - val_loss: 0.4189 - val_acc: 0.7916\n",
      "Epoch 115/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4068 - acc: 0.7980 - val_loss: 0.4195 - val_acc: 0.7901\n",
      "Epoch 116/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4064 - acc: 0.7993 - val_loss: 0.4194 - val_acc: 0.7907\n",
      "Epoch 117/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4071 - acc: 0.7987 - val_loss: 0.4193 - val_acc: 0.7896\n",
      "Epoch 118/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4068 - acc: 0.7985 - val_loss: 0.4190 - val_acc: 0.7910\n",
      "Epoch 119/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4068 - acc: 0.7987 - val_loss: 0.4186 - val_acc: 0.7913\n",
      "Epoch 120/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4061 - acc: 0.7987 - val_loss: 0.4183 - val_acc: 0.7918\n",
      "Epoch 121/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4065 - acc: 0.7984 - val_loss: 0.4199 - val_acc: 0.7903\n",
      "Epoch 122/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4062 - acc: 0.7990 - val_loss: 0.4192 - val_acc: 0.7914\n",
      "Epoch 123/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4065 - acc: 0.7985 - val_loss: 0.4194 - val_acc: 0.7904\n",
      "Epoch 124/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4067 - acc: 0.7986 - val_loss: 0.4185 - val_acc: 0.7909\n",
      "Epoch 125/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4068 - acc: 0.7988 - val_loss: 0.4198 - val_acc: 0.7917\n",
      "Epoch 126/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4063 - acc: 0.7988 - val_loss: 0.4189 - val_acc: 0.7911\n",
      "Epoch 127/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4068 - acc: 0.7983 - val_loss: 0.4194 - val_acc: 0.7909\n"
     ]
    }
   ],
   "source": [
    "model16, results16 = build_model(hidden_layers=[20,15,10], drop_out=0.1, optimizer=optimizers.Adam(lr=0.001),file_name='model16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7924365765796735"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results16.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_157 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 5s 26us/step - loss: 0.5229 - acc: 0.7292 - val_loss: 0.4514 - val_acc: 0.7785\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4413 - acc: 0.7841 - val_loss: 0.4385 - val_acc: 0.7836\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4342 - acc: 0.7857 - val_loss: 0.4411 - val_acc: 0.7785\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4294 - acc: 0.7871 - val_loss: 0.4303 - val_acc: 0.7849\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4271 - acc: 0.7880 - val_loss: 0.4295 - val_acc: 0.7852\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4262 - acc: 0.7885 - val_loss: 0.4288 - val_acc: 0.7850\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4250 - acc: 0.7884 - val_loss: 0.4275 - val_acc: 0.7855\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4241 - acc: 0.7892 - val_loss: 0.4273 - val_acc: 0.7853\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4235 - acc: 0.7895 - val_loss: 0.4270 - val_acc: 0.7852\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4228 - acc: 0.7897 - val_loss: 0.4286 - val_acc: 0.7858\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4226 - acc: 0.7899 - val_loss: 0.4274 - val_acc: 0.7846\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4217 - acc: 0.7907 - val_loss: 0.4264 - val_acc: 0.7875\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4213 - acc: 0.7906 - val_loss: 0.4276 - val_acc: 0.7861\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4213 - acc: 0.7911 - val_loss: 0.4250 - val_acc: 0.7868\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4203 - acc: 0.7917 - val_loss: 0.4252 - val_acc: 0.7880\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4201 - acc: 0.7913 - val_loss: 0.4248 - val_acc: 0.7890\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4198 - acc: 0.7916 - val_loss: 0.4246 - val_acc: 0.7884\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4196 - acc: 0.7915 - val_loss: 0.4243 - val_acc: 0.7884\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4191 - acc: 0.7916 - val_loss: 0.4238 - val_acc: 0.7897\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4187 - acc: 0.7923 - val_loss: 0.4231 - val_acc: 0.7905\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4182 - acc: 0.7932 - val_loss: 0.4237 - val_acc: 0.7888\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4183 - acc: 0.7928 - val_loss: 0.4238 - val_acc: 0.7900\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4180 - acc: 0.7928 - val_loss: 0.4227 - val_acc: 0.7900\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4178 - acc: 0.7937 - val_loss: 0.4240 - val_acc: 0.7892\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4178 - acc: 0.7933 - val_loss: 0.4241 - val_acc: 0.7888\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4176 - acc: 0.7937 - val_loss: 0.4224 - val_acc: 0.7902\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4172 - acc: 0.7943 - val_loss: 0.4230 - val_acc: 0.7905\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4170 - acc: 0.7938 - val_loss: 0.4217 - val_acc: 0.7921\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4172 - acc: 0.7938 - val_loss: 0.4220 - val_acc: 0.7904\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4169 - acc: 0.7939 - val_loss: 0.4234 - val_acc: 0.7897\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4167 - acc: 0.7936 - val_loss: 0.4218 - val_acc: 0.7913\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4164 - acc: 0.7943 - val_loss: 0.4217 - val_acc: 0.7902\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4164 - acc: 0.7947 - val_loss: 0.4221 - val_acc: 0.7912\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4161 - acc: 0.7948 - val_loss: 0.4216 - val_acc: 0.7922\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4158 - acc: 0.7951 - val_loss: 0.4228 - val_acc: 0.7903\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4158 - acc: 0.7949 - val_loss: 0.4221 - val_acc: 0.7899\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4157 - acc: 0.7947 - val_loss: 0.4216 - val_acc: 0.7902\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4153 - acc: 0.7954 - val_loss: 0.4219 - val_acc: 0.7908\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4159 - acc: 0.7946 - val_loss: 0.4224 - val_acc: 0.7902\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4151 - acc: 0.7952 - val_loss: 0.4237 - val_acc: 0.7909\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4152 - acc: 0.7951 - val_loss: 0.4217 - val_acc: 0.7904\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4153 - acc: 0.7951 - val_loss: 0.4212 - val_acc: 0.7923\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4149 - acc: 0.7956 - val_loss: 0.4266 - val_acc: 0.7893\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4150 - acc: 0.7954 - val_loss: 0.4211 - val_acc: 0.7914\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4149 - acc: 0.7956 - val_loss: 0.4227 - val_acc: 0.7905\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4147 - acc: 0.7951 - val_loss: 0.4218 - val_acc: 0.7918\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4145 - acc: 0.7959 - val_loss: 0.4215 - val_acc: 0.7911\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4144 - acc: 0.7960 - val_loss: 0.4211 - val_acc: 0.7919\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4149 - acc: 0.7957 - val_loss: 0.4212 - val_acc: 0.7915\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4145 - acc: 0.7959 - val_loss: 0.4216 - val_acc: 0.7921\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4142 - acc: 0.7958 - val_loss: 0.4208 - val_acc: 0.7918\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4142 - acc: 0.7961 - val_loss: 0.4215 - val_acc: 0.7913\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4145 - acc: 0.7955 - val_loss: 0.4234 - val_acc: 0.7894\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4139 - acc: 0.7958 - val_loss: 0.4213 - val_acc: 0.7911\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4138 - acc: 0.7955 - val_loss: 0.4212 - val_acc: 0.7928\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4138 - acc: 0.7958 - val_loss: 0.4209 - val_acc: 0.7916\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4138 - acc: 0.7960 - val_loss: 0.4210 - val_acc: 0.7923\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4135 - acc: 0.7959 - val_loss: 0.4207 - val_acc: 0.7915\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4137 - acc: 0.7963 - val_loss: 0.4222 - val_acc: 0.7920\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4134 - acc: 0.7969 - val_loss: 0.4214 - val_acc: 0.7916\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4131 - acc: 0.7968 - val_loss: 0.4224 - val_acc: 0.7904\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4138 - acc: 0.7961 - val_loss: 0.4232 - val_acc: 0.7917\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4138 - acc: 0.7963 - val_loss: 0.4225 - val_acc: 0.7909\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4134 - acc: 0.7964 - val_loss: 0.4207 - val_acc: 0.7920\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4132 - acc: 0.7962 - val_loss: 0.4222 - val_acc: 0.7919\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4133 - acc: 0.7955 - val_loss: 0.4220 - val_acc: 0.7923\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4132 - acc: 0.7961 - val_loss: 0.4205 - val_acc: 0.7917\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4126 - acc: 0.7966 - val_loss: 0.4206 - val_acc: 0.7917\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4132 - acc: 0.7967 - val_loss: 0.4214 - val_acc: 0.7926\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4131 - acc: 0.7967 - val_loss: 0.4205 - val_acc: 0.7911\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4133 - acc: 0.7966 - val_loss: 0.4204 - val_acc: 0.7917\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4128 - acc: 0.7967 - val_loss: 0.4228 - val_acc: 0.7888\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4132 - acc: 0.7963 - val_loss: 0.4219 - val_acc: 0.7893\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4125 - acc: 0.7968 - val_loss: 0.4206 - val_acc: 0.7919\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4129 - acc: 0.7961 - val_loss: 0.4205 - val_acc: 0.7918\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4124 - acc: 0.7973 - val_loss: 0.4208 - val_acc: 0.7922\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4126 - acc: 0.7966 - val_loss: 0.4226 - val_acc: 0.7917\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4122 - acc: 0.7972 - val_loss: 0.4243 - val_acc: 0.7882\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4128 - acc: 0.7969 - val_loss: 0.4217 - val_acc: 0.7905\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4124 - acc: 0.7971 - val_loss: 0.4210 - val_acc: 0.7927\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4123 - acc: 0.7969 - val_loss: 0.4257 - val_acc: 0.7886\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4122 - acc: 0.7972 - val_loss: 0.4206 - val_acc: 0.7927\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4120 - acc: 0.7980 - val_loss: 0.4208 - val_acc: 0.7908\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4126 - acc: 0.7966 - val_loss: 0.4212 - val_acc: 0.7912\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4119 - acc: 0.7976 - val_loss: 0.4220 - val_acc: 0.7911\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4121 - acc: 0.7973 - val_loss: 0.4203 - val_acc: 0.7910\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4123 - acc: 0.7969 - val_loss: 0.4246 - val_acc: 0.7904\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4121 - acc: 0.7967 - val_loss: 0.4210 - val_acc: 0.7938\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4118 - acc: 0.7977 - val_loss: 0.4199 - val_acc: 0.7920\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4123 - acc: 0.7970 - val_loss: 0.4205 - val_acc: 0.7913\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4120 - acc: 0.7977 - val_loss: 0.4216 - val_acc: 0.7898\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4118 - acc: 0.7973 - val_loss: 0.4212 - val_acc: 0.7908\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4114 - acc: 0.7971 - val_loss: 0.4201 - val_acc: 0.7925\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4119 - acc: 0.7977 - val_loss: 0.4210 - val_acc: 0.7916\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4117 - acc: 0.7978 - val_loss: 0.4213 - val_acc: 0.7928\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4115 - acc: 0.7973 - val_loss: 0.4214 - val_acc: 0.7917\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4114 - acc: 0.7975 - val_loss: 0.4217 - val_acc: 0.7915\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4117 - acc: 0.7977 - val_loss: 0.4205 - val_acc: 0.7918\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4114 - acc: 0.7982 - val_loss: 0.4209 - val_acc: 0.7914\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4113 - acc: 0.7977 - val_loss: 0.4234 - val_acc: 0.7904\n",
      "Epoch 101/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4110 - acc: 0.7984 - val_loss: 0.4225 - val_acc: 0.7926\n",
      "Epoch 102/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4112 - acc: 0.7980 - val_loss: 0.4225 - val_acc: 0.7914\n",
      "Epoch 103/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4114 - acc: 0.7980 - val_loss: 0.4204 - val_acc: 0.7914\n",
      "Epoch 104/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4110 - acc: 0.7982 - val_loss: 0.4200 - val_acc: 0.7923\n",
      "Epoch 105/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4111 - acc: 0.7981 - val_loss: 0.4205 - val_acc: 0.7918\n",
      "Epoch 106/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4111 - acc: 0.7980 - val_loss: 0.4200 - val_acc: 0.7918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4108 - acc: 0.7981 - val_loss: 0.4199 - val_acc: 0.7919\n",
      "Epoch 108/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4107 - acc: 0.7979 - val_loss: 0.4231 - val_acc: 0.7894\n",
      "Epoch 109/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4113 - acc: 0.7978 - val_loss: 0.4213 - val_acc: 0.7908\n",
      "Epoch 110/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4108 - acc: 0.7983 - val_loss: 0.4207 - val_acc: 0.7924\n",
      "Epoch 111/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4108 - acc: 0.7982 - val_loss: 0.4218 - val_acc: 0.7923\n",
      "Epoch 112/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4110 - acc: 0.7975 - val_loss: 0.4220 - val_acc: 0.7915\n",
      "Epoch 113/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4107 - acc: 0.7982 - val_loss: 0.4205 - val_acc: 0.7910\n",
      "Epoch 114/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4108 - acc: 0.7987 - val_loss: 0.4220 - val_acc: 0.7916\n",
      "Epoch 115/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4103 - acc: 0.7986 - val_loss: 0.4205 - val_acc: 0.7913\n",
      "Epoch 116/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4103 - acc: 0.7985 - val_loss: 0.4206 - val_acc: 0.7916\n",
      "Epoch 117/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4107 - acc: 0.7985 - val_loss: 0.4208 - val_acc: 0.7911\n",
      "Epoch 118/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4104 - acc: 0.7984 - val_loss: 0.4205 - val_acc: 0.7923\n",
      "Epoch 119/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4104 - acc: 0.7986 - val_loss: 0.4218 - val_acc: 0.7910\n",
      "Epoch 120/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4106 - acc: 0.7981 - val_loss: 0.4225 - val_acc: 0.7917\n",
      "Epoch 121/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4102 - acc: 0.7982 - val_loss: 0.4204 - val_acc: 0.7922\n",
      "Epoch 122/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4104 - acc: 0.7986 - val_loss: 0.4199 - val_acc: 0.7930\n",
      "Epoch 123/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4101 - acc: 0.7987 - val_loss: 0.4197 - val_acc: 0.7923\n",
      "Epoch 124/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4103 - acc: 0.7981 - val_loss: 0.4215 - val_acc: 0.7908\n",
      "Epoch 125/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4104 - acc: 0.7978 - val_loss: 0.4294 - val_acc: 0.7844\n",
      "Epoch 126/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4103 - acc: 0.7984 - val_loss: 0.4224 - val_acc: 0.7914\n",
      "Epoch 127/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4098 - acc: 0.7991 - val_loss: 0.4212 - val_acc: 0.7916\n",
      "Epoch 128/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4098 - acc: 0.7988 - val_loss: 0.4207 - val_acc: 0.7904\n",
      "Epoch 129/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4097 - acc: 0.7988 - val_loss: 0.4207 - val_acc: 0.7925\n",
      "Epoch 130/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4102 - acc: 0.7977 - val_loss: 0.4222 - val_acc: 0.7918\n",
      "Epoch 131/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4104 - acc: 0.7987 - val_loss: 0.4226 - val_acc: 0.7917\n",
      "Epoch 132/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4097 - acc: 0.7985 - val_loss: 0.4206 - val_acc: 0.7923\n",
      "Epoch 133/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4099 - acc: 0.7983 - val_loss: 0.4224 - val_acc: 0.7926\n",
      "Epoch 134/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4100 - acc: 0.7986 - val_loss: 0.4213 - val_acc: 0.7911\n",
      "Epoch 135/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4096 - acc: 0.7988 - val_loss: 0.4224 - val_acc: 0.7909\n",
      "Epoch 136/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4095 - acc: 0.7997 - val_loss: 0.4205 - val_acc: 0.7913\n",
      "Epoch 137/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4097 - acc: 0.7987 - val_loss: 0.4204 - val_acc: 0.7919\n",
      "Epoch 138/1000\n",
      "185736/185736 [==============================] - 3s 17us/step - loss: 0.4098 - acc: 0.7982 - val_loss: 0.4212 - val_acc: 0.7916\n"
     ]
    }
   ],
   "source": [
    "model17, results17 = build_model(hidden_layers=[20,15,10], l2_val=0.0001, optimizer=optimizers.Adam(lr=0.001),file_name='model17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7938148769347732"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results17.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_161 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_122 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_123 (Dropout)        (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_124 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 5s 29us/step - loss: 0.5576 - acc: 0.7068 - val_loss: 0.4592 - val_acc: 0.7809\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4589 - acc: 0.7783 - val_loss: 0.4373 - val_acc: 0.7836\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4413 - acc: 0.7852 - val_loss: 0.4324 - val_acc: 0.7838\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4363 - acc: 0.7862 - val_loss: 0.4305 - val_acc: 0.7853\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4333 - acc: 0.7876 - val_loss: 0.4292 - val_acc: 0.7864\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4315 - acc: 0.7884 - val_loss: 0.4276 - val_acc: 0.7863\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4308 - acc: 0.7885 - val_loss: 0.4277 - val_acc: 0.7869\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4296 - acc: 0.7898 - val_loss: 0.4275 - val_acc: 0.7877\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4290 - acc: 0.7898 - val_loss: 0.4270 - val_acc: 0.7875\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4280 - acc: 0.7903 - val_loss: 0.4266 - val_acc: 0.7872\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4273 - acc: 0.7915 - val_loss: 0.4269 - val_acc: 0.7870\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4265 - acc: 0.7911 - val_loss: 0.4259 - val_acc: 0.7875\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4259 - acc: 0.7913 - val_loss: 0.4251 - val_acc: 0.7884\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4258 - acc: 0.7915 - val_loss: 0.4253 - val_acc: 0.7881\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4249 - acc: 0.7924 - val_loss: 0.4252 - val_acc: 0.7886\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4245 - acc: 0.7929 - val_loss: 0.4245 - val_acc: 0.7898\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4239 - acc: 0.7925 - val_loss: 0.4248 - val_acc: 0.7893\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4234 - acc: 0.7935 - val_loss: 0.4256 - val_acc: 0.7874\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4231 - acc: 0.7933 - val_loss: 0.4237 - val_acc: 0.7895\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4239 - acc: 0.7928 - val_loss: 0.4235 - val_acc: 0.7882\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4230 - acc: 0.7938 - val_loss: 0.4240 - val_acc: 0.7895\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4230 - acc: 0.7935 - val_loss: 0.4239 - val_acc: 0.7895\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4222 - acc: 0.7941 - val_loss: 0.4268 - val_acc: 0.7886\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4221 - acc: 0.7934 - val_loss: 0.4242 - val_acc: 0.7904\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4224 - acc: 0.7944 - val_loss: 0.4233 - val_acc: 0.7893\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4217 - acc: 0.7946 - val_loss: 0.4229 - val_acc: 0.7909\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4218 - acc: 0.7938 - val_loss: 0.4238 - val_acc: 0.7901\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4217 - acc: 0.7936 - val_loss: 0.4234 - val_acc: 0.7892\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4215 - acc: 0.7943 - val_loss: 0.4224 - val_acc: 0.7893\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4216 - acc: 0.7936 - val_loss: 0.4232 - val_acc: 0.7897\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 3s 19us/step - loss: 0.4210 - acc: 0.7941 - val_loss: 0.4227 - val_acc: 0.7893\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4215 - acc: 0.7942 - val_loss: 0.4237 - val_acc: 0.7892\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4216 - acc: 0.7950 - val_loss: 0.4223 - val_acc: 0.7897\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4204 - acc: 0.7948 - val_loss: 0.4221 - val_acc: 0.7897\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4208 - acc: 0.7945 - val_loss: 0.4228 - val_acc: 0.7893\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4210 - acc: 0.7947 - val_loss: 0.4226 - val_acc: 0.7889\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4207 - acc: 0.7946 - val_loss: 0.4223 - val_acc: 0.7903\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4201 - acc: 0.7945 - val_loss: 0.4230 - val_acc: 0.7881\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4202 - acc: 0.7952 - val_loss: 0.4228 - val_acc: 0.7887\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4205 - acc: 0.7947 - val_loss: 0.4217 - val_acc: 0.7896\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4202 - acc: 0.7952 - val_loss: 0.4220 - val_acc: 0.7897\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4199 - acc: 0.7958 - val_loss: 0.4225 - val_acc: 0.7893\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4203 - acc: 0.7953 - val_loss: 0.4224 - val_acc: 0.7896\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4199 - acc: 0.7951 - val_loss: 0.4263 - val_acc: 0.7849\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4201 - acc: 0.7952 - val_loss: 0.4219 - val_acc: 0.7894\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4200 - acc: 0.7956 - val_loss: 0.4217 - val_acc: 0.7901\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4201 - acc: 0.7958 - val_loss: 0.4215 - val_acc: 0.7905\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4194 - acc: 0.7962 - val_loss: 0.4221 - val_acc: 0.7905\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4195 - acc: 0.7954 - val_loss: 0.4235 - val_acc: 0.7887\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4203 - acc: 0.7949 - val_loss: 0.4228 - val_acc: 0.7892\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4193 - acc: 0.7953 - val_loss: 0.4223 - val_acc: 0.7902\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4196 - acc: 0.7955 - val_loss: 0.4219 - val_acc: 0.7900\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4192 - acc: 0.7957 - val_loss: 0.4225 - val_acc: 0.7882\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4193 - acc: 0.7960 - val_loss: 0.4255 - val_acc: 0.7877\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4190 - acc: 0.7959 - val_loss: 0.4210 - val_acc: 0.7904\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4192 - acc: 0.7957 - val_loss: 0.4223 - val_acc: 0.7889\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4190 - acc: 0.7953 - val_loss: 0.4209 - val_acc: 0.7908\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4187 - acc: 0.7967 - val_loss: 0.4220 - val_acc: 0.7894\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4192 - acc: 0.7959 - val_loss: 0.4210 - val_acc: 0.7908\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4190 - acc: 0.7958 - val_loss: 0.4207 - val_acc: 0.7906\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4193 - acc: 0.7957 - val_loss: 0.4208 - val_acc: 0.7901\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4185 - acc: 0.7960 - val_loss: 0.4218 - val_acc: 0.7896\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4193 - acc: 0.7958 - val_loss: 0.4203 - val_acc: 0.7915\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4188 - acc: 0.7960 - val_loss: 0.4205 - val_acc: 0.7907\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4187 - acc: 0.7954 - val_loss: 0.4207 - val_acc: 0.7913\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4187 - acc: 0.7956 - val_loss: 0.4216 - val_acc: 0.7902\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4190 - acc: 0.7957 - val_loss: 0.4214 - val_acc: 0.7894\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4190 - acc: 0.7960 - val_loss: 0.4221 - val_acc: 0.7906\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4188 - acc: 0.7961 - val_loss: 0.4206 - val_acc: 0.7909\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4184 - acc: 0.7963 - val_loss: 0.4212 - val_acc: 0.7901\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4189 - acc: 0.7962 - val_loss: 0.4214 - val_acc: 0.7914\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4191 - acc: 0.7963 - val_loss: 0.4209 - val_acc: 0.7915\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4184 - acc: 0.7961 - val_loss: 0.4206 - val_acc: 0.7916\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4181 - acc: 0.7967 - val_loss: 0.4220 - val_acc: 0.7896\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4188 - acc: 0.7958 - val_loss: 0.4231 - val_acc: 0.7886\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4185 - acc: 0.7964 - val_loss: 0.4219 - val_acc: 0.7890\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4179 - acc: 0.7964 - val_loss: 0.4206 - val_acc: 0.7913\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4182 - acc: 0.7970 - val_loss: 0.4218 - val_acc: 0.7893\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4182 - acc: 0.7955 - val_loss: 0.4209 - val_acc: 0.7907\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4184 - acc: 0.7961 - val_loss: 0.4222 - val_acc: 0.7907\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4184 - acc: 0.7962 - val_loss: 0.4213 - val_acc: 0.7903\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4184 - acc: 0.7962 - val_loss: 0.4207 - val_acc: 0.7904\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4181 - acc: 0.7964 - val_loss: 0.4206 - val_acc: 0.7912\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4183 - acc: 0.7968 - val_loss: 0.4212 - val_acc: 0.7910\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4178 - acc: 0.7969 - val_loss: 0.4215 - val_acc: 0.7907\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4183 - acc: 0.7961 - val_loss: 0.4210 - val_acc: 0.7905\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4181 - acc: 0.7960 - val_loss: 0.4218 - val_acc: 0.7907\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4184 - acc: 0.7956 - val_loss: 0.4225 - val_acc: 0.7894\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4181 - acc: 0.7962 - val_loss: 0.4204 - val_acc: 0.7909\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4183 - acc: 0.7962 - val_loss: 0.4202 - val_acc: 0.7914\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4181 - acc: 0.7961 - val_loss: 0.4224 - val_acc: 0.7897\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4181 - acc: 0.7966 - val_loss: 0.4225 - val_acc: 0.7911\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4178 - acc: 0.7957 - val_loss: 0.4206 - val_acc: 0.7909\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4180 - acc: 0.7965 - val_loss: 0.4223 - val_acc: 0.7905\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4181 - acc: 0.7964 - val_loss: 0.4215 - val_acc: 0.7927\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4176 - acc: 0.7966 - val_loss: 0.4214 - val_acc: 0.7919\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4180 - acc: 0.7958 - val_loss: 0.4217 - val_acc: 0.7908\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4185 - acc: 0.7962 - val_loss: 0.4206 - val_acc: 0.7909\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4179 - acc: 0.7959 - val_loss: 0.4216 - val_acc: 0.7902\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4182 - acc: 0.7968 - val_loss: 0.4197 - val_acc: 0.7905\n",
      "Epoch 101/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4173 - acc: 0.7964 - val_loss: 0.4215 - val_acc: 0.7897\n",
      "Epoch 102/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4179 - acc: 0.7966 - val_loss: 0.4201 - val_acc: 0.7930\n",
      "Epoch 103/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4182 - acc: 0.7967 - val_loss: 0.4211 - val_acc: 0.7912\n",
      "Epoch 104/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4175 - acc: 0.7972 - val_loss: 0.4213 - val_acc: 0.7912\n",
      "Epoch 105/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4178 - acc: 0.7965 - val_loss: 0.4216 - val_acc: 0.7914\n",
      "Epoch 106/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4181 - acc: 0.7963 - val_loss: 0.4206 - val_acc: 0.7907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4185 - acc: 0.7962 - val_loss: 0.4218 - val_acc: 0.7902\n",
      "Epoch 108/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4181 - acc: 0.7971 - val_loss: 0.4217 - val_acc: 0.7916\n",
      "Epoch 109/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4176 - acc: 0.7970 - val_loss: 0.4219 - val_acc: 0.7906\n",
      "Epoch 110/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4185 - acc: 0.7961 - val_loss: 0.4194 - val_acc: 0.7918\n",
      "Epoch 111/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4178 - acc: 0.7969 - val_loss: 0.4204 - val_acc: 0.7916\n",
      "Epoch 112/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4173 - acc: 0.7975 - val_loss: 0.4208 - val_acc: 0.7903\n",
      "Epoch 113/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4172 - acc: 0.7969 - val_loss: 0.4216 - val_acc: 0.7905\n",
      "Epoch 114/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4176 - acc: 0.7962 - val_loss: 0.4212 - val_acc: 0.7903\n",
      "Epoch 115/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4175 - acc: 0.7965 - val_loss: 0.4209 - val_acc: 0.7903\n",
      "Epoch 116/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4176 - acc: 0.7965 - val_loss: 0.4202 - val_acc: 0.7908\n",
      "Epoch 117/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4170 - acc: 0.7967 - val_loss: 0.4203 - val_acc: 0.7905\n",
      "Epoch 118/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4173 - acc: 0.7974 - val_loss: 0.4203 - val_acc: 0.7918\n",
      "Epoch 119/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4173 - acc: 0.7968 - val_loss: 0.4196 - val_acc: 0.7916\n",
      "Epoch 120/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4178 - acc: 0.7963 - val_loss: 0.4210 - val_acc: 0.7922\n",
      "Epoch 121/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4171 - acc: 0.7970 - val_loss: 0.4207 - val_acc: 0.7916\n",
      "Epoch 122/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4173 - acc: 0.7965 - val_loss: 0.4207 - val_acc: 0.7915\n",
      "Epoch 123/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4171 - acc: 0.7972 - val_loss: 0.4201 - val_acc: 0.7906\n",
      "Epoch 124/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4179 - acc: 0.7969 - val_loss: 0.4215 - val_acc: 0.7911\n",
      "Epoch 125/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4172 - acc: 0.7966 - val_loss: 0.4216 - val_acc: 0.7910\n",
      "Epoch 126/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4178 - acc: 0.7964 - val_loss: 0.4202 - val_acc: 0.7927\n",
      "Epoch 127/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4168 - acc: 0.7971 - val_loss: 0.4213 - val_acc: 0.7903\n",
      "Epoch 128/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4173 - acc: 0.7960 - val_loss: 0.4192 - val_acc: 0.7921\n",
      "Epoch 129/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4171 - acc: 0.7960 - val_loss: 0.4211 - val_acc: 0.7909\n",
      "Epoch 130/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4171 - acc: 0.7966 - val_loss: 0.4203 - val_acc: 0.7925\n",
      "Epoch 131/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4170 - acc: 0.7969 - val_loss: 0.4203 - val_acc: 0.7917\n",
      "Epoch 132/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4173 - acc: 0.7967 - val_loss: 0.4199 - val_acc: 0.7913\n",
      "Epoch 133/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4170 - acc: 0.7965 - val_loss: 0.4199 - val_acc: 0.7921\n",
      "Epoch 134/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4168 - acc: 0.7976 - val_loss: 0.4194 - val_acc: 0.7934\n",
      "Epoch 135/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4175 - acc: 0.7963 - val_loss: 0.4203 - val_acc: 0.7917\n",
      "Epoch 136/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4171 - acc: 0.7968 - val_loss: 0.4201 - val_acc: 0.7907\n",
      "Epoch 137/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4176 - acc: 0.7965 - val_loss: 0.4211 - val_acc: 0.7902\n",
      "Epoch 138/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4175 - acc: 0.7968 - val_loss: 0.4196 - val_acc: 0.7918\n",
      "Epoch 139/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4172 - acc: 0.7964 - val_loss: 0.4211 - val_acc: 0.7906\n",
      "Epoch 140/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4177 - acc: 0.7962 - val_loss: 0.4192 - val_acc: 0.7921\n",
      "Epoch 141/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4172 - acc: 0.7963 - val_loss: 0.4200 - val_acc: 0.7900\n",
      "Epoch 142/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4175 - acc: 0.7963 - val_loss: 0.4192 - val_acc: 0.7926\n",
      "Epoch 143/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4176 - acc: 0.7963 - val_loss: 0.4194 - val_acc: 0.7913\n",
      "Epoch 144/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4173 - acc: 0.7964 - val_loss: 0.4195 - val_acc: 0.7919\n",
      "Epoch 145/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4169 - acc: 0.7965 - val_loss: 0.4199 - val_acc: 0.7917\n",
      "Epoch 146/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4169 - acc: 0.7969 - val_loss: 0.4204 - val_acc: 0.7910\n",
      "Epoch 147/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4171 - acc: 0.7964 - val_loss: 0.4200 - val_acc: 0.7918\n",
      "Epoch 148/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4173 - acc: 0.7962 - val_loss: 0.4204 - val_acc: 0.7904\n",
      "Epoch 149/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4170 - acc: 0.7962 - val_loss: 0.4197 - val_acc: 0.7914\n",
      "Epoch 150/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4170 - acc: 0.7971 - val_loss: 0.4199 - val_acc: 0.7921\n",
      "Epoch 151/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4170 - acc: 0.7968 - val_loss: 0.4192 - val_acc: 0.7924\n",
      "Epoch 152/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4166 - acc: 0.7973 - val_loss: 0.4196 - val_acc: 0.7920\n",
      "Epoch 153/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4170 - acc: 0.7966 - val_loss: 0.4206 - val_acc: 0.7931\n",
      "Epoch 154/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4165 - acc: 0.7975 - val_loss: 0.4205 - val_acc: 0.7920\n",
      "Epoch 155/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4171 - acc: 0.7970 - val_loss: 0.4195 - val_acc: 0.7918\n",
      "Epoch 156/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4167 - acc: 0.7971 - val_loss: 0.4223 - val_acc: 0.7899\n",
      "Epoch 157/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4166 - acc: 0.7958 - val_loss: 0.4194 - val_acc: 0.7926\n",
      "Epoch 158/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4164 - acc: 0.7969 - val_loss: 0.4193 - val_acc: 0.7922\n",
      "Epoch 159/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4173 - acc: 0.7967 - val_loss: 0.4197 - val_acc: 0.7925\n",
      "Epoch 160/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4170 - acc: 0.7968 - val_loss: 0.4196 - val_acc: 0.7917\n",
      "Epoch 161/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4166 - acc: 0.7963 - val_loss: 0.4202 - val_acc: 0.7924\n",
      "Epoch 162/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4168 - acc: 0.7966 - val_loss: 0.4203 - val_acc: 0.7919\n",
      "Epoch 163/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4167 - acc: 0.7969 - val_loss: 0.4200 - val_acc: 0.7930\n",
      "Epoch 164/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4167 - acc: 0.7973 - val_loss: 0.4193 - val_acc: 0.7920\n",
      "Epoch 165/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4162 - acc: 0.7971 - val_loss: 0.4212 - val_acc: 0.7926\n",
      "Epoch 166/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4169 - acc: 0.7968 - val_loss: 0.4221 - val_acc: 0.7927\n",
      "Epoch 167/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4160 - acc: 0.7975 - val_loss: 0.4199 - val_acc: 0.7906\n",
      "Epoch 168/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4173 - acc: 0.7960 - val_loss: 0.4194 - val_acc: 0.7919\n",
      "Epoch 169/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4163 - acc: 0.7962 - val_loss: 0.4197 - val_acc: 0.7920\n",
      "Epoch 170/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4172 - acc: 0.7962 - val_loss: 0.4206 - val_acc: 0.7922\n",
      "Epoch 171/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4169 - acc: 0.7964 - val_loss: 0.4207 - val_acc: 0.7922\n",
      "Epoch 172/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4170 - acc: 0.7970 - val_loss: 0.4201 - val_acc: 0.7913\n",
      "Epoch 173/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4165 - acc: 0.7973 - val_loss: 0.4208 - val_acc: 0.7930\n",
      "Epoch 174/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4171 - acc: 0.7963 - val_loss: 0.4208 - val_acc: 0.7910\n",
      "Epoch 175/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4170 - acc: 0.7970 - val_loss: 0.4205 - val_acc: 0.7933\n",
      "Epoch 176/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4168 - acc: 0.7965 - val_loss: 0.4186 - val_acc: 0.7927\n",
      "Epoch 177/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4167 - acc: 0.7964 - val_loss: 0.4188 - val_acc: 0.7928\n",
      "Epoch 178/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4167 - acc: 0.7972 - val_loss: 0.4201 - val_acc: 0.7928\n",
      "Epoch 179/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4169 - acc: 0.7970 - val_loss: 0.4191 - val_acc: 0.7928\n",
      "Epoch 180/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4166 - acc: 0.7978 - val_loss: 0.4198 - val_acc: 0.7913\n",
      "Epoch 181/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4164 - acc: 0.7972 - val_loss: 0.4183 - val_acc: 0.7934\n",
      "Epoch 182/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4164 - acc: 0.7978 - val_loss: 0.4208 - val_acc: 0.7925\n",
      "Epoch 183/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4174 - acc: 0.7975 - val_loss: 0.4199 - val_acc: 0.7914\n",
      "Epoch 184/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4165 - acc: 0.7969 - val_loss: 0.4193 - val_acc: 0.7919\n",
      "Epoch 185/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4164 - acc: 0.7973 - val_loss: 0.4191 - val_acc: 0.7919\n",
      "Epoch 186/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4165 - acc: 0.7964 - val_loss: 0.4211 - val_acc: 0.7908\n",
      "Epoch 187/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4165 - acc: 0.7969 - val_loss: 0.4209 - val_acc: 0.7913\n",
      "Epoch 188/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4163 - acc: 0.7964 - val_loss: 0.4196 - val_acc: 0.7926\n",
      "Epoch 189/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4164 - acc: 0.7977 - val_loss: 0.4187 - val_acc: 0.7941\n",
      "Epoch 190/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4169 - acc: 0.7968 - val_loss: 0.4186 - val_acc: 0.7931\n",
      "Epoch 191/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4163 - acc: 0.7966 - val_loss: 0.4187 - val_acc: 0.7932\n",
      "Epoch 192/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4163 - acc: 0.7974 - val_loss: 0.4200 - val_acc: 0.7912\n",
      "Epoch 193/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4167 - acc: 0.7970 - val_loss: 0.4196 - val_acc: 0.7924\n",
      "Epoch 194/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4163 - acc: 0.7978 - val_loss: 0.4209 - val_acc: 0.7907\n",
      "Epoch 195/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4165 - acc: 0.7968 - val_loss: 0.4187 - val_acc: 0.7924\n",
      "Epoch 196/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4161 - acc: 0.7980 - val_loss: 0.4195 - val_acc: 0.7923\n",
      "Epoch 197/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4165 - acc: 0.7972 - val_loss: 0.4212 - val_acc: 0.7922\n",
      "Epoch 198/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4167 - acc: 0.7965 - val_loss: 0.4207 - val_acc: 0.7911\n",
      "Epoch 199/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4169 - acc: 0.7967 - val_loss: 0.4196 - val_acc: 0.7913\n",
      "Epoch 200/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4163 - acc: 0.7973 - val_loss: 0.4223 - val_acc: 0.7914\n",
      "Epoch 201/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4165 - acc: 0.7970 - val_loss: 0.4202 - val_acc: 0.7917\n",
      "Epoch 202/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4167 - acc: 0.7969 - val_loss: 0.4184 - val_acc: 0.7929\n",
      "Epoch 203/1000\n",
      "185736/185736 [==============================] - 3s 18us/step - loss: 0.4169 - acc: 0.7965 - val_loss: 0.4209 - val_acc: 0.7903\n",
      "Epoch 204/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4167 - acc: 0.7967 - val_loss: 0.4193 - val_acc: 0.7925\n",
      "Epoch 205/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4164 - acc: 0.7977 - val_loss: 0.4197 - val_acc: 0.7922\n",
      "Epoch 206/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4163 - acc: 0.7966 - val_loss: 0.4190 - val_acc: 0.7916\n",
      "Epoch 207/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4167 - acc: 0.7969 - val_loss: 0.4192 - val_acc: 0.7927\n",
      "Epoch 208/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4168 - acc: 0.7977 - val_loss: 0.4186 - val_acc: 0.7933\n",
      "Epoch 209/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4164 - acc: 0.7973 - val_loss: 0.4179 - val_acc: 0.7927\n",
      "Epoch 210/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4159 - acc: 0.7977 - val_loss: 0.4196 - val_acc: 0.7935\n",
      "Epoch 211/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4160 - acc: 0.7972 - val_loss: 0.4198 - val_acc: 0.7914\n",
      "Epoch 212/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4165 - acc: 0.7971 - val_loss: 0.4215 - val_acc: 0.7904\n",
      "Epoch 213/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4164 - acc: 0.7972 - val_loss: 0.4240 - val_acc: 0.7900\n",
      "Epoch 214/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4170 - acc: 0.7967 - val_loss: 0.4188 - val_acc: 0.7938\n",
      "Epoch 215/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4159 - acc: 0.7970 - val_loss: 0.4200 - val_acc: 0.7918\n",
      "Epoch 216/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4162 - acc: 0.7972 - val_loss: 0.4193 - val_acc: 0.7920\n",
      "Epoch 217/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4166 - acc: 0.7974 - val_loss: 0.4216 - val_acc: 0.7913\n",
      "Epoch 218/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4166 - acc: 0.7975 - val_loss: 0.4177 - val_acc: 0.7931\n",
      "Epoch 219/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4164 - acc: 0.7972 - val_loss: 0.4177 - val_acc: 0.7937\n",
      "Epoch 220/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4157 - acc: 0.7970 - val_loss: 0.4188 - val_acc: 0.7921\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4157 - acc: 0.7974 - val_loss: 0.4193 - val_acc: 0.7927\n",
      "Epoch 222/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4156 - acc: 0.7980 - val_loss: 0.4192 - val_acc: 0.7932\n",
      "Epoch 223/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4162 - acc: 0.7980 - val_loss: 0.4195 - val_acc: 0.7925\n",
      "Epoch 224/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4161 - acc: 0.7974 - val_loss: 0.4183 - val_acc: 0.7928\n",
      "Epoch 225/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4163 - acc: 0.7965 - val_loss: 0.4187 - val_acc: 0.7934\n",
      "Epoch 226/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4162 - acc: 0.7968 - val_loss: 0.4195 - val_acc: 0.7925\n",
      "Epoch 227/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4164 - acc: 0.7976 - val_loss: 0.4201 - val_acc: 0.7925\n",
      "Epoch 228/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4160 - acc: 0.7976 - val_loss: 0.4186 - val_acc: 0.7928\n",
      "Epoch 229/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4163 - acc: 0.7972 - val_loss: 0.4204 - val_acc: 0.7918\n",
      "Epoch 230/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4159 - acc: 0.7972 - val_loss: 0.4185 - val_acc: 0.7924\n",
      "Epoch 231/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4158 - acc: 0.7979 - val_loss: 0.4190 - val_acc: 0.7931\n",
      "Epoch 232/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4166 - acc: 0.7967 - val_loss: 0.4186 - val_acc: 0.7923\n",
      "Epoch 233/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4166 - acc: 0.7974 - val_loss: 0.4205 - val_acc: 0.7906\n",
      "Epoch 234/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4163 - acc: 0.7984 - val_loss: 0.4193 - val_acc: 0.7925\n",
      "Epoch 235/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4158 - acc: 0.7983 - val_loss: 0.4197 - val_acc: 0.7929\n",
      "Epoch 236/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4160 - acc: 0.7979 - val_loss: 0.4192 - val_acc: 0.7931\n",
      "Epoch 237/1000\n",
      "185736/185736 [==============================] - 4s 19us/step - loss: 0.4163 - acc: 0.7974 - val_loss: 0.4197 - val_acc: 0.7918\n",
      "Epoch 238/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4163 - acc: 0.7970 - val_loss: 0.4190 - val_acc: 0.7926\n",
      "Epoch 239/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4168 - acc: 0.7964 - val_loss: 0.4196 - val_acc: 0.7925\n"
     ]
    }
   ],
   "source": [
    "model18, results18 = build_model(hidden_layers=[20,15,10], drop_out=0.1, l2_val=0.0001, optimizer=optimizers.Adam(lr=0.001),file_name='model18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7941379163284431"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results18.history['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.to_categorical(\n",
    "    train_y,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_softmax_output(hidden_layers, optimizer=optimizers.Adam(lr=0.01), batch_size=512, drop_out=0.0, l2_val=0, file_name=None):\n",
    "    model = models.Sequential()\n",
    "    # Hidden - Layers\n",
    "    for idx, layer in enumerate(hidden_layers):\n",
    "        if idx == 0:\n",
    "            model.add(Dense(layer, activation=\"relu\", input_shape=(221,), kernel_regularizer=l2(l2_val)))\n",
    "            model.add(Dropout(drop_out, noise_shape=None, seed=None))\n",
    "        else:\n",
    "            model.add(Dense(layer, activation=\"relu\", kernel_regularizer=l2(l2_val)))\n",
    "            model.add(Dropout(drop_out, noise_shape=None, seed=None))\n",
    "    # Output- Layer\n",
    "    model.add(Dense(2, activation=tf.nn.softmax))\n",
    "    model.summary()\n",
    "    # compiling the model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    # Define some callbacks\n",
    "    callbacks_func = []\n",
    "    earlyStopping = EarlyStopping(monitor='val_acc', patience=50, verbose=0, mode='max')\n",
    "    if file_name is None:\n",
    "        callbacks_func = [earlyStopping]\n",
    "    else:\n",
    "        mcp_save = ModelCheckpoint(file_name+'.hdf5', save_best_only=True, monitor='val_acc', mode='max')\n",
    "        callbacks_func = [mcp_save, earlyStopping]\n",
    "    results = model.fit(\n",
    "        train_x, tf.keras.utils.to_categorical(train_y),\n",
    "        epochs=1000,\n",
    "        batch_size=batch_size,\n",
    "        callbacks = callbacks_func,\n",
    "        validation_data=(val_x, tf.keras.utils.to_categorical(val_y))\n",
    "    )\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_228 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_173 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_174 (Dropout)        (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_175 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 4,937\n",
      "Trainable params: 4,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 185736 samples, validate on 46434 samples\n",
      "Epoch 1/1000\n",
      "185736/185736 [==============================] - 6s 32us/step - loss: 0.5507 - acc: 0.7118 - val_loss: 0.4514 - val_acc: 0.7822\n",
      "Epoch 2/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4512 - acc: 0.7799 - val_loss: 0.4347 - val_acc: 0.7839\n",
      "Epoch 3/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4384 - acc: 0.7841 - val_loss: 0.4294 - val_acc: 0.7855\n",
      "Epoch 4/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4341 - acc: 0.7871 - val_loss: 0.4311 - val_acc: 0.7865\n",
      "Epoch 5/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4316 - acc: 0.7885 - val_loss: 0.4274 - val_acc: 0.7856\n",
      "Epoch 6/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4298 - acc: 0.7886 - val_loss: 0.4274 - val_acc: 0.7882\n",
      "Epoch 7/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4278 - acc: 0.7895 - val_loss: 0.4270 - val_acc: 0.7871\n",
      "Epoch 8/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4278 - acc: 0.7898 - val_loss: 0.4254 - val_acc: 0.7890\n",
      "Epoch 9/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4260 - acc: 0.7910 - val_loss: 0.4248 - val_acc: 0.7881\n",
      "Epoch 10/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4258 - acc: 0.7913 - val_loss: 0.4259 - val_acc: 0.7879\n",
      "Epoch 11/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4251 - acc: 0.7911 - val_loss: 0.4245 - val_acc: 0.7893\n",
      "Epoch 12/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4247 - acc: 0.7919 - val_loss: 0.4238 - val_acc: 0.7897\n",
      "Epoch 13/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4244 - acc: 0.7920 - val_loss: 0.4242 - val_acc: 0.7882\n",
      "Epoch 14/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4242 - acc: 0.7915 - val_loss: 0.4252 - val_acc: 0.7877\n",
      "Epoch 15/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4242 - acc: 0.7914 - val_loss: 0.4241 - val_acc: 0.7900\n",
      "Epoch 16/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4237 - acc: 0.7922 - val_loss: 0.4239 - val_acc: 0.7891\n",
      "Epoch 17/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4227 - acc: 0.7924 - val_loss: 0.4234 - val_acc: 0.7899\n",
      "Epoch 18/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4229 - acc: 0.7924 - val_loss: 0.4237 - val_acc: 0.7880\n",
      "Epoch 19/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4228 - acc: 0.7922 - val_loss: 0.4242 - val_acc: 0.7902\n",
      "Epoch 20/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4217 - acc: 0.7929 - val_loss: 0.4247 - val_acc: 0.7883\n",
      "Epoch 21/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4220 - acc: 0.7917 - val_loss: 0.4240 - val_acc: 0.7896\n",
      "Epoch 22/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4218 - acc: 0.7928 - val_loss: 0.4234 - val_acc: 0.7897\n",
      "Epoch 23/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4214 - acc: 0.7941 - val_loss: 0.4233 - val_acc: 0.7887\n",
      "Epoch 24/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4215 - acc: 0.7934 - val_loss: 0.4225 - val_acc: 0.7912\n",
      "Epoch 25/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4210 - acc: 0.7932 - val_loss: 0.4226 - val_acc: 0.7900\n",
      "Epoch 26/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4213 - acc: 0.7931 - val_loss: 0.4226 - val_acc: 0.7907\n",
      "Epoch 27/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4210 - acc: 0.7935 - val_loss: 0.4229 - val_acc: 0.7895\n",
      "Epoch 28/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4208 - acc: 0.7931 - val_loss: 0.4228 - val_acc: 0.7899\n",
      "Epoch 29/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4200 - acc: 0.7936 - val_loss: 0.4232 - val_acc: 0.7899\n",
      "Epoch 30/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4207 - acc: 0.7933 - val_loss: 0.4223 - val_acc: 0.7896\n",
      "Epoch 31/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4207 - acc: 0.7935 - val_loss: 0.4220 - val_acc: 0.7898\n",
      "Epoch 32/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4201 - acc: 0.7935 - val_loss: 0.4221 - val_acc: 0.7900\n",
      "Epoch 33/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4203 - acc: 0.7938 - val_loss: 0.4220 - val_acc: 0.7909\n",
      "Epoch 34/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4198 - acc: 0.7940 - val_loss: 0.4218 - val_acc: 0.7895\n",
      "Epoch 35/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4199 - acc: 0.7936 - val_loss: 0.4209 - val_acc: 0.7913\n",
      "Epoch 36/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4196 - acc: 0.7936 - val_loss: 0.4241 - val_acc: 0.7895\n",
      "Epoch 37/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4192 - acc: 0.7946 - val_loss: 0.4218 - val_acc: 0.7909\n",
      "Epoch 38/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4197 - acc: 0.7945 - val_loss: 0.4215 - val_acc: 0.7914\n",
      "Epoch 39/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4196 - acc: 0.7951 - val_loss: 0.4228 - val_acc: 0.7889\n",
      "Epoch 40/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4196 - acc: 0.7943 - val_loss: 0.4212 - val_acc: 0.7916\n",
      "Epoch 41/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4195 - acc: 0.7945 - val_loss: 0.4206 - val_acc: 0.7902\n",
      "Epoch 42/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4187 - acc: 0.7945 - val_loss: 0.4217 - val_acc: 0.7914\n",
      "Epoch 43/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4192 - acc: 0.7943 - val_loss: 0.4208 - val_acc: 0.7906\n",
      "Epoch 44/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4190 - acc: 0.7947 - val_loss: 0.4214 - val_acc: 0.7906\n",
      "Epoch 45/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4191 - acc: 0.7953 - val_loss: 0.4208 - val_acc: 0.7911\n",
      "Epoch 46/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4188 - acc: 0.7942 - val_loss: 0.4219 - val_acc: 0.7900\n",
      "Epoch 47/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4183 - acc: 0.7954 - val_loss: 0.4218 - val_acc: 0.7910\n",
      "Epoch 48/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4186 - acc: 0.7956 - val_loss: 0.4216 - val_acc: 0.7914\n",
      "Epoch 49/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4183 - acc: 0.7953 - val_loss: 0.4208 - val_acc: 0.7908\n",
      "Epoch 50/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4180 - acc: 0.7950 - val_loss: 0.4207 - val_acc: 0.7912\n",
      "Epoch 51/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4184 - acc: 0.7955 - val_loss: 0.4226 - val_acc: 0.7904\n",
      "Epoch 52/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4188 - acc: 0.7953 - val_loss: 0.4203 - val_acc: 0.7915\n",
      "Epoch 53/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4188 - acc: 0.7948 - val_loss: 0.4206 - val_acc: 0.7914\n",
      "Epoch 54/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4183 - acc: 0.7951 - val_loss: 0.4208 - val_acc: 0.7922\n",
      "Epoch 55/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4180 - acc: 0.7947 - val_loss: 0.4209 - val_acc: 0.7908\n",
      "Epoch 56/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4180 - acc: 0.7948 - val_loss: 0.4220 - val_acc: 0.7913\n",
      "Epoch 57/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4186 - acc: 0.7939 - val_loss: 0.4214 - val_acc: 0.7900\n",
      "Epoch 58/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4178 - acc: 0.7955 - val_loss: 0.4209 - val_acc: 0.7916\n",
      "Epoch 59/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4177 - acc: 0.7956 - val_loss: 0.4213 - val_acc: 0.7903\n",
      "Epoch 60/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4175 - acc: 0.7951 - val_loss: 0.4206 - val_acc: 0.7905\n",
      "Epoch 61/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4183 - acc: 0.7941 - val_loss: 0.4220 - val_acc: 0.7886\n",
      "Epoch 62/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4180 - acc: 0.7948 - val_loss: 0.4211 - val_acc: 0.7904\n",
      "Epoch 63/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4174 - acc: 0.7956 - val_loss: 0.4214 - val_acc: 0.7904\n",
      "Epoch 64/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4181 - acc: 0.7949 - val_loss: 0.4208 - val_acc: 0.7920\n",
      "Epoch 65/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4178 - acc: 0.7957 - val_loss: 0.4201 - val_acc: 0.7916\n",
      "Epoch 66/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4179 - acc: 0.7950 - val_loss: 0.4198 - val_acc: 0.7910\n",
      "Epoch 67/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4181 - acc: 0.7947 - val_loss: 0.4213 - val_acc: 0.7904\n",
      "Epoch 68/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4178 - acc: 0.7959 - val_loss: 0.4209 - val_acc: 0.7909\n",
      "Epoch 69/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4173 - acc: 0.7951 - val_loss: 0.4203 - val_acc: 0.7913\n",
      "Epoch 70/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4175 - acc: 0.7951 - val_loss: 0.4203 - val_acc: 0.7917\n",
      "Epoch 71/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4177 - acc: 0.7959 - val_loss: 0.4214 - val_acc: 0.7897\n",
      "Epoch 72/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4171 - acc: 0.7962 - val_loss: 0.4205 - val_acc: 0.7921\n",
      "Epoch 73/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4176 - acc: 0.7961 - val_loss: 0.4206 - val_acc: 0.7917\n",
      "Epoch 74/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4178 - acc: 0.7954 - val_loss: 0.4217 - val_acc: 0.7909\n",
      "Epoch 75/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4177 - acc: 0.7955 - val_loss: 0.4199 - val_acc: 0.7918\n",
      "Epoch 76/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4177 - acc: 0.7953 - val_loss: 0.4211 - val_acc: 0.7904\n",
      "Epoch 77/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4171 - acc: 0.7953 - val_loss: 0.4203 - val_acc: 0.7917\n",
      "Epoch 78/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4176 - acc: 0.7958 - val_loss: 0.4198 - val_acc: 0.7916\n",
      "Epoch 79/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4175 - acc: 0.7958 - val_loss: 0.4216 - val_acc: 0.7906\n",
      "Epoch 80/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4179 - acc: 0.7949 - val_loss: 0.4204 - val_acc: 0.7911\n",
      "Epoch 81/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4173 - acc: 0.7951 - val_loss: 0.4202 - val_acc: 0.7911\n",
      "Epoch 82/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4172 - acc: 0.7957 - val_loss: 0.4213 - val_acc: 0.7906\n",
      "Epoch 83/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4169 - acc: 0.7957 - val_loss: 0.4207 - val_acc: 0.7920\n",
      "Epoch 84/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4174 - acc: 0.7959 - val_loss: 0.4201 - val_acc: 0.7908\n",
      "Epoch 85/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4171 - acc: 0.7959 - val_loss: 0.4197 - val_acc: 0.7914\n",
      "Epoch 86/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4166 - acc: 0.7961 - val_loss: 0.4208 - val_acc: 0.7908\n",
      "Epoch 87/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4164 - acc: 0.7960 - val_loss: 0.4205 - val_acc: 0.7923\n",
      "Epoch 88/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4172 - acc: 0.7955 - val_loss: 0.4218 - val_acc: 0.7908\n",
      "Epoch 89/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4171 - acc: 0.7957 - val_loss: 0.4201 - val_acc: 0.7900\n",
      "Epoch 90/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4165 - acc: 0.7963 - val_loss: 0.4192 - val_acc: 0.7918\n",
      "Epoch 91/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4165 - acc: 0.7959 - val_loss: 0.4214 - val_acc: 0.7903\n",
      "Epoch 92/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4168 - acc: 0.7963 - val_loss: 0.4217 - val_acc: 0.7888\n",
      "Epoch 93/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4170 - acc: 0.7954 - val_loss: 0.4229 - val_acc: 0.7904\n",
      "Epoch 94/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4165 - acc: 0.7955 - val_loss: 0.4196 - val_acc: 0.7920\n",
      "Epoch 95/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4170 - acc: 0.7962 - val_loss: 0.4199 - val_acc: 0.7918\n",
      "Epoch 96/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4173 - acc: 0.7947 - val_loss: 0.4202 - val_acc: 0.7912\n",
      "Epoch 97/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4170 - acc: 0.7955 - val_loss: 0.4196 - val_acc: 0.7917\n",
      "Epoch 98/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4160 - acc: 0.7957 - val_loss: 0.4201 - val_acc: 0.7927\n",
      "Epoch 99/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4166 - acc: 0.7966 - val_loss: 0.4201 - val_acc: 0.7907\n",
      "Epoch 100/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4167 - acc: 0.7959 - val_loss: 0.4194 - val_acc: 0.7922\n",
      "Epoch 101/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4160 - acc: 0.7961 - val_loss: 0.4195 - val_acc: 0.7927\n",
      "Epoch 102/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4162 - acc: 0.7963 - val_loss: 0.4199 - val_acc: 0.7915\n",
      "Epoch 103/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4162 - acc: 0.7961 - val_loss: 0.4205 - val_acc: 0.7897\n",
      "Epoch 104/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4165 - acc: 0.7961 - val_loss: 0.4196 - val_acc: 0.7918\n",
      "Epoch 105/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4164 - acc: 0.7956 - val_loss: 0.4194 - val_acc: 0.7903\n",
      "Epoch 106/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4164 - acc: 0.7964 - val_loss: 0.4191 - val_acc: 0.7928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4161 - acc: 0.7963 - val_loss: 0.4196 - val_acc: 0.7908\n",
      "Epoch 108/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4163 - acc: 0.7964 - val_loss: 0.4195 - val_acc: 0.7916\n",
      "Epoch 109/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4159 - acc: 0.7970 - val_loss: 0.4215 - val_acc: 0.7913\n",
      "Epoch 110/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4166 - acc: 0.7960 - val_loss: 0.4191 - val_acc: 0.7924\n",
      "Epoch 111/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4163 - acc: 0.7954 - val_loss: 0.4205 - val_acc: 0.7907\n",
      "Epoch 112/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4162 - acc: 0.7969 - val_loss: 0.4189 - val_acc: 0.7931\n",
      "Epoch 113/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4161 - acc: 0.7966 - val_loss: 0.4211 - val_acc: 0.7924\n",
      "Epoch 114/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4160 - acc: 0.7967 - val_loss: 0.4209 - val_acc: 0.7935\n",
      "Epoch 115/1000\n",
      "185736/185736 [==============================] - 4s 20us/step - loss: 0.4158 - acc: 0.7966 - val_loss: 0.4195 - val_acc: 0.7915\n",
      "Epoch 116/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4158 - acc: 0.7968 - val_loss: 0.4193 - val_acc: 0.7918\n",
      "Epoch 117/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4158 - acc: 0.7971 - val_loss: 0.4196 - val_acc: 0.7931\n",
      "Epoch 118/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4161 - acc: 0.7970 - val_loss: 0.4210 - val_acc: 0.7918\n",
      "Epoch 119/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4156 - acc: 0.7967 - val_loss: 0.4192 - val_acc: 0.7928\n",
      "Epoch 120/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4156 - acc: 0.7968 - val_loss: 0.4199 - val_acc: 0.7919\n",
      "Epoch 121/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4161 - acc: 0.7961 - val_loss: 0.4188 - val_acc: 0.7924\n",
      "Epoch 122/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4156 - acc: 0.7970 - val_loss: 0.4185 - val_acc: 0.7917\n",
      "Epoch 123/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4164 - acc: 0.7963 - val_loss: 0.4190 - val_acc: 0.7931\n",
      "Epoch 124/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4161 - acc: 0.7968 - val_loss: 0.4188 - val_acc: 0.7920\n",
      "Epoch 125/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4159 - acc: 0.7971 - val_loss: 0.4194 - val_acc: 0.7906\n",
      "Epoch 126/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4158 - acc: 0.7962 - val_loss: 0.4194 - val_acc: 0.7916\n",
      "Epoch 127/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4154 - acc: 0.7969 - val_loss: 0.4183 - val_acc: 0.7924\n",
      "Epoch 128/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4152 - acc: 0.7966 - val_loss: 0.4191 - val_acc: 0.7931\n",
      "Epoch 129/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4153 - acc: 0.7971 - val_loss: 0.4193 - val_acc: 0.7941\n",
      "Epoch 130/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4161 - acc: 0.7965 - val_loss: 0.4189 - val_acc: 0.7922\n",
      "Epoch 131/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4155 - acc: 0.7963 - val_loss: 0.4186 - val_acc: 0.7925\n",
      "Epoch 132/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4162 - acc: 0.7961 - val_loss: 0.4184 - val_acc: 0.7922\n",
      "Epoch 133/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4152 - acc: 0.7972 - val_loss: 0.4205 - val_acc: 0.7920\n",
      "Epoch 134/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4156 - acc: 0.7965 - val_loss: 0.4190 - val_acc: 0.7923\n",
      "Epoch 135/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4157 - acc: 0.7965 - val_loss: 0.4196 - val_acc: 0.7920\n",
      "Epoch 136/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4156 - acc: 0.7965 - val_loss: 0.4223 - val_acc: 0.7931\n",
      "Epoch 137/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4157 - acc: 0.7966 - val_loss: 0.4183 - val_acc: 0.7917\n",
      "Epoch 138/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4156 - acc: 0.7967 - val_loss: 0.4191 - val_acc: 0.7919\n",
      "Epoch 139/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4158 - acc: 0.7975 - val_loss: 0.4180 - val_acc: 0.7937\n",
      "Epoch 140/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4157 - acc: 0.7970 - val_loss: 0.4188 - val_acc: 0.7926\n",
      "Epoch 141/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4151 - acc: 0.7972 - val_loss: 0.4198 - val_acc: 0.7917\n",
      "Epoch 142/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4158 - acc: 0.7965 - val_loss: 0.4196 - val_acc: 0.7923\n",
      "Epoch 143/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4156 - acc: 0.7966 - val_loss: 0.4178 - val_acc: 0.7930\n",
      "Epoch 144/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4157 - acc: 0.7961 - val_loss: 0.4188 - val_acc: 0.7930\n",
      "Epoch 145/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4151 - acc: 0.7968 - val_loss: 0.4202 - val_acc: 0.7922\n",
      "Epoch 146/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4159 - acc: 0.7967 - val_loss: 0.4189 - val_acc: 0.7928\n",
      "Epoch 147/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4152 - acc: 0.7962 - val_loss: 0.4203 - val_acc: 0.7922\n",
      "Epoch 148/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4158 - acc: 0.7968 - val_loss: 0.4211 - val_acc: 0.7924\n",
      "Epoch 149/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4160 - acc: 0.7963 - val_loss: 0.4193 - val_acc: 0.7918\n",
      "Epoch 150/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4156 - acc: 0.7966 - val_loss: 0.4204 - val_acc: 0.7921\n",
      "Epoch 151/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4149 - acc: 0.7965 - val_loss: 0.4194 - val_acc: 0.7924\n",
      "Epoch 152/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4151 - acc: 0.7971 - val_loss: 0.4232 - val_acc: 0.7873\n",
      "Epoch 153/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4155 - acc: 0.7973 - val_loss: 0.4209 - val_acc: 0.7926\n",
      "Epoch 154/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4153 - acc: 0.7962 - val_loss: 0.4188 - val_acc: 0.7932\n",
      "Epoch 155/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4151 - acc: 0.7976 - val_loss: 0.4191 - val_acc: 0.7919\n",
      "Epoch 156/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4156 - acc: 0.7961 - val_loss: 0.4193 - val_acc: 0.7916\n",
      "Epoch 157/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4150 - acc: 0.7971 - val_loss: 0.4198 - val_acc: 0.7924\n",
      "Epoch 158/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4154 - acc: 0.7970 - val_loss: 0.4202 - val_acc: 0.7923\n",
      "Epoch 159/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4152 - acc: 0.7964 - val_loss: 0.4218 - val_acc: 0.7887\n",
      "Epoch 160/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4158 - acc: 0.7960 - val_loss: 0.4187 - val_acc: 0.7931\n",
      "Epoch 161/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4153 - acc: 0.7972 - val_loss: 0.4206 - val_acc: 0.7915\n",
      "Epoch 162/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4157 - acc: 0.7968 - val_loss: 0.4214 - val_acc: 0.7916\n",
      "Epoch 163/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4155 - acc: 0.7964 - val_loss: 0.4204 - val_acc: 0.7908\n",
      "Epoch 164/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4156 - acc: 0.7965 - val_loss: 0.4192 - val_acc: 0.7914\n",
      "Epoch 165/1000\n",
      "185736/185736 [==============================] - 4s 21us/step - loss: 0.4155 - acc: 0.7971 - val_loss: 0.4192 - val_acc: 0.7919\n",
      "Epoch 166/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4152 - acc: 0.7972 - val_loss: 0.4188 - val_acc: 0.7929\n",
      "Epoch 167/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4153 - acc: 0.7977 - val_loss: 0.4207 - val_acc: 0.7923\n",
      "Epoch 168/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4154 - acc: 0.7972 - val_loss: 0.4182 - val_acc: 0.7922\n",
      "Epoch 169/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4154 - acc: 0.7971 - val_loss: 0.4205 - val_acc: 0.7928\n",
      "Epoch 170/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4149 - acc: 0.7975 - val_loss: 0.4188 - val_acc: 0.7936\n",
      "Epoch 171/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4154 - acc: 0.7968 - val_loss: 0.4187 - val_acc: 0.7922\n",
      "Epoch 172/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4150 - acc: 0.7975 - val_loss: 0.4182 - val_acc: 0.7925\n",
      "Epoch 173/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4150 - acc: 0.7971 - val_loss: 0.4200 - val_acc: 0.7925\n",
      "Epoch 174/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4147 - acc: 0.7977 - val_loss: 0.4181 - val_acc: 0.7937\n",
      "Epoch 175/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4153 - acc: 0.7970 - val_loss: 0.4186 - val_acc: 0.7924\n",
      "Epoch 176/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4149 - acc: 0.7966 - val_loss: 0.4194 - val_acc: 0.7914\n",
      "Epoch 177/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4150 - acc: 0.7973 - val_loss: 0.4218 - val_acc: 0.7910\n",
      "Epoch 178/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4149 - acc: 0.7975 - val_loss: 0.4198 - val_acc: 0.7923\n",
      "Epoch 179/1000\n",
      "185736/185736 [==============================] - 4s 22us/step - loss: 0.4143 - acc: 0.7972 - val_loss: 0.4193 - val_acc: 0.7919\n"
     ]
    }
   ],
   "source": [
    "model19, results19 = build_model_with_softmax_output(hidden_layers=[20,15,10], batch_size=512, drop_out=0.1, l2_val=0.0001, optimizer=optimizers.Adam(lr=0.001),file_name='model19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.794073308135987"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(results19.history['val_acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_without_train(hidden_layers, drop_out=0.0, l2_val=0, optimizer=optimizers.Adam(lr=0.000001)):\n",
    "    model = models.Sequential()\n",
    "    # Hidden - Layers\n",
    "    for idx, layer in enumerate(hidden_layers):\n",
    "        if idx == 0:\n",
    "            model.add(Dense(layer, activation=\"relu\", input_shape=(221,), kernel_regularizer=l2(l2_val)))\n",
    "            model.add(Dropout(drop_out, noise_shape=None, seed=None))\n",
    "        else:\n",
    "            model.add(Dense(layer, activation=\"relu\", kernel_regularizer=l2(l2_val)))\n",
    "            model.add(Dropout(drop_out, noise_shape=None, seed=None))\n",
    "    # Output- Layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_181 (Dense)            (None, 20)                4440      \n",
      "_________________________________________________________________\n",
      "dropout_137 (Dropout)        (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dropout_138 (Dropout)        (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dropout_139 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 4,926\n",
      "Trainable params: 4,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = build_model_without_train(hidden_layers=[20,15,10], drop_out=0.1, l2_val=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.load_weights('model18.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99502/99502 [==============================] - 7s 75us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41586358213886654, 0.7952302466258123]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.evaluate(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kickstarter)",
   "language": "python",
   "name": "kickstarter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
